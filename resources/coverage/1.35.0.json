{
    "spec": "https://raw.githubusercontent.com/kubernetes/kubernetes/master/api/openapi-spec/swagger.json",
    "tests": [
        {
            "file": null,
            "test": "",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, list mutating webhooks",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, list validating webhooks",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, update mutating webhook",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, update validating webhook",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
            "release": "1.35.0",
            "testname": "Mutating Admission webhook, create and update mutating webhook configuration with matchConditions",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
            "release": "1.35.0",
            "testname": "Validating Admission webhook, create and update validating webhook configuration with matchConditions",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, deny attach",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, deny custom resource create and delete",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, deny create",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, deny custom resource definition",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, honor timeout",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, discovery document",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, ordered mutation",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, mutate custom resource",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, mutate custom resource with different stored version",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, mutate custom resource with pruning",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
            "release": "1.35.0",
            "testname": "Mutating Admission webhook, mutating webhook excluding object with specific name",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, mutation with defaulting",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, admission control not allowed on webhook configuration objects",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
            "release": "1.35.0",
            "testname": "Mutating Admission webhook, reject mutating webhook configurations with invalid matchConditions",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
            "release": "1.35.0",
            "testname": "Validing Admission webhook, reject validating webhook configurations with invalid matchConditions",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/apimachinery/webhook.go",
            "test": "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
            "release": "1.35.0",
            "testname": "Admission webhook, fail closed",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/aggregated_discovery.go",
            "test": "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
            "release": "1.35.0",
            "testname": "Aggregated Discovery Interface",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/aggregated_discovery.go",
            "test": "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
            "release": "1.35.0",
            "testname": "Aggregated Discovery Interface CRDs",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/aggregated_discovery.go",
            "test": "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
            "release": "1.35.0",
            "testname": "Aggregated Discovery Endpoint Accept Headers",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/aggregated_discovery.go",
            "test": "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
            "release": "1.35.0",
            "testname": "Aggregated Discovery Endpoint Accept Headers CRDs",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/aggregator.go",
            "test": "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
            "release": "1.35.0",
            "testname": "aggregator-supports-the-sample-apiserver",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (fairness)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (priority)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/flowcontrol.go",
            "test": "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
            "release": "1.35.0",
            "testname": "Priority and Fairness FlowSchema API",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": "test/e2e/apimachinery/flowcontrol.go",
            "test": "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
            "release": "1.35.0",
            "testname": "Priority and Fairness PriorityLevelConfiguration API",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/crd_conversion_webhook.go",
            "test": "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition Conversion Webhook, convert mixed version list",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_conversion_webhook.go",
            "test": "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition Conversion Webhook, conversion custom resource",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/custom_resource_definition.go",
            "test": "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition, defaulting",
            "conformance_test": true,
            "promotion_release": "1.17.0"
        },
        {
            "file": "test/e2e/apimachinery/custom_resource_definition.go",
            "test": "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition, discovery",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/custom_resource_definition.go",
            "test": "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition, create",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apimachinery/custom_resource_definition.go",
            "test": "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition, status sub-resource",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/custom_resource_definition.go",
            "test": "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition, list",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_watch.go",
            "test": "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource Definition, watch",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_selectable_fields.go",
            "test": "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
            "release": "1.35.0",
            "testname": "custom-resource-definition-field-selectors-list-watch-register-informers",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, stop serving version",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, version rename",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, with x-kubernetes-preserve-unknown-fields at root",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, with x-kubernetes-preserve-unknown-fields in embedded object",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, with x-kubernetes-preserve-unknown-fields in object",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, with validation schema",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, varying groups",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, varying kinds",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/crd_publish_openapi.go",
            "test": "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
            "release": "1.35.0",
            "testname": "Custom Resource OpenAPI Publish, varying versions",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Discovery Custom resource should have storage version hash",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Discovery should accurately determine present and missing resources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/discovery.go",
            "test": "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
            "release": "1.35.0",
            "testname": "Discovery, confirm the groupVerion and a resourcefrom each apiGroup",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/apimachinery/discovery.go",
            "test": "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
            "release": "1.35.0",
            "testname": "Discovery, confirm the PreferredVersion for each api group",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, unknown fields CR no validation schema",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, unknown fields CR fails validation",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, valid CR with validation schema",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, CR duplicates",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, typed object",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, unknown metadata",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": "test/e2e/apimachinery/field_validation.go",
            "test": "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
            "release": "1.35.0",
            "testname": "Server side field validation, typed unknown metadata",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, delete replication controller, propagation policy background",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, delete deployment,  propagation policy background",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, delete replication controller, after owned pods",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, dependency cycle",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, multiple owners",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, delete replication controller, propagation policy orphan",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apimachinery/garbage_collector.go",
            "test": "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
            "release": "1.35.0",
            "testname": "Garbage Collector, delete deployment, propagation policy orphan",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] health handlers should contain necessary checks",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
            "release": "1.35.0",
            "testname": "Namespace, apply finalizer to a namespace",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
            "release": "1.35.0",
            "testname": "Namespace, apply update to a namespace",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
            "release": "1.35.0",
            "testname": "Namespace, apply changes to a namespace status",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
            "release": "1.35.0",
            "testname": "namespace-deletion-removes-pods",
            "conformance_test": true,
            "promotion_release": "1.11.0"
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
            "release": "1.35.0",
            "testname": "namespace-deletion-removes-services",
            "conformance_test": true,
            "promotion_release": "1.11.0"
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
            "release": "1.35.0",
            "testname": "Namespace patching",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] OpenAPIV3 should round trip OpenAPI V3 for all built-in group versions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/namespace.go",
            "test": "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
            "release": "1.35.0",
            "testname": "Ordered Namespace Deletion",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, apply changes to a ResourceQuota status",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, update and delete",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, configmap",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, pod",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, replicaSet",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, replicationController",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, secret",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, service",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, object count quota, resourcequotas",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, manage lifecycle of a ResourceQuota",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, quota scope, BestEffort and NotBestEffort scope",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/resource_quota.go",
            "test": "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
            "release": "1.35.0",
            "testname": "ResourceQuota, quota scope, Terminating and NotTerminating scope",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Server request timeout default timeout should be used if the specified timeout in the request URL is 0s",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Server request timeout should return HTTP status code 400 if the user specifies an invalid timeout in the request URL",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Server request timeout the request should be served with a default timeout if the specified timeout in the request URL exceeds maximum allowed",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should work for CRDs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ServerSideApply should work for subresources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/chunking.go",
            "test": "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
            "release": "1.35.0",
            "testname": "API Chunking, server should return chunks of results for list calls",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": "test/e2e/apimachinery/chunking.go",
            "test": "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
            "release": "1.35.0",
            "testname": "API Chunking, server should support continue listing from the last key even if the original version has been compacted away",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": "test/e2e/apimachinery/table_conversion.go",
            "test": "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
            "release": "1.35.0",
            "testname": "API metadata HTTP return",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] Servers with support for Table transformation should return pod details",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/server_version.go",
            "test": "[sig-api-machinery] server version should find the server version [Conformance]",
            "release": "1.35.0",
            "testname": "Confirm a server version",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/apimachinery/validatingadmissionpolicy.go",
            "test": "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
            "release": "1.35.0",
            "testname": "ValidatingAdmissionPolicy",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/validatingadmissionpolicy.go",
            "test": "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
            "release": "1.35.0",
            "testname": "ValidatingAdmissionPolicy API",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/validatingadmissionpolicy.go",
            "test": "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
            "release": "1.35.0",
            "testname": "ValidatingadmissionPolicyBinding API",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apimachinery/validatingadmissionpolicy.go",
            "test": "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
            "release": "1.35.0",
            "testname": "ValidatingAdmissionPolicy",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/apimachinery/watch.go",
            "test": "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
            "release": "1.35.0",
            "testname": "watch-configmaps-closed-and-restarted",
            "conformance_test": true,
            "promotion_release": "1.11.0"
        },
        {
            "file": "test/e2e/apimachinery/watch.go",
            "test": "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
            "release": "1.35.0",
            "testname": "watch-configmaps-from-resource-version",
            "conformance_test": true,
            "promotion_release": "1.11.0"
        },
        {
            "file": "test/e2e/apimachinery/watch.go",
            "test": "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
            "release": "1.35.0",
            "testname": "watch-configmaps-with-multiple-watchers",
            "conformance_test": true,
            "promotion_release": "1.11.0"
        },
        {
            "file": "test/e2e/apimachinery/watch.go",
            "test": "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
            "release": "1.35.0",
            "testname": "watch-configmaps-label-changed",
            "conformance_test": true,
            "promotion_release": "1.11.0"
        },
        {
            "file": "test/e2e/apimachinery/watch.go",
            "test": "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
            "release": "1.35.0",
            "testname": "watch-consistency",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/apps/controller_revision.go",
            "test": "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
            "release": "1.35.0",
            "testname": "ControllerRevision, resource lifecycle",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should not emit unexpected warnings",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/cronjob.go",
            "test": "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
            "release": "1.35.0",
            "testname": "CronJob Suspend",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/cronjob.go",
            "test": "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
            "release": "1.35.0",
            "testname": "CronJob ForbidConcurrent",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should remove from active list jobs that have been deleted",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/cronjob.go",
            "test": "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
            "release": "1.35.0",
            "testname": "CronJob ReplaceConcurrent",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/cronjob.go",
            "test": "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
            "release": "1.35.0",
            "testname": "CronJob AllowConcurrent",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/cronjob.go",
            "test": "[sig-apps] CronJob should support CronJob API operations [Conformance]",
            "release": "1.35.0",
            "testname": "CronJob API Operations",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-apps] CronJob should support timezone",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet, list and delete a collection of DaemonSets",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet-FailedPodCreation",
            "conformance_test": true,
            "promotion_release": "1.10.0"
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet-Rollback",
            "conformance_test": true,
            "promotion_release": "1.10.0"
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet-NodeSelection",
            "conformance_test": true,
            "promotion_release": "1.10.0"
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet-Creation",
            "conformance_test": true,
            "promotion_release": "1.10.0"
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet-RollingUpdate",
            "conformance_test": true,
            "promotion_release": "1.10.0"
        },
        {
            "file": "test/e2e/apps/daemon_set.go",
            "test": "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
            "release": "1.35.0",
            "testname": "DaemonSet, status sub-resource",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment RevisionHistoryLimit",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment, completes the scaling of a Deployment subresource",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment Proportional Scaling",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment deployment should support rollover [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment Rollover",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Deployment iterative rollouts should eventually progress",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment Recreate",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment RollingUpdate",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment, completes the lifecycle of a Deployment",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/apps/deployment.go",
            "test": "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
            "release": "1.35.0",
            "testname": "Deployment, status sub-resource",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/disruption.go",
            "test": "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
            "release": "1.35.0",
            "testname": "PodDisruptionBudget: list and delete collection",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/disruption.go",
            "test": "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
            "release": "1.35.0",
            "testname": "PodDisruptionBudget: block an eviction until the PDB is updated to allow it",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": "test/e2e/apps/disruption.go",
            "test": "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
            "release": "1.35.0",
            "testname": "PodDisruptionBudget: create, update, patch, and delete object",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/disruption.go",
            "test": "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
            "release": "1.35.0",
            "testname": "PodDisruptionBudget: Status updates",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/disruption.go",
            "test": "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
            "release": "1.35.0",
            "testname": "PodDisruptionBudget: update and patch status",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
            "release": "1.35.0",
            "testname": "Jobs, orphan pods, re-adoption",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should allow to delegate reconciliation to external controller",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
            "release": "1.35.0",
            "testname": "Ensure pod failure policy allows to ignore failure matching on the DisruptionTarget condition",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
            "release": "1.35.0",
            "testname": "Verify Pod Failure policy allows to fail job early on exit code.",
            "conformance_test": true,
            "promotion_release": "1.31.0"
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should apply changes to a job status [Conformance]",
            "release": "1.35.0",
            "testname": "Jobs, apply changes to status",
            "conformance_test": true,
            "promotion_release": "1.24.0"
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
            "release": "1.35.0",
            "testname": "Ensure Pods of an Indexed Job get a unique index.",
            "conformance_test": true,
            "promotion_release": "1.24.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should delete a job [Conformance]",
            "release": "1.35.0",
            "testname": "Jobs, active pods, graceful termination",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should delete pods when suspended",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
            "release": "1.35.0",
            "testname": "Ensure that all indexes are executed for an indexed job with backoffLimitPerIndex despite some failing",
            "conformance_test": true,
            "promotion_release": "1.33.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should fail to exceed backoffLimit",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] Job should fail when exceeds active deadline",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
            "release": "1.35.0",
            "testname": "Jobs, manage lifecycle",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
            "release": "1.35.0",
            "testname": "Mark indexes as failed when the FailIndex action is matched in podFailurePolicy",
            "conformance_test": true,
            "promotion_release": "1.33.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should not create pods when created in suspend state",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] Job should remove pods when job is deleted",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
            "release": "1.35.0",
            "testname": "Jobs, completion after task failure",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] Job should run a job to completion when tasks succeed",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
            "release": "1.35.0",
            "testname": "Terminate job execution when the maxFailedIndexes is exceeded",
            "conformance_test": true,
            "promotion_release": "1.33.0"
        },
        {
            "file": null,
            "test": "[sig-apps] Job should update the status ready field",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
            "release": "1.35.0",
            "testname": "Ensure that job with successPolicy succeeded when all indexes succeeded",
            "conformance_test": true,
            "promotion_release": "1.33.0"
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
            "release": "1.35.0",
            "testname": "Ensure that job with successPolicy succeededCount rule succeeded even when some indexes remain pending",
            "conformance_test": true,
            "promotion_release": "1.33.0"
        },
        {
            "file": "test/e2e/apps/job.go",
            "test": "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
            "release": "1.35.0",
            "testname": "Ensure that job with successPolicy succeededIndexes rule succeeded even when some indexes remain pending",
            "conformance_test": true,
            "promotion_release": "1.33.0"
        },
        {
            "file": "test/e2e/apps/replica_set.go",
            "test": "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
            "release": "1.35.0",
            "testname": "ReplicaSet, is created, Replaced and Patched",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/replica_set.go",
            "test": "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
            "release": "1.35.0",
            "testname": "ReplicaSet, completes the scaling of a ReplicaSet subresource",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/apps/replica_set.go",
            "test": "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
            "release": "1.35.0",
            "testname": "Replica Set, adopt matching pods and release non matching pods",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/apps/replica_set.go",
            "test": "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
            "release": "1.35.0",
            "testname": "ReplicaSet, list and delete a collection of ReplicaSets",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": null,
            "test": "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/replica_set.go",
            "test": "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
            "release": "1.35.0",
            "testname": "Replica Set, run basic image",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/replica_set.go",
            "test": "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
            "release": "1.35.0",
            "testname": "ReplicaSet, status sub-resource",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": "test/e2e/apps/rc.go",
            "test": "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
            "release": "1.35.0",
            "testname": "Replication Controller, adopt matching pods",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/apps/rc.go",
            "test": "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
            "release": "1.35.0",
            "testname": "Replication Controller, get and update ReplicationController scale",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": "test/e2e/apps/rc.go",
            "test": "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
            "release": "1.35.0",
            "testname": "Replication Controller, release pods",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": null,
            "test": "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/rc.go",
            "test": "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
            "release": "1.35.0",
            "testname": "Replication Controller, run basic image",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apps/rc.go",
            "test": "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
            "release": "1.35.0",
            "testname": "Replication Controller, check for issues like exceeding allocated quota",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/apps/rc.go",
            "test": "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
            "release": "1.35.0",
            "testname": "Replication Controller, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, Burst Scaling",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, Scaling",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet resource Replica scaling",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, list, patch and delete a collection of StatefulSets",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, Rolling Update with Partition",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, Rolling Update",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, Recreate Failed Pod",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/apps/statefulset.go",
            "test": "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
            "release": "1.35.0",
            "testname": "StatefulSet, status sub-resource",
            "conformance_test": true,
            "promotion_release": "1.22.0"
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/architecture/conformance.go",
            "test": "[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]",
            "release": "1.35.0",
            "testname": "Conformance tests minimum number of nodes.",
            "conformance_test": true,
            "promotion_release": "1.23.0"
        },
        {
            "file": null,
            "test": "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/auth/certificates.go",
            "test": "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
            "release": "1.35.0",
            "testname": "CertificateSigningRequest API",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-auth] SelfSubjectReview should support SelfSubjectReview API operations",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
            "release": "1.35.0",
            "testname": "OIDC Discovery (ServiceAccountIssuerDiscovery)",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
            "release": "1.35.0",
            "testname": "Service account tokens auto mount optionally",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
            "release": "1.35.0",
            "testname": "ServiceAccount, create and review token",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
            "release": "1.35.0",
            "testname": "RootCA ConfigMap test",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
            "release": "1.35.0",
            "testname": "Service Account Tokens Must AutoMount",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
            "release": "1.35.0",
            "testname": "TokenRequestProjection should mount a projected volume with token using TokenRequest API.",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
            "release": "1.35.0",
            "testname": "ServiceAccount lifecycle test",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/auth/service_accounts.go",
            "test": "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
            "release": "1.35.0",
            "testname": "ServiceAccount, update a ServiceAccount",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": "test/e2e/auth/subjectreviews.go",
            "test": "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
            "release": "1.35.0",
            "testname": "SubjectReview, API Operations",
            "conformance_test": true,
            "promotion_release": "1.27.0"
        },
        {
            "file": null,
            "test": "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, guestbook application",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, check version v1",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl apply apply set/view last-applied",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, cluster info",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, describe pod or rc",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, diff Deployment",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, create service, replication controller",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, label update",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, patch to annotate",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, replace",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, run pod",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, server-side dry-run Pod",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client kubectl subresource flag GET on status subresource of built-in type (node) returns identical info as GET on the built-in type",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client kubectl subresource flag should not be used in a bulk GET",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields of a typed object",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, version",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client kubectl wait should ignore not found error with",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Proxy server should support",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Proxy server should support proxy with",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should contain last line of the log",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should support exec",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, replication controller",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/kubectl/kubectl.go",
            "test": "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, scale replication controller",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl delete interactive based on user confirmation input",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] kubectl kuberc given preferences should be applied",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] kubectl kuberc given preferences should be ignored when flags are explicitly passed",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/kubectl/logs.go",
            "test": "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
            "release": "1.35.0",
            "testname": "Kubectl, logs",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/instrumentation/events.go",
            "test": "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
            "release": "1.35.0",
            "testname": "New Event resource lifecycle, testing a list of events",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/instrumentation/events.go",
            "test": "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
            "release": "1.35.0",
            "testname": "New Event resource lifecycle, testing a single event",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/instrumentation/core_events.go",
            "test": "[sig-instrumentation] Events should delete a collection of events [Conformance]",
            "release": "1.35.0",
            "testname": "Event, delete a collection",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/instrumentation/core_events.go",
            "test": "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
            "release": "1.35.0",
            "testname": "Event, manage lifecycle of an Event",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": null,
            "test": "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, for ExternalName Services",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, resolve the hostname",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, resolve the subdomain",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should provide DNS for services [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, services",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should provide DNS for the cluster [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, cluster",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, cluster",
            "conformance_test": true,
            "promotion_release": "1.14.0"
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, PQDN for services",
            "conformance_test": true,
            "promotion_release": "1.17.0"
        },
        {
            "file": null,
            "test": "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/dns.go",
            "test": "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
            "release": "1.35.0",
            "testname": "DNS, custom dnsConfig",
            "conformance_test": true,
            "promotion_release": "1.17.0"
        },
        {
            "file": null,
            "test": "[sig-network] DNS should support configurable pod resolv.conf",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/endpointslicemirroring.go",
            "test": "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice Mirroring",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/endpointslice.go",
            "test": "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice API",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/network/endpointslice.go",
            "test": "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice API",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/network/endpointslice.go",
            "test": "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice API",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/network/endpointslice.go",
            "test": "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice, multiple IPs, multiple ports",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": "test/e2e/network/endpointslice.go",
            "test": "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice, single IP, multiple ports",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": "test/e2e/network/endpointslice.go",
            "test": "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
            "release": "1.35.0",
            "testname": "EndpointSlice API",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/network/hostport.go",
            "test": "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduling, HostPort matching and HostIP and Protocol not-matching",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/network/ingress.go",
            "test": "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
            "release": "1.35.0",
            "testname": "Ingress API",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/network/ingressclass.go",
            "test": "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
            "release": "1.35.0",
            "testname": "IngressClass API",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Netpol API should support creating NetworkPolicy API operations",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/network/networking.go",
            "test": "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Networking, intra pod http",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": "test/e2e/common/network/networking.go",
            "test": "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Networking, intra pod udp",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": "test/e2e/common/network/networking.go",
            "test": "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Networking, intra pod http, from node",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/network/networking.go",
            "test": "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Networking, intra pod http, from node",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should update endpoints: http",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking should check kube-proxy urls",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/proxy.go",
            "test": "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
            "release": "1.35.0",
            "testname": "Proxy, validate Proxy responses",
            "conformance_test": true,
            "promotion_release": "1.24.0"
        },
        {
            "file": "test/e2e/network/proxy.go",
            "test": "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
            "release": "1.35.0",
            "testname": "Proxy, validate ProxyWithPath responses",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/proxy.go",
            "test": "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
            "release": "1.35.0",
            "testname": "Proxy through apiserver to a Service",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/network/service_cidrs.go",
            "test": "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
            "release": "1.35.0",
            "testname": "IPAddress API",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": "test/e2e/network/service_cidrs.go",
            "test": "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
            "release": "1.35.0",
            "testname": "ServiceCIDR API",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": null,
            "test": "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service_latency.go",
            "test": "[sig-network] Service endpoints latency should not be very high [Conformance]",
            "release": "1.35.0",
            "testname": "Service endpoint latency, thresholds",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should allow pods to hairpin back to themselves through services",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
            "release": "1.35.0",
            "testname": "Service, change type, ClusterIP to ExternalName",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
            "release": "1.35.0",
            "testname": "Service, change type, ExternalName to ClusterIP",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
            "release": "1.35.0",
            "testname": "Service, change type, ExternalName to NodePort",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
            "release": "1.35.0",
            "testname": "Service, change type, NodePort to ExternalName",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
            "release": "1.35.0",
            "testname": "Service, NodePort Service",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Service, NodePort type, session affinity to None",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Service, ClusterIP type, session affinity to None",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should be able to up and down services",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should be rejected when no endpoints exist",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should be updated after adding or deleting ports",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should check NodePort out-of-range",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should complete a service status lifecycle [Conformance]",
            "release": "1.35.0",
            "testname": "Service, complete ServiceStatus lifecycle",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should connect to the named ports exposed by restartable init containers",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should connect to the ports exposed by restartable init containers",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should create endpoints for unready pods",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should delete a collection of services [Conformance]",
            "release": "1.35.0",
            "testname": "Service, deletes a collection of services",
            "conformance_test": true,
            "promotion_release": "1.23.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should fail health check node port if there are only terminating endpoints",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should find a service from listing all namespaces [Conformance]",
            "release": "1.35.0",
            "testname": "Find Kubernetes Service in default Namespace",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Service, NodePort type, session affinity to ClientIP",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Service, ClusterIP type, session affinity to ClientIP",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should implement service.kubernetes.io/headless",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should prevent NodePort collisions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should provide secure master service [Conformance]",
            "release": "1.35.0",
            "testname": "Kubernetes Service",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should release NodePorts on delete",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
            "release": "1.35.0",
            "testname": "Service, endpoints",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
            "release": "1.35.0",
            "testname": "Service, should serve endpoints on same port and different protocols.",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
            "release": "1.35.0",
            "testname": "Service, endpoints with multiple ports",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/network/service.go",
            "test": "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
            "release": "1.35.0",
            "testname": "Endpoint resource lifecycle",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-network] Services should work after the service has been recreated",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Topology Hints should distribute endpoints evenly",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferClose",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferClose",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node or fall back to same zone when using PreferSameNode [FeatureGate:PreferSameTrafficDistribution] [Beta]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node when using PreferSameNode and fall back when the endpoint becomes unavailable [FeatureGate:PreferSameTrafficDistribution] [Beta]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/configmap.go",
            "test": "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap, from environment field with various prefixes",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": "test/e2e/common/node/configmap.go",
            "test": "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap, from environment field",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/configmap.go",
            "test": "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap, from environment variables",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/configmap.go",
            "test": "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap, with empty-key",
            "conformance_test": true,
            "promotion_release": "1.14.0"
        },
        {
            "file": "test/e2e/common/node/configmap.go",
            "test": "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap lifecycle",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/configmap.go",
            "test": "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Update",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/common/node/lifecycle_hook.go",
            "test": "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod Lifecycle, post start exec hook",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/lifecycle_hook.go",
            "test": "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod Lifecycle, post start http hook",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/lifecycle_hook.go",
            "test": "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod Lifecycle, prestop exec hook",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/lifecycle_hook.go",
            "test": "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod Lifecycle, prestop http hook",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/runtime.go",
            "test": "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Container Runtime, TerminationMessage, from log output of succeeding container",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/common/node/runtime.go",
            "test": "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Container Runtime, TerminationMessage, from file of succeeding container",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/common/node/runtime.go",
            "test": "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Container Runtime, TerminationMessage, from container's log output of failing container",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/common/node/runtime.go",
            "test": "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Container Runtime, TerminationMessagePath, non-root user and non-default path",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": null,
            "test": "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/runtime.go",
            "test": "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Container Runtime, Restart Policy, Pod Phases",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/containers.go",
            "test": "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Containers, with arguments",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/containers.go",
            "test": "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Containers, with command and arguments",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/containers.go",
            "test": "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Containers, with command",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/containers.go",
            "test": "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Containers, without command and arguments",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] crictl should be able to run crictl on the node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/downwardapi.go",
            "test": "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI, environment for CPU and memory limits and requests",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/downwardapi.go",
            "test": "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI, environment for default CPU and memory limits and requests",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/downwardapi.go",
            "test": "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI, environment for host ip",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/downwardapi.go",
            "test": "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI, environment for hostIPs",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/common/node/downwardapi.go",
            "test": "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI, environment for name, namespace and ip",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/downwardapi.go",
            "test": "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI, environment for Pod UID",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/ephemeral_containers.go",
            "test": "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
            "release": "1.35.0",
            "testname": "Ephemeral Container, update ephemeral containers",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/common/node/ephemeral_containers.go",
            "test": "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
            "release": "1.35.0",
            "testname": "Ephemeral Container Creation",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": null,
            "test": "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/init_container.go",
            "test": "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
            "release": "1.35.0",
            "testname": "init-container-starts-app-restartalways-pod",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/common/node/init_container.go",
            "test": "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
            "release": "1.35.0",
            "testname": "init-container-starts-app-restartnever-pod",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/common/node/init_container.go",
            "test": "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
            "release": "1.35.0",
            "testname": "init-container-fails-stops-app-restartnever-pod",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/common/node/init_container.go",
            "test": "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
            "release": "1.35.0",
            "testname": "init-container-fails-stops-app-restartalways-pod",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": null,
            "test": "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/kubelet_etc_hosts.go",
            "test": "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Kubelet, managed etc hosts",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/kubelet.go",
            "test": "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Kubelet, log output, default",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/kubelet.go",
            "test": "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Kubelet, failed pod, delete",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/kubelet.go",
            "test": "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Kubelet, failed pod, terminated reason",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/kubelet.go",
            "test": "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Kubelet, hostAliases",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/kubelet.go",
            "test": "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Kubelet, pod with read only root file system",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": null,
            "test": "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/lease.go",
            "test": "[sig-node] Lease lease API should be available [Conformance]",
            "release": "1.35.0",
            "testname": "lease API should be available",
            "conformance_test": true,
            "promotion_release": "1.17.0"
        },
        {
            "file": null,
            "test": "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Mount propagation should propagate mounts within defined scopes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] NodeLease NodeLease should have OwnerReferences set",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/node/node_lifecycle.go",
            "test": "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
            "release": "1.35.0",
            "testname": "Node, resource lifecycle",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/node/taints.go",
            "test": "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod Eviction, Toleration limits",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/node/taints.go",
            "test": "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
            "release": "1.35.0",
            "testname": "Taint, Pod Eviction on taint removal",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/node/pods.go",
            "test": "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, QOS",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, ActiveDeadlineSeconds",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, update",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, service environment variables",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should delete a collection of pods [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, delete a collection",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, assigned hostip",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should patch a pod status [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, patching status",
            "conformance_test": true,
            "promotion_release": "1.25.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, completes the lifecycle of a Pod and the PodStatus",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": null,
            "test": "[sig-node] Pods should support pod readiness gates [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, remote command execution over websocket",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/pods.go",
            "test": "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, logs from websockets",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/common/node/podtemplates.go",
            "test": "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
            "release": "1.35.0",
            "testname": "PodTemplate, delete a collection",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/podtemplates.go",
            "test": "[sig-node] PodTemplates should replace a pod template [Conformance]",
            "release": "1.35.0",
            "testname": "PodTemplate, replace",
            "conformance_test": true,
            "promotion_release": "1.24.0"
        },
        {
            "file": "test/e2e/common/node/podtemplates.go",
            "test": "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
            "release": "1.35.0",
            "testname": "PodTemplate lifecycle",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": null,
            "test": "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/node/pre_stop.go",
            "test": "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
            "release": "1.35.0",
            "testname": "Pods, prestop hook",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should be restarted startup probe fails",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using local file, restart",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using grpc call, failure",
            "conformance_test": true,
            "promotion_release": "1.23.0"
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using http endpoint, restart",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using http endpoint, multiple restarts (slow)",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using local file, no restart",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using grpc call, success",
            "conformance_test": true,
            "promotion_release": "1.23.0"
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using http endpoint, failure",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod liveness probe, using tcp socket, no restart",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod readiness probe, with initial delay",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/container_probe.go",
            "test": "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod readiness probe, failure",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/runtimeclass.go",
            "test": "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod with the deleted RuntimeClass is rejected.",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/common/node/runtimeclass.go",
            "test": "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Pod with the non-existing RuntimeClass is rejected.",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": null,
            "test": "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/runtimeclass.go",
            "test": "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "RuntimeClass Overhead field must be respected.",
            "conformance_test": true,
            "promotion_release": "1.24.0"
        },
        {
            "file": "test/e2e/common/node/runtimeclass.go",
            "test": "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Can schedule a pod requesting existing RuntimeClass.",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/common/node/runtimeclass.go",
            "test": "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
            "release": "1.35.0",
            "testname": "RuntimeClass API",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/common/node/secrets.go",
            "test": "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets, pod environment from source",
            "conformance_test": true,
            "promotion_release": "1.34.0"
        },
        {
            "file": "test/e2e/common/node/secrets.go",
            "test": "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets, pod environment field",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/secrets.go",
            "test": "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets, pod environment from source",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/secrets.go",
            "test": "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets, with empty-key",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/common/node/secrets.go",
            "test": "[sig-node] Secrets should patch a secret [Conformance]",
            "release": "1.35.0",
            "testname": "Secret patching",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": "test/e2e/node/security_context.go",
            "test": "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Security Context, test RunAsGroup at container level",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/node/security_context.go",
            "test": "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
            "release": "1.35.0",
            "testname": "Security Context, test RunAsGroup at pod level",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/security_context.go",
            "test": "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Security Context, runAsUser=65534",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/common/node/security_context.go",
            "test": "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Security Context, privileged=false.",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": null,
            "test": "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/security_context.go",
            "test": "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Security Context, readOnlyRootFilesystem=false.",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": null,
            "test": "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/security_context.go",
            "test": "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Security Context, allowPrivilegeEscalation=false.",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": null,
            "test": "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] SSH should SSH to all nodes and run commands",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/sysctl.go",
            "test": "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
            "release": "1.35.0",
            "testname": "Sysctls, reject invalid sysctls",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/common/node/sysctl.go",
            "test": "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
            "release": "1.35.0",
            "testname": "Sysctl, test sysctls",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": null,
            "test": "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Environment variables, expansion",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Environment variables, command argument expansion",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Environment variables, command expansion",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeSubpathEnvExpansion, subpath expansion",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeSubpathEnvExpansion, subpath with absolute path",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeSubpathEnvExpansion, subpath with backticks",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeSubpathEnvExpansion, subpath test writes",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/common/node/expansion.go",
            "test": "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeSubpathEnvExpansion, subpath ready from failed state",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/scheduling/limit_range.go",
            "test": "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
            "release": "1.35.0",
            "testname": "LimitRange, resources",
            "conformance_test": true,
            "promotion_release": "1.18.0"
        },
        {
            "file": "test/e2e/scheduling/limit_range.go",
            "test": "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
            "release": "1.35.0",
            "testname": "LimitRange, list, patch and delete a LimitRange by collection",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": "test/e2e/scheduling/predicates.go",
            "test": "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduler, resource limits",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/scheduling/predicates.go",
            "test": "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduler, node selector matching",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/scheduling/predicates.go",
            "test": "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduler, node selector not matching",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/scheduling/predicates.go",
            "test": "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduling, HostPort and Protocol match, HostIPs different but one is default HostIP (0.0.0.0)",
            "conformance_test": true,
            "promotion_release": "1.16.0"
        },
        {
            "file": "test/e2e/scheduling/preemption.go",
            "test": "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
            "release": "1.35.0",
            "testname": "Pod preemption verification",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/scheduling/preemption.go",
            "test": "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduler, Verify PriorityClass endpoints",
            "conformance_test": true,
            "promotion_release": "1.20.0"
        },
        {
            "file": "test/e2e/scheduling/preemption.go",
            "test": "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduler, Basic Preemption",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/scheduling/preemption.go",
            "test": "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
            "release": "1.35.0",
            "testname": "Scheduler, Preemption for critical pod",
            "conformance_test": true,
            "promotion_release": "1.19.0"
        },
        {
            "file": "test/e2e/scheduling/preemption.go",
            "test": "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
            "release": "1.35.0",
            "testname": "Verify the DisruptionTarget condition is added to the preempted pod",
            "conformance_test": true,
            "promotion_release": "1.31.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, text data, binary data",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, create, update and delete",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, without mapping, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, without mapping",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, without mapping, volume mode set",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, with mapping, volume mode set",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, with mapping, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, with mapping",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, multiple volume maps",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, immutability",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/common/storage/configmap_volume.go",
            "test": "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "ConfigMap Volume, update",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/storage/csi_inline.go",
            "test": "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
            "release": "1.35.0",
            "testname": "CSIDriver, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.28.0"
        },
        {
            "file": "test/e2e/storage/csi_inline.go",
            "test": "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
            "release": "1.35.0",
            "testname": "CSIInlineVolumes should support Pods with inline volumes",
            "conformance_test": true,
            "promotion_release": "1.26.0"
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/storage/csi_node.go",
            "test": "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
            "release": "1.35.0",
            "testname": "CSINode, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/storage/csistoragecapacity.go",
            "test": "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
            "release": "1.35.0",
            "testname": "CSIStorageCapacity API",
            "conformance_test": true,
            "promotion_release": "1.24.0"
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should mount multiple PV pointing to the same storage on the same node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with mount options",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source (ROX mode)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, CPU limits",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, CPU request",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, memory limits",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, memory request",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, CPU limit, default node allocatable",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, memory limit, default node allocatable",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, pod name",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, file mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, update annotations",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/downwardapi_volume.go",
            "test": "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "DownwardAPI volume, update label",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, Shared volumes between containers",
            "conformance_test": true,
            "promotion_release": "1.15.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode 0644",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode 0644, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode 0666",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode 0666,, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode 0777",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode 0777, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode 0644",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode 0644",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode 0666",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode 0666",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode 0777",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode 0777",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium default, volume mode default",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/empty_dir.go",
            "test": "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir, medium memory, volume mode default",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/storage/empty_dir_wrapper.go",
            "test": "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir Wrapper Volume, ConfigMap volumes, no race",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": "test/e2e/storage/empty_dir_wrapper.go",
            "test": "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
            "release": "1.35.0",
            "testname": "EmptyDir Wrapper Volume, Secret and ConfigMap volumes, no conflict",
            "conformance_test": true,
            "promotion_release": "1.13.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] Flexvolumes should be mountable when non-attachable",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] HostPath should support r/w [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] HostPath should support subPath [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/storage/persistent_volumes.go",
            "test": "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
            "release": "1.35.0",
            "testname": "PersistentVolumes(Claims), apply changes to a pv/pvc status",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": "test/e2e/storage/persistent_volumes.go",
            "test": "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
            "release": "1.35.0",
            "testname": "PersistentVolumes(Claims), lifecycle",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/projected_combined.go",
            "test": "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, multiple projections",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, create, update and delete",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, volume mode default",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, mapped, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, mapped, non-root user",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, mapped",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, multiple volume paths",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_configmap.go",
            "test": "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, ConfigMap, update",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, CPU limits",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, CPU request",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, memory limits",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, memory request",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, CPU limit, node allocatable",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, memory limit, node allocatable",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, pod name",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, update annotation",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_downwardapi.go",
            "test": "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, DownwardAPI, update labels",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, Secrets, create, update delete",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Project Volume, Secrets, non-root, custom fsGroup",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, Secrets, volume mode default",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, Secrets, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, Secrets, mapped, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, Secrets, mapped",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/projected_secret.go",
            "test": "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Projected Volume, Secrets, mapped, multiple paths",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": null,
            "test": "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": null,
            "test": "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, create, update and delete",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, volume mode default, secret with same name in different namespace",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, volume mode 0440, fsGroup 1001 and uid 1000",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, default",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, mapping, volume mode 0400",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, mapping",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, mapping multiple volume paths",
            "conformance_test": true,
            "promotion_release": "1.9.0"
        },
        {
            "file": "test/e2e/common/storage/secrets_volume.go",
            "test": "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
            "release": "1.35.0",
            "testname": "Secrets Volume, immutability",
            "conformance_test": true,
            "promotion_release": "1.21.0"
        },
        {
            "file": "test/e2e/storage/storageclass.go",
            "test": "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
            "release": "1.35.0",
            "testname": "StorageClass, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.29.0"
        },
        {
            "file": "test/e2e/storage/subpath.go",
            "test": "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
            "release": "1.35.0",
            "testname": "SubPath: Reading content from a configmap volume.",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/storage/subpath.go",
            "test": "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
            "release": "1.35.0",
            "testname": "SubPath: Reading content from a configmap volume.",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/storage/subpath.go",
            "test": "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
            "release": "1.35.0",
            "testname": "SubPath: Reading content from a downwardAPI volume.",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/storage/subpath.go",
            "test": "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
            "release": "1.35.0",
            "testname": "SubPath: Reading content from a projected volume.",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": "test/e2e/storage/subpath.go",
            "test": "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
            "release": "1.35.0",
            "testname": "SubPath: Reading content from a secret volume.",
            "conformance_test": true,
            "promotion_release": "1.12.0"
        },
        {
            "file": null,
            "test": "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
            "release": "1.35.0",
            "testname": null,
            "conformance_test": false,
            "promotion_release": null
        },
        {
            "file": "test/e2e/storage/volume_attachment.go",
            "test": "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeAttachment, apply changes to a volumeattachment status",
            "conformance_test": true,
            "promotion_release": "1.32.0"
        },
        {
            "file": "test/e2e/storage/volume_attachment.go",
            "test": "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeAttachment, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.30.0"
        },
        {
            "file": "test/e2e/storage/volumeattributesclass.go",
            "test": "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
            "release": "1.35.0",
            "testname": "VolumeAttributesClass, lifecycle",
            "conformance_test": true,
            "promotion_release": "1.35.0"
        }
    ],
    "release": "1.35.0",
    "sources": [
        "https://prow.k8s.io/view/gcs/kubernetes-ci-logs/logs/ci-kubernetes-audit-kind-conformance/1974377016555737088",
        "https://prow.k8s.io/view/gcs/kubernetes-ci-logs/logs/ci-kubernetes-e2e-gci-gce/1974430116943499264",
        "https://prow.k8s.io/view/gcs/kubernetes-ci-logs/logs/ci-kubernetes-gce-conformance-latest/1974398910587736064"
    ],
    "endpoints": [
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1DeleteNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect DELETE requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1DeleteNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect DELETE requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1DeleteNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect DELETE requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1DeleteNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect DELETE requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1DeleteNodeProxy",
            "conf_tested": false,
            "description": "connect DELETE requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1DeleteNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect DELETE requests to proxy of Node"
        },
        {
            "kind": "PodAttachOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/attach",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedPodAttach",
            "conf_tested": false,
            "description": "connect GET requests to attach of Pod"
        },
        {
            "kind": "PodExecOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/exec",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                null
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedPodExec",
            "conf_tested": true,
            "description": "connect GET requests to exec of Pod"
        },
        {
            "kind": "PodPortForwardOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/portforward",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                null
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedPodPortforward",
            "conf_tested": true,
            "description": "connect GET requests to portforward of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Services should create endpoints for unready pods"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect GET requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
                "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect GET requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect GET requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect GET requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNodeProxy",
            "conf_tested": false,
            "description": "connect GET requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
                "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1GetNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect GET requests to proxy of Node"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1HeadNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect HEAD requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1HeadNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect HEAD requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1HeadNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect HEAD requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1HeadNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect HEAD requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1HeadNodeProxy",
            "conf_tested": false,
            "description": "connect HEAD requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1HeadNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect HEAD requests to proxy of Node"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1OptionsNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect OPTIONS requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1OptionsNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect OPTIONS requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1OptionsNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect OPTIONS requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1OptionsNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect OPTIONS requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1OptionsNodeProxy",
            "conf_tested": false,
            "description": "connect OPTIONS requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1OptionsNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect OPTIONS requests to proxy of Node"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PatchNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect PATCH requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PatchNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect PATCH requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PatchNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect PATCH requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PatchNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect PATCH requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PatchNodeProxy",
            "conf_tested": false,
            "description": "connect PATCH requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PatchNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect PATCH requests to proxy of Node"
        },
        {
            "kind": "PodAttachOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/attach",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedPodAttach",
            "conf_tested": false,
            "description": "connect POST requests to attach of Pod"
        },
        {
            "kind": "PodExecOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/exec",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedPodExec",
            "conf_tested": false,
            "description": "connect POST requests to exec of Pod"
        },
        {
            "kind": "PodPortForwardOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/portforward",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedPodPortforward",
            "conf_tested": false,
            "description": "connect POST requests to portforward of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect POST requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect POST requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect POST requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect POST requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNodeProxy",
            "conf_tested": false,
            "description": "connect POST requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PostNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect POST requests to proxy of Node"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PutNamespacedPodProxy",
            "conf_tested": true,
            "description": "connect PUT requests to proxy of Pod"
        },
        {
            "kind": "PodProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PutNamespacedPodProxyWithPath",
            "conf_tested": true,
            "description": "connect PUT requests to proxy of Pod"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PutNamespacedServiceProxy",
            "conf_tested": true,
            "description": "connect PUT requests to proxy of Service"
        },
        {
            "kind": "ServiceProxyOptions",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]"
            ],
            "action": "connect",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PutNamespacedServiceProxyWithPath",
            "conf_tested": true,
            "description": "connect PUT requests to proxy of Service"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PutNodeProxy",
            "conf_tested": false,
            "description": "connect PUT requests to proxy of Node"
        },
        {
            "kind": "NodeProxyOptions",
            "path": "/api/v1/nodes/{name}/proxy/{path}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "connect",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "connectCoreV1PutNodeProxyWithPath",
            "conf_tested": false,
            "description": "connect PUT requests to proxy of Node"
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1MutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "create a MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1ValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "create a ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1ValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "create a ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1ValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "create a ValidatingWebhookConfiguration"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "createApiextensionsV1CustomResourceDefinition",
            "conf_tested": true,
            "description": "create a CustomResourceDefinition"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "createApiregistrationV1APIService",
            "conf_tested": true,
            "description": "create an APIService"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "createAppsV1NamespacedControllerRevision",
            "conf_tested": true,
            "description": "create a ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "createAppsV1NamespacedDaemonSet",
            "conf_tested": true,
            "description": "create a DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should work after the service has been recreated",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "createAppsV1NamespacedDeployment",
            "conf_tested": true,
            "description": "create a Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "createAppsV1NamespacedReplicaSet",
            "conf_tested": true,
            "description": "create a ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "createAppsV1NamespacedStatefulSet",
            "conf_tested": true,
            "description": "create a StatefulSet"
        },
        {
            "kind": "SelfSubjectReview",
            "path": "/apis/authentication.k8s.io/v1/selfsubjectreviews",
            "group": "authentication.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "authentication",
            "endpoint": "createAuthenticationV1SelfSubjectReview",
            "conf_tested": false,
            "description": "create a SelfSubjectReview"
        },
        {
            "kind": "TokenReview",
            "path": "/apis/authentication.k8s.io/v1/tokenreviews",
            "group": "authentication.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "authentication",
            "endpoint": "createAuthenticationV1TokenReview",
            "conf_tested": true,
            "description": "create a TokenReview"
        },
        {
            "kind": "LocalSubjectAccessReview",
            "path": "/apis/authorization.k8s.io/v1/namespaces/{namespace}/localsubjectaccessreviews",
            "group": "authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "authorization",
            "endpoint": "createAuthorizationV1NamespacedLocalSubjectAccessReview",
            "conf_tested": true,
            "description": "create a LocalSubjectAccessReview"
        },
        {
            "kind": "SelfSubjectAccessReview",
            "path": "/apis/authorization.k8s.io/v1/selfsubjectaccessreviews",
            "group": "authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "authorization",
            "endpoint": "createAuthorizationV1SelfSubjectAccessReview",
            "conf_tested": true,
            "description": "create a SelfSubjectAccessReview"
        },
        {
            "kind": "SelfSubjectRulesReview",
            "path": "/apis/authorization.k8s.io/v1/selfsubjectrulesreviews",
            "group": "authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "authorization",
            "endpoint": "createAuthorizationV1SelfSubjectRulesReview",
            "conf_tested": false,
            "description": "create a SelfSubjectRulesReview"
        },
        {
            "kind": "SubjectAccessReview",
            "path": "/apis/authorization.k8s.io/v1/subjectaccessreviews",
            "group": "authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "authorization",
            "endpoint": "createAuthorizationV1SubjectAccessReview",
            "conf_tested": true,
            "description": "create a SubjectAccessReview"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "createAutoscalingV1NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "create a HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "createAutoscalingV2NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "create a HorizontalPodAutoscaler"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-apps] CronJob should support timezone",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "createBatchV1NamespacedCronJob",
            "conf_tested": true,
            "description": "create a CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "createBatchV1NamespacedJob",
            "conf_tested": true,
            "description": "create a Job"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "createCertificatesV1CertificateSigningRequest",
            "conf_tested": true,
            "description": "create a CertificateSigningRequest"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "createCoordinationV1NamespacedLease",
            "conf_tested": true,
            "description": "create a Lease"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (fairness)",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (priority)",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-api-machinery] health handlers should contain necessary checks",
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] OpenAPIV3 should round trip OpenAPI V3 for all built-in group versions",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] Server request timeout default timeout should be used if the specified timeout in the request URL is 0s",
                "[sig-api-machinery] Server request timeout should return HTTP status code 400 if the user specifies an invalid timeout in the request URL",
                "[sig-api-machinery] Server request timeout the request should be served with a default timeout if the specified timeout in the request URL exceeds maximum allowed",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-api-machinery] server version should find the server version [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-apps] CronJob should support timezone",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                "[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] SelfSubjectReview should support SelfSubjectReview API operations",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance]",
                "[sig-cli] Kubectl client Kubectl apply apply set/view last-applied",
                "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
                "[sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC",
                "[sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds",
                "[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance]",
                "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
                "[sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
                "[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]",
                "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses",
                "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
                "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
                "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
                "[sig-cli] Kubectl client kubectl subresource flag GET on status subresource of built-in type (node) returns identical info as GET on the built-in type",
                "[sig-cli] Kubectl client kubectl subresource flag should not be used in a bulk GET",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields of a typed object",
                "[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance]",
                "[sig-cli] Kubectl client kubectl wait should ignore not found error with",
                "[sig-cli] Kubectl client Proxy server should support",
                "[sig-cli] Kubectl client Proxy server should support proxy with",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
                "[sig-cli] Kubectl client Simple pod should contain last line of the log",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
                "[sig-cli] Kubectl client Simple pod should support exec",
                "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
                "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
                "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
                "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl delete interactive based on user confirmation input",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] kubectl kuberc given preferences should be applied",
                "[sig-cli] kubectl kuberc given preferences should be ignored when flags are explicitly passed",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
                "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should delete a collection of services [Conformance]",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should find a service from listing all namespaces [Conformance]",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should provide secure master service [Conformance]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-network] Topology Hints should distribute endpoints evenly",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node or fall back to same zone when using PreferSameNode [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node when using PreferSameNode and fall back when the endpoint becomes unavailable [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NodeLease NodeLease should have OwnerReferences set",
                "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] SSH should SSH to all nodes and run commands",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
                "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
                "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1Namespace",
            "conf_tested": true,
            "description": "create a Namespace"
        },
        {
            "kind": "Binding",
            "path": "/api/v1/namespaces/{namespace}/bindings",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedBinding",
            "conf_tested": false,
            "description": "create a Binding"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedConfigMap",
            "conf_tested": true,
            "description": "create a ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedEndpoints",
            "conf_tested": true,
            "description": "create Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedEvent",
            "conf_tested": true,
            "description": "create an Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedLimitRange",
            "conf_tested": true,
            "description": "create a LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "create a PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedPod",
            "conf_tested": true,
            "description": "create a Pod"
        },
        {
            "kind": "Binding",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/binding",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedPodBinding",
            "conf_tested": true,
            "description": "create binding of a Pod"
        },
        {
            "kind": "Eviction",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/eviction",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedPodEviction",
            "conf_tested": true,
            "description": "create eviction of a Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedPodTemplate",
            "conf_tested": true,
            "description": "create a PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedReplicationController",
            "conf_tested": true,
            "description": "create a ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedResourceQuota",
            "conf_tested": true,
            "description": "create a ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedSecret",
            "conf_tested": true,
            "description": "create a Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should delete a collection of services [Conformance]",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedService",
            "conf_tested": true,
            "description": "create a Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedServiceAccount",
            "conf_tested": true,
            "description": "create a ServiceAccount"
        },
        {
            "kind": "TokenRequest",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts/{name}/token",
            "group": "authentication.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1NamespacedServiceAccountToken",
            "conf_tested": true,
            "description": "create token of a ServiceAccount"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1Node",
            "conf_tested": true,
            "description": "create a Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "createCoreV1PersistentVolume",
            "conf_tested": true,
            "description": "create a PersistentVolume"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "createDiscoveryV1NamespacedEndpointSlice",
            "conf_tested": true,
            "description": "create an EndpointSlice"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "createEventsV1NamespacedEvent",
            "conf_tested": true,
            "description": "create an Event"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "createFlowcontrolApiserverV1FlowSchema",
            "conf_tested": true,
            "description": "create a FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "createFlowcontrolApiserverV1PriorityLevelConfiguration",
            "conf_tested": true,
            "description": "create a PriorityLevelConfiguration"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "createNetworkingV1IngressClass",
            "conf_tested": true,
            "description": "create an IngressClass"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "createNetworkingV1IPAddress",
            "conf_tested": true,
            "description": "create an IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "createNetworkingV1NamespacedIngress",
            "conf_tested": true,
            "description": "create an Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "createNetworkingV1NamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "create a NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "createNetworkingV1ServiceCIDR",
            "conf_tested": false,
            "description": "create a ServiceCIDR"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "createNodeV1RuntimeClass",
            "conf_tested": true,
            "description": "create a RuntimeClass"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "createPolicyV1NamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "create a PodDisruptionBudget"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "createRbacAuthorizationV1ClusterRole",
            "conf_tested": true,
            "description": "create a ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "createRbacAuthorizationV1ClusterRoleBinding",
            "conf_tested": true,
            "description": "create a ClusterRoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "createRbacAuthorizationV1NamespacedRole",
            "conf_tested": false,
            "description": "create a Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "createRbacAuthorizationV1NamespacedRoleBinding",
            "conf_tested": true,
            "description": "create a RoleBinding"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "createResourceV1DeviceClass",
            "conf_tested": false,
            "description": "create a DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "createResourceV1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "create a ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "createResourceV1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "create a ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "createResourceV1ResourceSlice",
            "conf_tested": false,
            "description": "create a ResourceSlice"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "createSchedulingV1PriorityClass",
            "conf_tested": true,
            "description": "create a PriorityClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "createStorageV1CSIDriver",
            "conf_tested": true,
            "description": "create a CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "createStorageV1CSINode",
            "conf_tested": true,
            "description": "create a CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "createStorageV1NamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "create a CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "createStorageV1StorageClass",
            "conf_tested": true,
            "description": "create a StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                null
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "createStorageV1VolumeAttachment",
            "conf_tested": true,
            "description": "create a VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]"
            ],
            "action": "post",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "createStorageV1VolumeAttributesClass",
            "conf_tested": true,
            "description": "create a VolumeAttributesClass"
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1CollectionMutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "delete collection of MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1CollectionValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "delete collection of ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1CollectionValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "delete collection of ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1CollectionValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "delete collection of ValidatingWebhookConfiguration"
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1MutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "delete a MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1ValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "delete a ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1ValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "delete a ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1ValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "delete a ValidatingWebhookConfiguration"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "deleteApiextensionsV1CollectionCustomResourceDefinition",
            "conf_tested": true,
            "description": "delete collection of CustomResourceDefinition"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "deleteApiextensionsV1CustomResourceDefinition",
            "conf_tested": true,
            "description": "delete a CustomResourceDefinition"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "deleteApiregistrationV1APIService",
            "conf_tested": true,
            "description": "delete an APIService"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "deleteApiregistrationV1CollectionAPIService",
            "conf_tested": true,
            "description": "delete collection of APIService"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1CollectionNamespacedControllerRevision",
            "conf_tested": true,
            "description": "delete collection of ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1CollectionNamespacedDaemonSet",
            "conf_tested": true,
            "description": "delete collection of DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1CollectionNamespacedDeployment",
            "conf_tested": true,
            "description": "delete collection of Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1CollectionNamespacedReplicaSet",
            "conf_tested": true,
            "description": "delete collection of ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1CollectionNamespacedStatefulSet",
            "conf_tested": true,
            "description": "delete collection of StatefulSet"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1NamespacedControllerRevision",
            "conf_tested": true,
            "description": "delete a ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1NamespacedDaemonSet",
            "conf_tested": true,
            "description": "delete a DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should work after the service has been recreated",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1NamespacedDeployment",
            "conf_tested": true,
            "description": "delete a Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1NamespacedReplicaSet",
            "conf_tested": true,
            "description": "delete a ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "deleteAppsV1NamespacedStatefulSet",
            "conf_tested": true,
            "description": "delete a StatefulSet"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "deleteAutoscalingV1CollectionNamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "delete collection of HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "deleteAutoscalingV1NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "delete a HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "deleteAutoscalingV2CollectionNamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "delete collection of HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "deleteAutoscalingV2NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "delete a HorizontalPodAutoscaler"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "deleteBatchV1CollectionNamespacedCronJob",
            "conf_tested": true,
            "description": "delete collection of CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "deleteBatchV1CollectionNamespacedJob",
            "conf_tested": true,
            "description": "delete collection of Job"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "deleteBatchV1NamespacedCronJob",
            "conf_tested": true,
            "description": "delete a CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should remove pods when job is deleted",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "deleteBatchV1NamespacedJob",
            "conf_tested": true,
            "description": "delete a Job"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1CertificateSigningRequest",
            "conf_tested": true,
            "description": "delete a CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1CollectionCertificateSigningRequest",
            "conf_tested": true,
            "description": "delete collection of CertificateSigningRequest"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "deleteCoordinationV1CollectionNamespacedLease",
            "conf_tested": true,
            "description": "delete collection of Lease"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases/{name}",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "deleteCoordinationV1NamespacedLease",
            "conf_tested": true,
            "description": "delete a Lease"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedConfigMap",
            "conf_tested": true,
            "description": "delete collection of ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedEndpoints",
            "conf_tested": true,
            "description": "delete collection of Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedEvent",
            "conf_tested": true,
            "description": "delete collection of Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedLimitRange",
            "conf_tested": true,
            "description": "delete collection of LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "delete collection of PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedPod",
            "conf_tested": true,
            "description": "delete collection of Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedPodTemplate",
            "conf_tested": true,
            "description": "delete collection of PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedReplicationController",
            "conf_tested": true,
            "description": "delete collection of ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedResourceQuota",
            "conf_tested": true,
            "description": "delete collection of ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Secrets should patch a secret [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedSecret",
            "conf_tested": true,
            "description": "delete collection of Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should delete a collection of services [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedService",
            "conf_tested": true,
            "description": "delete collection of Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNamespacedServiceAccount",
            "conf_tested": true,
            "description": "delete collection of ServiceAccount"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionNode",
            "conf_tested": false,
            "description": "delete collection of Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1CollectionPersistentVolume",
            "conf_tested": true,
            "description": "delete collection of PersistentVolume"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (fairness)",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (priority)",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-api-machinery] health handlers should contain necessary checks",
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] OpenAPIV3 should round trip OpenAPI V3 for all built-in group versions",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] Server request timeout default timeout should be used if the specified timeout in the request URL is 0s",
                "[sig-api-machinery] Server request timeout should return HTTP status code 400 if the user specifies an invalid timeout in the request URL",
                "[sig-api-machinery] Server request timeout the request should be served with a default timeout if the specified timeout in the request URL exceeds maximum allowed",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-api-machinery] server version should find the server version [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-apps] CronJob should support timezone",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                "[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] SelfSubjectReview should support SelfSubjectReview API operations",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance]",
                "[sig-cli] Kubectl client Kubectl apply apply set/view last-applied",
                "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
                "[sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC",
                "[sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds",
                "[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance]",
                "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
                "[sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
                "[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]",
                "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses",
                "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
                "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
                "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
                "[sig-cli] Kubectl client kubectl subresource flag GET on status subresource of built-in type (node) returns identical info as GET on the built-in type",
                "[sig-cli] Kubectl client kubectl subresource flag should not be used in a bulk GET",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields of a typed object",
                "[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance]",
                "[sig-cli] Kubectl client kubectl wait should ignore not found error with",
                "[sig-cli] Kubectl client Proxy server should support",
                "[sig-cli] Kubectl client Proxy server should support proxy with",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
                "[sig-cli] Kubectl client Simple pod should contain last line of the log",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
                "[sig-cli] Kubectl client Simple pod should support exec",
                "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
                "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
                "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
                "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl delete interactive based on user confirmation input",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] kubectl kuberc given preferences should be applied",
                "[sig-cli] kubectl kuberc given preferences should be ignored when flags are explicitly passed",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
                "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should delete a collection of services [Conformance]",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should find a service from listing all namespaces [Conformance]",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should provide secure master service [Conformance]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-network] Topology Hints should distribute endpoints evenly",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node or fall back to same zone when using PreferSameNode [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node when using PreferSameNode and fall back when the endpoint becomes unavailable [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NodeLease NodeLease should have OwnerReferences set",
                "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] SSH should SSH to all nodes and run commands",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
                "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
                "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1Namespace",
            "conf_tested": true,
            "description": "delete a Namespace"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedConfigMap",
            "conf_tested": true,
            "description": "delete a ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedEndpoints",
            "conf_tested": true,
            "description": "delete Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedEvent",
            "conf_tested": true,
            "description": "delete an Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedLimitRange",
            "conf_tested": true,
            "description": "delete a LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "delete a PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedPod",
            "conf_tested": true,
            "description": "delete a Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedPodTemplate",
            "conf_tested": true,
            "description": "delete a PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedReplicationController",
            "conf_tested": true,
            "description": "delete a ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedResourceQuota",
            "conf_tested": true,
            "description": "delete a ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedSecret",
            "conf_tested": true,
            "description": "delete a Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should work after the service has been recreated",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedService",
            "conf_tested": true,
            "description": "delete a Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1NamespacedServiceAccount",
            "conf_tested": true,
            "description": "delete a ServiceAccount"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1Node",
            "conf_tested": true,
            "description": "delete a Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "deleteCoreV1PersistentVolume",
            "conf_tested": true,
            "description": "delete a PersistentVolume"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "deleteDiscoveryV1CollectionNamespacedEndpointSlice",
            "conf_tested": true,
            "description": "delete collection of EndpointSlice"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices/{name}",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "deleteDiscoveryV1NamespacedEndpointSlice",
            "conf_tested": true,
            "description": "delete an EndpointSlice"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "deleteEventsV1CollectionNamespacedEvent",
            "conf_tested": true,
            "description": "delete collection of Event"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events/{name}",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "deleteEventsV1NamespacedEvent",
            "conf_tested": true,
            "description": "delete an Event"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "deleteFlowcontrolApiserverV1CollectionFlowSchema",
            "conf_tested": true,
            "description": "delete collection of FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "deleteFlowcontrolApiserverV1CollectionPriorityLevelConfiguration",
            "conf_tested": true,
            "description": "delete collection of PriorityLevelConfiguration"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "deleteFlowcontrolApiserverV1FlowSchema",
            "conf_tested": true,
            "description": "delete a FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "deleteFlowcontrolApiserverV1PriorityLevelConfiguration",
            "conf_tested": true,
            "description": "delete a PriorityLevelConfiguration"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1CollectionIngressClass",
            "conf_tested": true,
            "description": "delete collection of IngressClass"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1CollectionIPAddress",
            "conf_tested": true,
            "description": "delete collection of IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1CollectionNamespacedIngress",
            "conf_tested": true,
            "description": "delete collection of Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1CollectionNamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "delete collection of NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1CollectionServiceCIDR",
            "conf_tested": false,
            "description": "delete collection of ServiceCIDR"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1IngressClass",
            "conf_tested": true,
            "description": "delete an IngressClass"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1IPAddress",
            "conf_tested": true,
            "description": "delete an IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1NamespacedIngress",
            "conf_tested": true,
            "description": "delete an Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1NamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "delete a NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1ServiceCIDR",
            "conf_tested": false,
            "description": "delete a ServiceCIDR"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "deleteNodeV1CollectionRuntimeClass",
            "conf_tested": true,
            "description": "delete collection of RuntimeClass"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses/{name}",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "deleteNodeV1RuntimeClass",
            "conf_tested": true,
            "description": "delete a RuntimeClass"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "deletePolicyV1CollectionNamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "delete collection of PodDisruptionBudget"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "deletePolicyV1NamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "delete a PodDisruptionBudget"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1ClusterRole",
            "conf_tested": true,
            "description": "delete a ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1ClusterRoleBinding",
            "conf_tested": true,
            "description": "delete a ClusterRoleBinding"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1CollectionClusterRole",
            "conf_tested": false,
            "description": "delete collection of ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1CollectionClusterRoleBinding",
            "conf_tested": false,
            "description": "delete collection of ClusterRoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1CollectionNamespacedRole",
            "conf_tested": false,
            "description": "delete collection of Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1CollectionNamespacedRoleBinding",
            "conf_tested": false,
            "description": "delete collection of RoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1NamespacedRole",
            "conf_tested": false,
            "description": "delete a Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "deleteRbacAuthorizationV1NamespacedRoleBinding",
            "conf_tested": true,
            "description": "delete a RoleBinding"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1CollectionDeviceClass",
            "conf_tested": false,
            "description": "delete collection of DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1CollectionNamespacedResourceClaim",
            "conf_tested": false,
            "description": "delete collection of ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1CollectionNamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "delete collection of ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1CollectionResourceSlice",
            "conf_tested": false,
            "description": "delete collection of ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1DeviceClass",
            "conf_tested": false,
            "description": "delete a DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "delete a ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "delete a ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "deleteResourceV1ResourceSlice",
            "conf_tested": false,
            "description": "delete a ResourceSlice"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "deleteSchedulingV1CollectionPriorityClass",
            "conf_tested": true,
            "description": "delete collection of PriorityClass"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses/{name}",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "deleteSchedulingV1PriorityClass",
            "conf_tested": true,
            "description": "delete a PriorityClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CollectionCSIDriver",
            "conf_tested": true,
            "description": "delete collection of CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CollectionCSINode",
            "conf_tested": true,
            "description": "delete collection of CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                null
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CollectionNamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "delete collection of CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CollectionStorageClass",
            "conf_tested": true,
            "description": "delete collection of StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CollectionVolumeAttachment",
            "conf_tested": true,
            "description": "delete collection of VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]"
            ],
            "action": "deletecollection",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CollectionVolumeAttributesClass",
            "conf_tested": true,
            "description": "delete collection of VolumeAttributesClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CSIDriver",
            "conf_tested": true,
            "description": "delete a CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1CSINode",
            "conf_tested": true,
            "description": "delete a CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1NamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "delete a CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1StorageClass",
            "conf_tested": true,
            "description": "delete a StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                null
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1VolumeAttachment",
            "conf_tested": true,
            "description": "delete a VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]"
            ],
            "action": "delete",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "deleteStorageV1VolumeAttributesClass",
            "conf_tested": true,
            "description": "delete a VolumeAttributesClass"
        },
        {
            "kind": null,
            "path": "/apis/admissionregistration.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "admissionregistration",
            "endpoint": "getAdmissionregistrationAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/admissionregistration.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "admissionregistration",
            "endpoint": "getAdmissionregistrationV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/apiextensions.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apiextensions",
            "endpoint": "getApiextensionsAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/apiextensions.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apiextensions",
            "endpoint": "getApiextensionsV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/apiregistration.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apiregistration",
            "endpoint": "getApiregistrationAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/apiregistration.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apiregistration",
            "endpoint": "getApiregistrationV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apis",
            "endpoint": "getAPIVersions",
            "conf_tested": true,
            "description": "get available API versions"
        },
        {
            "kind": null,
            "path": "/apis/apps/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apps",
            "endpoint": "getAppsAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/apps/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "apps",
            "endpoint": "getAppsV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/authentication.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "authentication",
            "endpoint": "getAuthenticationAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/authentication.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "authentication",
            "endpoint": "getAuthenticationV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/authorization.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "authorization",
            "endpoint": "getAuthorizationAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/authorization.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "authorization",
            "endpoint": "getAuthorizationV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/autoscaling/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "autoscaling",
            "endpoint": "getAutoscalingAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/autoscaling/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "autoscaling",
            "endpoint": "getAutoscalingV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/autoscaling/v2/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "autoscaling",
            "endpoint": "getAutoscalingV2APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/batch/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "batch",
            "endpoint": "getBatchAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/batch/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "batch",
            "endpoint": "getBatchV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/certificates.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "certificates",
            "endpoint": "getCertificatesAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/certificates.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "certificates",
            "endpoint": "getCertificatesV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/version/",
            "group": null,
            "level": "stable",
            "tests": [
                "",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
                "[sig-api-machinery] server version should find the server version [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "version",
            "endpoint": "getCodeVersion",
            "conf_tested": true,
            "description": "get the version information for this server"
        },
        {
            "kind": null,
            "path": "/apis/coordination.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "coordination",
            "endpoint": "getCoordinationAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/coordination.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "coordination",
            "endpoint": "getCoordinationV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/api/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "core",
            "endpoint": "getCoreAPIVersions",
            "conf_tested": true,
            "description": "get available API versions"
        },
        {
            "kind": null,
            "path": "/api/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "core",
            "endpoint": "getCoreV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/discovery.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "discovery",
            "endpoint": "getDiscoveryAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/discovery.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "discovery",
            "endpoint": "getDiscoveryV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/events.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "events",
            "endpoint": "getEventsAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/events.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "events",
            "endpoint": "getEventsV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/flowcontrol.apiserver.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "flowcontrolApiserver",
            "endpoint": "getFlowcontrolApiserverAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "flowcontrolApiserver",
            "endpoint": "getFlowcontrolApiserverV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/internal.apiserver.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "internalApiserver",
            "endpoint": "getInternalApiserverAPIGroup",
            "conf_tested": false,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/networking.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "networking",
            "endpoint": "getNetworkingAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/networking.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "networking",
            "endpoint": "getNetworkingV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/node.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "node",
            "endpoint": "getNodeAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/node.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "node",
            "endpoint": "getNodeV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/policy/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "policy",
            "endpoint": "getPolicyAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/policy/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "policy",
            "endpoint": "getPolicyV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/rbac.authorization.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "rbacAuthorization",
            "endpoint": "getRbacAuthorizationAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/rbac.authorization.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "rbacAuthorization",
            "endpoint": "getRbacAuthorizationV1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/resource.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "resource",
            "endpoint": "getResourceAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/resource.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "resource",
            "endpoint": "getResourceV1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/scheduling.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "scheduling",
            "endpoint": "getSchedulingAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/scheduling.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "scheduling",
            "endpoint": "getSchedulingV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/storage.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]"
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "storage",
            "endpoint": "getStorageAPIGroup",
            "conf_tested": true,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/storagemigration.k8s.io/",
            "group": null,
            "level": "stable",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "storagemigration",
            "endpoint": "getStoragemigrationAPIGroup",
            "conf_tested": false,
            "description": "get information of a group"
        },
        {
            "kind": null,
            "path": "/apis/storage.k8s.io/v1/",
            "group": null,
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                null
            ],
            "action": null,
            "tested": true,
            "release": "1.35.0",
            "version": null,
            "category": "storage",
            "endpoint": "getStorageV1APIResources",
            "conf_tested": true,
            "description": "get available resources"
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1MutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "list or watch objects of kind MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1ValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "list or watch objects of kind ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1ValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "list or watch objects of kind ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1ValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "list or watch objects of kind ValidatingWebhookConfiguration"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "listApiextensionsV1CustomResourceDefinition",
            "conf_tested": true,
            "description": "list or watch objects of kind CustomResourceDefinition"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "listApiregistrationV1APIService",
            "conf_tested": true,
            "description": "list or watch objects of kind APIService"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/controllerrevisions",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1ControllerRevisionForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/daemonsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1DaemonSetForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/deployments",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1DeploymentForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Deployment"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1NamespacedControllerRevision",
            "conf_tested": true,
            "description": "list or watch objects of kind ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1NamespacedDaemonSet",
            "conf_tested": true,
            "description": "list or watch objects of kind DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1NamespacedDeployment",
            "conf_tested": true,
            "description": "list or watch objects of kind Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should work after the service has been recreated",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1NamespacedReplicaSet",
            "conf_tested": true,
            "description": "list or watch objects of kind ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1NamespacedStatefulSet",
            "conf_tested": true,
            "description": "list or watch objects of kind StatefulSet"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/replicasets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1ReplicaSetForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/statefulsets",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "listAppsV1StatefulSetForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind StatefulSet"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "listAutoscalingV1HorizontalPodAutoscalerForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "listAutoscalingV1NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "list or watch objects of kind HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "listAutoscalingV2HorizontalPodAutoscalerForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "listAutoscalingV2NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "list or watch objects of kind HorizontalPodAutoscaler"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/cronjobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "listBatchV1CronJobForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/jobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "listBatchV1JobForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Job"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "listBatchV1NamespacedCronJob",
            "conf_tested": true,
            "description": "list or watch objects of kind CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "listBatchV1NamespacedJob",
            "conf_tested": true,
            "description": "list or watch objects of kind Job"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "listCertificatesV1CertificateSigningRequest",
            "conf_tested": true,
            "description": "list or watch objects of kind CertificateSigningRequest"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/leases",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "listCoordinationV1LeaseForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Lease"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] NodeLease NodeLease should have OwnerReferences set",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "listCoordinationV1NamespacedLease",
            "conf_tested": true,
            "description": "list or watch objects of kind Lease"
        },
        {
            "kind": "ComponentStatus",
            "path": "/api/v1/componentstatuses",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1ComponentStatus",
            "conf_tested": false,
            "description": "list objects of kind ComponentStatus"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/configmaps",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1ConfigMapForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/endpoints",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1EndpointsForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/events",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1EventForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/limitranges",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1LimitRangeForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind LimitRange"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1Namespace",
            "conf_tested": true,
            "description": "list or watch objects of kind Namespace"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (fairness)",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (priority)",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-api-machinery] health handlers should contain necessary checks",
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] OpenAPIV3 should round trip OpenAPI V3 for all built-in group versions",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] Server request timeout default timeout should be used if the specified timeout in the request URL is 0s",
                "[sig-api-machinery] Server request timeout should return HTTP status code 400 if the user specifies an invalid timeout in the request URL",
                "[sig-api-machinery] Server request timeout the request should be served with a default timeout if the specified timeout in the request URL exceeds maximum allowed",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-api-machinery] server version should find the server version [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-apps] CronJob should support timezone",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                "[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] SelfSubjectReview should support SelfSubjectReview API operations",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance]",
                "[sig-cli] Kubectl client Kubectl apply apply set/view last-applied",
                "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
                "[sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC",
                "[sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds",
                "[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance]",
                "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
                "[sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
                "[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]",
                "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses",
                "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
                "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
                "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
                "[sig-cli] Kubectl client kubectl subresource flag GET on status subresource of built-in type (node) returns identical info as GET on the built-in type",
                "[sig-cli] Kubectl client kubectl subresource flag should not be used in a bulk GET",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields of a typed object",
                "[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance]",
                "[sig-cli] Kubectl client kubectl wait should ignore not found error with",
                "[sig-cli] Kubectl client Proxy server should support",
                "[sig-cli] Kubectl client Proxy server should support proxy with",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
                "[sig-cli] Kubectl client Simple pod should contain last line of the log",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
                "[sig-cli] Kubectl client Simple pod should support exec",
                "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
                "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
                "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
                "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl delete interactive based on user confirmation input",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] kubectl kuberc given preferences should be applied",
                "[sig-cli] kubectl kuberc given preferences should be ignored when flags are explicitly passed",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
                "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should delete a collection of services [Conformance]",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should find a service from listing all namespaces [Conformance]",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should provide secure master service [Conformance]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-network] Topology Hints should distribute endpoints evenly",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node or fall back to same zone when using PreferSameNode [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node when using PreferSameNode and fall back when the endpoint becomes unavailable [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NodeLease NodeLease should have OwnerReferences set",
                "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] SSH should SSH to all nodes and run commands",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
                "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
                "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedConfigMap",
            "conf_tested": true,
            "description": "list or watch objects of kind ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedEndpoints",
            "conf_tested": true,
            "description": "list or watch objects of kind Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedEvent",
            "conf_tested": true,
            "description": "list or watch objects of kind Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedLimitRange",
            "conf_tested": true,
            "description": "list or watch objects of kind LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "list or watch objects of kind PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods",
            "group": "",
            "level": "stable",
            "tests": [
                "",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
                "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedPod",
            "conf_tested": true,
            "description": "list or watch objects of kind Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedPodTemplate",
            "conf_tested": true,
            "description": "list or watch objects of kind PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers",
            "group": "",
            "level": "stable",
            "tests": [
                "",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedReplicationController",
            "conf_tested": true,
            "description": "list or watch objects of kind ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedResourceQuota",
            "conf_tested": true,
            "description": "list or watch objects of kind ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedSecret",
            "conf_tested": true,
            "description": "list or watch objects of kind Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should delete a collection of services [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedService",
            "conf_tested": true,
            "description": "list or watch objects of kind Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (fairness)",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (priority)",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-api-machinery] health handlers should contain necessary checks",
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] OpenAPIV3 should round trip OpenAPI V3 for all built-in group versions",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] Server request timeout default timeout should be used if the specified timeout in the request URL is 0s",
                "[sig-api-machinery] Server request timeout should return HTTP status code 400 if the user specifies an invalid timeout in the request URL",
                "[sig-api-machinery] Server request timeout the request should be served with a default timeout if the specified timeout in the request URL exceeds maximum allowed",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-api-machinery] server version should find the server version [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-apps] CronJob should support timezone",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                "[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] SelfSubjectReview should support SelfSubjectReview API operations",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance]",
                "[sig-cli] Kubectl client Kubectl apply apply set/view last-applied",
                "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
                "[sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC",
                "[sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds",
                "[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance]",
                "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
                "[sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
                "[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]",
                "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses",
                "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
                "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
                "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
                "[sig-cli] Kubectl client kubectl subresource flag GET on status subresource of built-in type (node) returns identical info as GET on the built-in type",
                "[sig-cli] Kubectl client kubectl subresource flag should not be used in a bulk GET",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields of a typed object",
                "[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance]",
                "[sig-cli] Kubectl client kubectl wait should ignore not found error with",
                "[sig-cli] Kubectl client Proxy server should support",
                "[sig-cli] Kubectl client Proxy server should support proxy with",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
                "[sig-cli] Kubectl client Simple pod should contain last line of the log",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
                "[sig-cli] Kubectl client Simple pod should support exec",
                "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
                "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
                "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
                "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl delete interactive based on user confirmation input",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] kubectl kuberc given preferences should be applied",
                "[sig-cli] kubectl kuberc given preferences should be ignored when flags are explicitly passed",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
                "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should delete a collection of services [Conformance]",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should find a service from listing all namespaces [Conformance]",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should provide secure master service [Conformance]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-network] Topology Hints should distribute endpoints evenly",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node or fall back to same zone when using PreferSameNode [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node when using PreferSameNode and fall back when the endpoint becomes unavailable [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NodeLease NodeLease should have OwnerReferences set",
                "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] SSH should SSH to all nodes and run commands",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
                "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
                "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1NamespacedServiceAccount",
            "conf_tested": true,
            "description": "list or watch objects of kind ServiceAccount"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes",
            "group": "",
            "level": "stable",
            "tests": [
                "",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support aggregated discovery interface for CRDs [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery endpoint Accept headers [Conformance]",
                "[sig-api-machinery] AggregatedDiscovery should support raw aggregated discovery request for CRDs [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (fairness)",
                "[sig-api-machinery] API priority and fairness should ensure that requests can't be drowned out (priority)",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/json,application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf\"",
                "[sig-api-machinery] client-go should negotiate watch and report errors with accept \"application/vnd.kubernetes.protobuf,application/json\"",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] should include custom resource definition resources in discovery documents [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition creating/deleting custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition Watch [Privileged:ClusterAdmin] CustomResourceDefinition Watch watch on custom resource definition objects [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields at the schema root [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD preserving unknown fields in an embedded object [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD without validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for CRD with validation schema [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of different groups [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group and version but different kinds [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] works for multiple CRDs of same group but different versions [Conformance]",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that contains a syntax error",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains an x-kubernetes-validations rule that exceeds the estimated cost limit",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource definition that contains a x-kubernetes-validations rule that refers to a property that do not exist",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail create of a custom resource that exceeds the runtime cost limit for x-kubernetes-validations rule execution",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail update of a custom resource that does not satisfy a x-kubernetes-validations transition rule",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST fail validation for create of a custom resource that does not satisfy the x-kubernetes-validations rules",
                "[sig-api-machinery] CustomResourceValidationRules [Privileged:ClusterAdmin] MUST NOT fail validation for create of a custom resource that satisfies the x-kubernetes-validations rules",
                "[sig-api-machinery] Discovery Custom resource should have storage version hash",
                "[sig-api-machinery] Discovery should accurately determine present and missing resources",
                "[sig-api-machinery] Discovery should locate the groupVersion and a resource within each APIGroup [Conformance]",
                "[sig-api-machinery] Discovery should validate PreferredVersion for each APIGroup [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a CR with unknown fields for CRD with no validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply an invalid CR with extra properties for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should create/apply a valid CR for CRD with validation schema [Conformance]",
                "[sig-api-machinery] FieldValidation should detect duplicates in a CR when preserving unknown fields [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown and duplicate fields of a typed object [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields in both the root and embedded object of a CR [Conformance]",
                "[sig-api-machinery] FieldValidation should detect unknown metadata fields of a typed object [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Garbage collector should support cascading deletion of custom resources",
                "[sig-api-machinery] Garbage collector should support orphan deletion of custom resources",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Generated clientset should create v1 cronJobs, delete cronJobs, watch cronJobs",
                "[sig-api-machinery] health handlers should contain necessary checks",
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] OpenAPIV3 should publish OpenAPI V3 for CustomResourceDefinition",
                "[sig-api-machinery] OpenAPIV3 should round trip OpenAPI V3 for all built-in group versions",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] Server request timeout default timeout should be used if the specified timeout in the request URL is 0s",
                "[sig-api-machinery] Server request timeout should return HTTP status code 400 if the user specifies an invalid timeout in the request URL",
                "[sig-api-machinery] Server request timeout the request should be served with a default timeout if the specified timeout in the request URL exceeds maximum allowed",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should not remove a field if an owner unsets the field but other managers still have ownership of the field",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-api-machinery] ServerSideApply should work for CRDs",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] Servers with support for API chunking should return chunks of results for list calls [Conformance]",
                "[sig-api-machinery] Servers with support for API chunking should support continue listing from the last key if the original version has been compacted away, though the list is inconsistent [Slow] [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return a 406 for a backend which does not implement metadata [Conformance]",
                "[sig-api-machinery] Servers with support for Table transformation should return chunks of table results for list calls",
                "[sig-api-machinery] Servers with support for Table transformation should return generic metadata details across all namespaces for nodes",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-api-machinery] server version should find the server version [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should delete failed finished jobs with limit of one job",
                "[sig-apps] CronJob should delete successful finished jobs with limit of one successful job",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should set the cronjob-scheduled-timestamp annotation on a job",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                "[sig-apps] CronJob should support timezone",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: no PDB => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                "[sig-architecture] Conformance Tests should have at least two untainted nodes [Conformance]",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] SelfSubjectReview should support SelfSubjectReview API operations",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1alpha1",
                "[sig-auth] SelfSubjectReview testing SSR in different API groups authentication/v1beta1",
                "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should allow opting out of API token automount [Conformance]",
                "[sig-auth] ServiceAccounts should create a serviceAccountToken and ensure a successful TokenReview [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                "[sig-auth] SubjectReview should support SubjectReview API operations [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl client Guestbook application should create and stop a working application [Conformance]",
                "[sig-cli] Kubectl client Kubectl api-versions should check if v1 is in available api versions [Conformance]",
                "[sig-cli] Kubectl client Kubectl apply apply set/view last-applied",
                "[sig-cli] Kubectl client Kubectl apply should apply a new configuration to an existing RC",
                "[sig-cli] Kubectl client Kubectl apply should reuse port when apply to an existing SVC",
                "[sig-cli] Kubectl client Kubectl cluster-info dump should check if cluster-info dump succeeds",
                "[sig-cli] Kubectl client Kubectl cluster-info should check if Kubernetes control plane services is included in cluster-info [Conformance]",
                "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
                "[sig-cli] Kubectl client Kubectl create quota should reject quota with invalid scopes",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for cronjob",
                "[sig-cli] Kubectl client Kubectl describe should check if kubectl describe prints relevant information for rc and pods [Conformance]",
                "[sig-cli] Kubectl client Kubectl diff should check if kubectl diff finds a difference for Deployments [Conformance]",
                "[sig-cli] Kubectl client Kubectl events should show event when pod is created",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl get componentstatuses should get componentstatuses",
                "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
                "[sig-cli] Kubectl client Kubectl patch should add annotations for pods in rc [Conformance]",
                "[sig-cli] Kubectl client Kubectl prune with applyset should apply and prune objects",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
                "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
                "[sig-cli] Kubectl client kubectl subresource flag GET on status subresource of built-in type (node) returns identical info as GET on the built-in type",
                "[sig-cli] Kubectl client kubectl subresource flag should not be used in a bulk GET",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a CR with unknown fields for CRD with no validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply an invalid/valid CR with arbitrary-extra properties for CRD with partially-specified validation schema",
                "[sig-cli] Kubectl client Kubectl validation should create/apply a valid CR for CRD with validation schema",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields in both the root and embedded object of a CR",
                "[sig-cli] Kubectl client Kubectl validation should detect unknown metadata fields of a typed object",
                "[sig-cli] Kubectl client Kubectl version should check is all data is printed [Conformance]",
                "[sig-cli] Kubectl client kubectl wait should ignore not found error with",
                "[sig-cli] Kubectl client Proxy server should support",
                "[sig-cli] Kubectl client Proxy server should support proxy with",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
                "[sig-cli] Kubectl client Simple pod should contain last line of the log",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
                "[sig-cli] Kubectl client Simple pod should support exec",
                "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
                "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
                "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] Kubectl client Update Demo should create and stop a replication controller [Conformance]",
                "[sig-cli] Kubectl client Update Demo should scale a replication controller [Conformance]",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl delete interactive based on user confirmation input",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] kubectl kuberc given preferences should be applied",
                "[sig-cli] kubectl kuberc given preferences should be ignored when flags are explicitly passed",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                "[sig-instrumentation] Events should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Networking should provide unchanging, static URL paths for kubernetes api services",
                "[sig-network] NoSNAT Should be able to send traffic between Pods without SNAT",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Proxy version v1 should proxy logs on node using proxy subresource",
                "[sig-network] Proxy version v1 should proxy logs on node with explicit kubelet port using proxy subresource",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should delete a collection of services [Conformance]",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should find a service from listing all namespaces [Conformance]",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should prevent NodePort collisions",
                "[sig-network] Services should provide secure master service [Conformance]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-network] Topology Hints should distribute endpoints evenly",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic correctly between pods on multiple nodes when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferClose",
                "[sig-network] Traffic Distribution should route traffic to an endpoint in the same zone when using PreferSameZone [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node or fall back to same zone when using PreferSameNode [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-network] Traffic Distribution should route traffic to an endpoint on the same node when using PreferSameNode and fall back when the endpoint becomes unavailable [FeatureGate:PreferSameTrafficDistribution] [Beta]",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should fail to create ConfigMap with empty key [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartAlways pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should invoke init containers on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers and fail the pod if init containers fail on a RestartNever pod [Conformance]",
                "[sig-node] InitContainer [NodeConformance] should not start app containers if init containers fail on a RestartAlways pod [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should be possible to delete [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NodeLease NodeLease should have OwnerReferences set",
                "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pod Container Status should never report container start when an init container fails",
                "[sig-node] Pods Extended Pod Container Status should never report success for a pending container",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should delete a collection of pods [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PodTemplates should delete a collection of pod templates [Conformance]",
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should mark readiness on pods to false and disable liveness probes while pod is in progress of terminating",
                "[sig-node] Probing container should mark readiness on pods to false while pod is in progress of terminating when a pod has a readiness probe",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with conflicting node selector",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass and initialize its Overhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should schedule a Pod requesting a RuntimeClass without PodOverhead [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Secrets should fail to create secret due to empty secret key [Conformance]",
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run with an explicit root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should not run without a specified user ID",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] SSH should SSH to all nodes and run commands",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should reject invalid sysctls [MinimumKubeletVersion:1.21] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Dynamic Provisioning Invalid AWS KMS key should report an error and create no PV",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source (ROX mode)",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
                "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
                "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1Node",
            "conf_tested": true,
            "description": "list or watch objects of kind Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1PersistentVolume",
            "conf_tested": true,
            "description": "list or watch objects of kind PersistentVolume"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/persistentvolumeclaims",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1PersistentVolumeClaimForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/pods",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if not matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1PodForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/podtemplates",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1PodTemplateForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/replicationcontrollers",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1ReplicationControllerForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/resourcequotas",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1ResourceQuotaForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/secrets",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Secrets should patch a secret [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1SecretForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Secret"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/serviceaccounts",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1ServiceAccountForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind ServiceAccount"
        },
        {
            "kind": "Service",
            "path": "/api/v1/services",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should find a service from listing all namespaces [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "listCoreV1ServiceForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Service"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/endpointslices",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "listDiscoveryV1EndpointSliceForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind EndpointSlice"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "listDiscoveryV1NamespacedEndpointSlice",
            "conf_tested": true,
            "description": "list or watch objects of kind EndpointSlice"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/events",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]"
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "listEventsV1EventForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Event"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should delete a collection of events [Conformance]",
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "listEventsV1NamespacedEvent",
            "conf_tested": true,
            "description": "list or watch objects of kind Event"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "listFlowcontrolApiserverV1FlowSchema",
            "conf_tested": true,
            "description": "list or watch objects of kind FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "listFlowcontrolApiserverV1PriorityLevelConfiguration",
            "conf_tested": true,
            "description": "list or watch objects of kind PriorityLevelConfiguration"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1IngressClass",
            "conf_tested": true,
            "description": "list or watch objects of kind IngressClass"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/ingresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1IngressForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind Ingress"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1IPAddress",
            "conf_tested": true,
            "description": "list or watch objects of kind IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1NamespacedIngress",
            "conf_tested": true,
            "description": "list or watch objects of kind Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                "[sig-network] Netpol API should support creating NetworkPolicy API with endport field",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1NamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "list or watch objects of kind NetworkPolicy"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/networkpolicies",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1NetworkPolicyForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "listNetworkingV1ServiceCIDR",
            "conf_tested": true,
            "description": "list or watch objects of kind ServiceCIDR"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "listNodeV1RuntimeClass",
            "conf_tested": true,
            "description": "list or watch objects of kind RuntimeClass"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "listPolicyV1NamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "list or watch objects of kind PodDisruptionBudget"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/poddisruptionbudgets",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "listPolicyV1PodDisruptionBudgetForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind PodDisruptionBudget"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "listRbacAuthorizationV1ClusterRole",
            "conf_tested": true,
            "description": "list or watch objects of kind ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "listRbacAuthorizationV1ClusterRoleBinding",
            "conf_tested": false,
            "description": "list or watch objects of kind ClusterRoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "listRbacAuthorizationV1NamespacedRole",
            "conf_tested": false,
            "description": "list or watch objects of kind Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "listRbacAuthorizationV1NamespacedRoleBinding",
            "conf_tested": false,
            "description": "list or watch objects of kind RoleBinding"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/rolebindings",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "listRbacAuthorizationV1RoleBindingForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind RoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/roles",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "listRbacAuthorizationV1RoleForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind Role"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "listResourceV1DeviceClass",
            "conf_tested": false,
            "description": "list or watch objects of kind DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "listResourceV1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "listResourceV1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaimTemplate"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/resourceclaims",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "listResourceV1ResourceClaimForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "listResourceV1ResourceClaimTemplateForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice",
                "[sig-node] [DRA] ResourceSlice Controller creates slices [ConformanceCandidate]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "listResourceV1ResourceSlice",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceSlice"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "listSchedulingV1PriorityClass",
            "conf_tested": true,
            "description": "list or watch objects of kind PriorityClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1CSIDriver",
            "conf_tested": true,
            "description": "list or watch objects of kind CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1CSINode",
            "conf_tested": true,
            "description": "list or watch objects of kind CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/csistoragecapacities",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1CSIStorageCapacityForAllNamespaces",
            "conf_tested": true,
            "description": "list or watch objects of kind CSIStorageCapacity"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1NamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "list or watch objects of kind CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should adopt matching orphans and release non-matching pods",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should not deadlock when a pod's predecessor fails",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications with PVCs",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should provide basic identity",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenDeleted)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs after adopting pod (WhenScaled)",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a OnScaledown policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should delete PVCs with a WhenDeleted policy",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVCs when there is another controller",
                "[sig-apps] StatefulSet Non-retain StatefulSetPersistentVolumeClaimPolicy should not delete PVC with OnScaledown policy if another controller owns the PVC",
                "[sig-storage] PVC Protection Verify \"immediate\" deletion of a PVC that is not in active use by a pod",
                "[sig-storage] PVC Protection Verify that PVC in active use by a pod is not removed immediately",
                "[sig-storage] PVC Protection Verify that scheduling of a pod that uses PVC that is being deleted fails and the pod becomes Unschedulable",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1StorageClass",
            "conf_tested": true,
            "description": "list or watch objects of kind StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1VolumeAttachment",
            "conf_tested": true,
            "description": "list or watch objects of kind VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
                null
            ],
            "action": "list",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "listStorageV1VolumeAttributesClass",
            "conf_tested": true,
            "description": "list or watch objects of kind VolumeAttributesClass"
        },
        {
            "kind": null,
            "path": "/logs/{logpath}",
            "group": null,
            "level": "stable",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "logs",
            "endpoint": "logFileHandler",
            "conf_tested": false,
            "description": null
        },
        {
            "kind": null,
            "path": "/logs/",
            "group": null,
            "level": "stable",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "logs",
            "endpoint": "logFileListHandler",
            "conf_tested": false,
            "description": null
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1MutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "partially update the specified MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1ValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "partially update the specified ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1ValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "partially update the specified ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}/status",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1ValidatingAdmissionPolicyStatus",
            "conf_tested": true,
            "description": "partially update status of the specified ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1ValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "partially update the specified ValidatingWebhookConfiguration"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] custom resource defaulting for requests and from storage works [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] updates the published spec when one version gets renamed [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "patchApiextensionsV1CustomResourceDefinition",
            "conf_tested": true,
            "description": "partially update the specified CustomResourceDefinition"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}/status",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "patchApiextensionsV1CustomResourceDefinitionStatus",
            "conf_tested": true,
            "description": "partially update status of the specified CustomResourceDefinition"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "patchApiregistrationV1APIService",
            "conf_tested": true,
            "description": "partially update the specified APIService"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}/status",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "patchApiregistrationV1APIServiceStatus",
            "conf_tested": true,
            "description": "partially update status of the specified APIService"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedControllerRevision",
            "conf_tested": true,
            "description": "partially update the specified ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedDaemonSet",
            "conf_tested": true,
            "description": "partially update the specified DaemonSet"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedDaemonSetStatus",
            "conf_tested": true,
            "description": "partially update status of the specified DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ServerSideApply should ignore conflict errors if force apply is used",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedDeployment",
            "conf_tested": true,
            "description": "partially update the specified Deployment"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedDeploymentScale",
            "conf_tested": true,
            "description": "partially update scale of the specified Deployment"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedDeploymentStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedReplicaSet",
            "conf_tested": true,
            "description": "partially update the specified ReplicaSet"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedReplicaSetScale",
            "conf_tested": true,
            "description": "partially update scale of the specified ReplicaSet"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedReplicaSetStatus",
            "conf_tested": true,
            "description": "partially update status of the specified ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedStatefulSet",
            "conf_tested": true,
            "description": "partially update the specified StatefulSet"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedStatefulSetScale",
            "conf_tested": true,
            "description": "partially update scale of the specified StatefulSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "patchAppsV1NamespacedStatefulSetStatus",
            "conf_tested": true,
            "description": "partially update status of the specified StatefulSet"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "patchAutoscalingV1NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "partially update the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}/status",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "patchAutoscalingV1NamespacedHorizontalPodAutoscalerStatus",
            "conf_tested": false,
            "description": "partially update status of the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "patchAutoscalingV2NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "partially update the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}/status",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "patchAutoscalingV2NamespacedHorizontalPodAutoscalerStatus",
            "conf_tested": false,
            "description": "partially update status of the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "patchBatchV1NamespacedCronJob",
            "conf_tested": true,
            "description": "partially update the specified CronJob"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}/status",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "patchBatchV1NamespacedCronJobStatus",
            "conf_tested": true,
            "description": "partially update status of the specified CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "patchBatchV1NamespacedJob",
            "conf_tested": true,
            "description": "partially update the specified Job"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}/status",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should apply changes to a job status [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "patchBatchV1NamespacedJobStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Job"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1CertificateSigningRequest",
            "conf_tested": true,
            "description": "partially update the specified CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}/approval",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1CertificateSigningRequestApproval",
            "conf_tested": true,
            "description": "partially update approval of the specified CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}/status",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1CertificateSigningRequestStatus",
            "conf_tested": true,
            "description": "partially update status of the specified CertificateSigningRequest"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases/{name}",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "patchCoordinationV1NamespacedLease",
            "conf_tested": true,
            "description": "partially update the specified Lease"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should allow expressions to refer variables. [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should validate against a Deployment [Conformance]",
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1Namespace",
            "conf_tested": true,
            "description": "partially update the specified Namespace"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedConfigMap",
            "conf_tested": true,
            "description": "partially update the specified ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedEndpoints",
            "conf_tested": true,
            "description": "partially update the specified Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedEvent",
            "conf_tested": true,
            "description": "partially update the specified Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-scheduling] LimitRange should list, patch and delete a LimitRange by collection [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedLimitRange",
            "conf_tested": true,
            "description": "partially update the specified LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "partially update the specified PersistentVolumeClaim"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPersistentVolumeClaimStatus",
            "conf_tested": true,
            "description": "partially update status of the specified PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should not be blocked by dependency circle [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPod",
            "conf_tested": true,
            "description": "partially update the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/ephemeralcontainers",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPodEphemeralcontainers",
            "conf_tested": true,
            "description": "partially update ephemeralcontainers of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/resize",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPodResize",
            "conf_tested": false,
            "description": "partially update resize of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPodStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedPodTemplate",
            "conf_tested": true,
            "description": "partially update the specified PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedReplicationController",
            "conf_tested": true,
            "description": "partially update the specified ReplicationController"
        },
        {
            "kind": "Scale",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedReplicationControllerScale",
            "conf_tested": true,
            "description": "partially update scale of the specified ReplicationController"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedReplicationControllerStatus",
            "conf_tested": true,
            "description": "partially update status of the specified ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedResourceQuota",
            "conf_tested": true,
            "description": "partially update the specified ResourceQuota"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedResourceQuotaStatus",
            "conf_tested": true,
            "description": "partially update status of the specified ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Secrets should patch a secret [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedSecret",
            "conf_tested": true,
            "description": "partially update the specified Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedService",
            "conf_tested": true,
            "description": "partially update the specified Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedServiceAccount",
            "conf_tested": true,
            "description": "partially update the specified ServiceAccount"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespacedServiceStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Service"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NamespaceStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Namespace"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1Node",
            "conf_tested": true,
            "description": "partially update the specified Node"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1NodeStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1PersistentVolume",
            "conf_tested": true,
            "description": "partially update the specified PersistentVolume"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "patchCoreV1PersistentVolumeStatus",
            "conf_tested": true,
            "description": "partially update status of the specified PersistentVolume"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices/{name}",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "patchDiscoveryV1NamespacedEndpointSlice",
            "conf_tested": true,
            "description": "partially update the specified EndpointSlice"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events/{name}",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "patchEventsV1NamespacedEvent",
            "conf_tested": true,
            "description": "partially update the specified Event"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "patchFlowcontrolApiserverV1FlowSchema",
            "conf_tested": true,
            "description": "partially update the specified FlowSchema"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}/status",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "patchFlowcontrolApiserverV1FlowSchemaStatus",
            "conf_tested": true,
            "description": "partially update status of the specified FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "patchFlowcontrolApiserverV1PriorityLevelConfiguration",
            "conf_tested": true,
            "description": "partially update the specified PriorityLevelConfiguration"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}/status",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "patchFlowcontrolApiserverV1PriorityLevelConfigurationStatus",
            "conf_tested": true,
            "description": "partially update status of the specified PriorityLevelConfiguration"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1IngressClass",
            "conf_tested": true,
            "description": "partially update the specified IngressClass"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1IPAddress",
            "conf_tested": true,
            "description": "partially update the specified IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1NamespacedIngress",
            "conf_tested": true,
            "description": "partially update the specified Ingress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}/status",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1NamespacedIngressStatus",
            "conf_tested": true,
            "description": "partially update status of the specified Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1NamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "partially update the specified NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1ServiceCIDR",
            "conf_tested": false,
            "description": "partially update the specified ServiceCIDR"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}/status",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "patchNetworkingV1ServiceCIDRStatus",
            "conf_tested": false,
            "description": "partially update status of the specified ServiceCIDR"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses/{name}",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "patchNodeV1RuntimeClass",
            "conf_tested": true,
            "description": "partially update the specified RuntimeClass"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "patchPolicyV1NamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "partially update the specified PodDisruptionBudget"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}/status",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "patchPolicyV1NamespacedPodDisruptionBudgetStatus",
            "conf_tested": true,
            "description": "partially update status of the specified PodDisruptionBudget"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "patchRbacAuthorizationV1ClusterRole",
            "conf_tested": false,
            "description": "partially update the specified ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "patchRbacAuthorizationV1ClusterRoleBinding",
            "conf_tested": false,
            "description": "partially update the specified ClusterRoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "patchRbacAuthorizationV1NamespacedRole",
            "conf_tested": false,
            "description": "partially update the specified Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "patchRbacAuthorizationV1NamespacedRoleBinding",
            "conf_tested": false,
            "description": "partially update the specified RoleBinding"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "patchResourceV1DeviceClass",
            "conf_tested": false,
            "description": "partially update the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "patchResourceV1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "partially update the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "patchResourceV1NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "partially update status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "patchResourceV1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "partially update the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "patchResourceV1ResourceSlice",
            "conf_tested": false,
            "description": "partially update the specified ResourceSlice"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses/{name}",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "patchSchedulingV1PriorityClass",
            "conf_tested": true,
            "description": "partially update the specified PriorityClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1CSIDriver",
            "conf_tested": true,
            "description": "partially update the specified CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1CSINode",
            "conf_tested": true,
            "description": "partially update the specified CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1NamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "partially update the specified CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1StorageClass",
            "conf_tested": true,
            "description": "partially update the specified StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1VolumeAttachment",
            "conf_tested": true,
            "description": "partially update the specified VolumeAttachment"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}/status",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                null
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1VolumeAttachmentStatus",
            "conf_tested": true,
            "description": "partially update status of the specified VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]"
            ],
            "action": "patch",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "patchStorageV1VolumeAttributesClass",
            "conf_tested": true,
            "description": "partially update the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1MutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "read the specified MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check a CRD",
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should type check validation expressions"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1ValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "read the specified ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1ValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "read the specified ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}/status",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1ValidatingAdmissionPolicyStatus",
            "conf_tested": true,
            "description": "read status of the specified ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1ValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "read the specified ValidatingWebhookConfiguration"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition listing custom resource definition objects works [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "readApiextensionsV1CustomResourceDefinition",
            "conf_tested": true,
            "description": "read the specified CustomResourceDefinition"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}/status",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "readApiextensionsV1CustomResourceDefinitionStatus",
            "conf_tested": true,
            "description": "read status of the specified CustomResourceDefinition"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "readApiregistrationV1APIService",
            "conf_tested": true,
            "description": "read the specified APIService"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}/status",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "readApiregistrationV1APIServiceStatus",
            "conf_tested": true,
            "description": "read status of the specified APIService"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedControllerRevision",
            "conf_tested": true,
            "description": "read the specified ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedDaemonSet",
            "conf_tested": true,
            "description": "read the specified DaemonSet"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedDaemonSetStatus",
            "conf_tested": true,
            "description": "read status of the specified DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing mutating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] listing validating webhooks should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny custom resource creation, update and deletion [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should deny crd creation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should honor timeout [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should include webhook resources in discovery documents [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate configmap [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with different stored version [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate custom resource with pruning [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate everything except 'skip-me' configmaps [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should mutate pod and apply defaults after mutation [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should not be able to mutate or prevent deletion of webhook configuration objects [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject mutating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should reject validating webhook configurations with invalid match conditions [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should unconditionally reject operations on fail closed webhook [Conformance]",
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert from CR v1 to CR v2 [Conformance]",
                "[sig-api-machinery] CustomResourceFieldSelectors [Privileged:ClusterAdmin] CustomResourceFieldSelectors MUST list and watch custom resources matching the field selector [Conformance]",
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-api-machinery] ServerSideApply should remove a field if it is owned but removed in the apply request",
                "[sig-apps] Deployment deployment reaping should cascade to its replica sets and pods",
                "[sig-apps] Deployment deployment should delete old replica sets [Conformance]",
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment RollingUpdateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                "[sig-apps] Deployment test Deployment ReplicaSet orphaning and adoption regarding controllerRef",
                "[sig-cli] Kubectl delete interactive based on user confirmation input",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from all pods based on default container",
                "[sig-cli] Kubectl logs all pod logs the Deployment has 2 replicas and each pod has 2 containers should get logs from each pod and each container in Deployment",
                "[sig-cli] Kubectl rollout undo undo should rollback and update deployment env",
                "[sig-network] Proxy version v1 should proxy through a service and a pod [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Service endpoints latency should not be very high [Conformance]",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should work after the service has been recreated",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedDeployment",
            "conf_tested": true,
            "description": "read the specified Deployment"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedDeploymentScale",
            "conf_tested": true,
            "description": "read scale of the specified Deployment"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedDeploymentStatus",
            "conf_tested": true,
            "description": "read status of the specified Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should list and delete a collection of ReplicaSets [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedReplicaSet",
            "conf_tested": true,
            "description": "read the specified ReplicaSet"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedReplicaSetScale",
            "conf_tested": true,
            "description": "read scale of the specified ReplicaSet"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedReplicaSetStatus",
            "conf_tested": true,
            "description": "read status of the specified ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should list, patch and delete a collection of StatefulSets [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet MinReadySeconds should be honored when enabled",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedStatefulSet",
            "conf_tested": true,
            "description": "read the specified StatefulSet"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedStatefulSetScale",
            "conf_tested": true,
            "description": "read scale of the specified StatefulSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "readAppsV1NamespacedStatefulSetStatus",
            "conf_tested": true,
            "description": "read status of the specified StatefulSet"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "readAutoscalingV1NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "read the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}/status",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "readAutoscalingV1NamespacedHorizontalPodAutoscalerStatus",
            "conf_tested": false,
            "description": "read status of the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "readAutoscalingV2NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "read the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}/status",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "readAutoscalingV2NamespacedHorizontalPodAutoscalerStatus",
            "conf_tested": false,
            "description": "read status of the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should be able to schedule after more than 100 missed schedule",
                "[sig-apps] CronJob should not emit unexpected warnings",
                "[sig-apps] CronJob should not schedule jobs when suspended [Slow] [Conformance]",
                "[sig-apps] CronJob should not schedule new jobs when ForbidConcurrent [Slow] [Conformance]",
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] CronJob should replace jobs when ReplaceConcurrent [Conformance]",
                "[sig-apps] CronJob should schedule multiple jobs concurrently [Conformance]",
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "readBatchV1NamespacedCronJob",
            "conf_tested": true,
            "description": "read the specified CronJob"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}/status",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "readBatchV1NamespacedCronJobStatus",
            "conf_tested": true,
            "description": "read status of the specified CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should remove from active list jobs that have been deleted",
                "[sig-apps] Job should allow to delegate reconciliation to external controller",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on exit code",
                "[sig-apps] Job should allow to use the pod failure policy on exit code to fail the job early [Conformance]",
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                "[sig-apps] Job should create pods for an Indexed job with completion indexes and specified hostname [Conformance]",
                "[sig-apps] Job should create pods with completion indexes for an Indexed Job",
                "[sig-apps] Job should delete a job [Conformance]",
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should execute all indexes despite some failing when using backoffLimitPerIndex [Conformance]",
                "[sig-apps] Job should fail to exceed backoffLimit",
                "[sig-apps] Job should fail when exceeds active deadline",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should mark indexes as failed when the FailIndex action is matched in podFailurePolicy [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should record the failure-count in the Pod annotation when using backoffLimitPerIndex",
                "[sig-apps] Job should recreate pods only after they have failed if pod replacement policy is set to Failed",
                "[sig-apps] Job should remove pods when job is deleted",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are locally restarted [Conformance]",
                "[sig-apps] Job should run a job to completion when tasks sometimes fail and are not locally restarted",
                "[sig-apps] Job should run a job to completion when tasks succeed",
                "[sig-apps] Job should terminate job execution when the number of failed indexes exceeds maxFailedIndexes [Conformance]",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] Job with successPolicy should succeeded when all indexes succeeded [Conformance]",
                "[sig-apps] Job with successPolicy succeededCount rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] Job with successPolicy succeededIndexes rule should succeeded even when some indexes remain pending [Conformance]",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "readBatchV1NamespacedJob",
            "conf_tested": true,
            "description": "read the specified Job"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}/status",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should apply changes to a job status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "readBatchV1NamespacedJobStatus",
            "conf_tested": true,
            "description": "read status of the specified Job"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "readCertificatesV1CertificateSigningRequest",
            "conf_tested": true,
            "description": "read the specified CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}/approval",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "readCertificatesV1CertificateSigningRequestApproval",
            "conf_tested": true,
            "description": "read approval of the specified CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}/status",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "readCertificatesV1CertificateSigningRequestStatus",
            "conf_tested": true,
            "description": "read status of the specified CertificateSigningRequest"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases/{name}",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]",
                "[sig-node] NodeLease NodeLease the kubelet should create and update a lease in the kube-node-lease namespace",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "readCoordinationV1NamespacedLease",
            "conf_tested": true,
            "description": "read the specified Lease"
        },
        {
            "kind": "ComponentStatus",
            "path": "/api/v1/componentstatuses/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1ComponentStatus",
            "conf_tested": false,
            "description": "read the specified ComponentStatus"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] Namespaces [Serial] should patch a Namespace [Conformance]",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1Namespace",
            "conf_tested": true,
            "description": "read the specified Namespace"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-node] ConfigMap should run through a ConfigMap lifecycle [Conformance]",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedConfigMap",
            "conf_tested": true,
            "description": "read the specified ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should create and delete Endpoints and EndpointSlices for a Service with a selector specified [Conformance]",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedEndpoints",
            "conf_tested": true,
            "description": "read the specified Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedEvent",
            "conf_tested": true,
            "description": "read the specified Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedLimitRange",
            "conf_tested": true,
            "description": "read the specified LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "read the specified PersistentVolumeClaim"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPersistentVolumeClaimStatus",
            "conf_tested": true,
            "description": "read status of the specified PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny attaching pod [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-api-machinery] Generated clientset should create pods, set the deletionTimestamp and deletionGracePeriodSeconds of the pod",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all pods are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-api-machinery] ServerSideApply should work for subresources",
                "[sig-api-machinery] Servers with support for Table transformation should return pod details",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] Job should allow to use a pod failure policy to ignore failure matching on DisruptionTarget condition [Conformance]",
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicaSet should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] ReplicationController should adopt matching pods on creation [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a private image",
                "[sig-apps] ReplicationController should serve a basic image on each replica with a public image [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-auth] NodeAuthenticator The kubelet can delegate ServiceAccount tokens to the API server",
                "[sig-auth] NodeAuthenticator The kubelet's main port 10250 should reject requests with no credentials",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-cli] Kubectl client Kubectl copy should copy a file from a running Pod",
                "[sig-cli] Kubectl client Kubectl label should update the label on a resource [Conformance]",
                "[sig-cli] Kubectl client Kubectl replace should update a single-container pod's image [Conformance]",
                "[sig-cli] Kubectl client Kubectl run pod should create a pod from an image when restart is Never [Conformance]",
                "[sig-cli] Kubectl client Kubectl server-side dry-run should check if kubectl can dry-run update Pods [Conformance]",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a failing command",
                "[sig-cli] Kubectl client Simple pod Kubectl run running a successful command",
                "[sig-cli] Kubectl client Simple pod should contain last line of the log",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a failing command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes execing into a container with a successful command",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should handle in-cluster config",
                "[sig-cli] Kubectl client Simple pod should return command exit codes should support port-forward",
                "[sig-cli] Kubectl client Simple pod should support exec",
                "[sig-cli] Kubectl client Simple pod should support exec through an HTTP proxy",
                "[sig-cli] Kubectl client Simple pod should support exec through kubectl proxy",
                "[sig-cli] Kubectl client Simple pod should support exec using resource/name",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach",
                "[sig-cli] Kubectl client Simple pod should support inline execution and attach with websockets or fallback to spdy",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles on ephemeral container",
                "[sig-cli] kubectl debug custom profile should be applied on static profiles while copying from pod",
                "[sig-cli] Kubectl exec should be able to execute 1000 times in a container",
                "[sig-cli] Kubectl logs default container logs the second container is the default-container by annotation should log default container if not specified",
                "[sig-cli] Kubectl logs logs should be able to retrieve and filter logs [Conformance]",
                "[sig-cli] Kubectl Port forwarding Shutdown client connection while the remote stream is writing data to the port-forward connection port-forward should keep working after detect broken connection",
                "[sig-cli] Kubectl Port forwarding with a pod being removed should stop port-forwarding",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect from a Pod to a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to connect to other Pod from a terminating Pod",
                "[sig-network] Connectivity Pod Lifecycle should be able to have zero downtime on a Blue Green deployment using Services and Readiness Gates",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS HostNetwork spec.Hostname field is not silently ignored and is used for hostname for a Pod",
                "[sig-network] DNS HostNetwork spec.Hostname field is silently ignored and the node hostname is used when hostNetwork is set to true for a Pod",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Hostname [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Conformance]",
                "[sig-network] DNS should provide DNS for the cluster [Provider:GCE]",
                "[sig-network] DNS should provide /etc/hosts entries for the cluster [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for the cluster [LinuxOnly]",
                "[sig-network] DNS should support configurable pod DNS nameservers [Conformance]",
                "[sig-network] DNS should support configurable pod resolv.conf",
                "[sig-network] DNS should work with a search path containing an underscore and a search path with a single dot",
                "[sig-network] DNS should work with the pod containing more than 6 DNS search paths and longer than 256 search list characters",
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoint with multiple subsets and same IP address",
                "[sig-network] EndpointSlice should create Endpoints and EndpointSlices for Pods matching a Service [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple endpoint IPs specified in multiple EndpointSlices [Conformance]",
                "[sig-network] EndpointSlice should support a Service with multiple ports specified in multiple EndpointSlices [Conformance]",
                "[sig-network] HostPort validates that there is no conflict between pods with same hostPort but different hostIP and protocol [LinuxOnly] [Conformance]",
                "[sig-network] KubeProxy should set TCP CLOSE_WAIT timeout [Privileged]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: http [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for intra-pod communication: udp [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: http [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Pods should function for node-pod communication: udp [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service Proxy [Conformance]",
                "[sig-network] Proxy version v1 A set of valid responses are returned for both pod and service ProxyWithPath [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs",
                "[sig-network] Services should allow pods to hairpin back to themselves through services",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is true",
                "[sig-network] Services should be able to create a functioning NodePort service [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be possible to connect to a service via ExternalIP when the external IP is not assigned to a node",
                "[sig-network] Services should be rejected for evicted pods (no endpoints exist)",
                "[sig-network] Services should be rejected when no endpoints exist",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should connect to the named ports exposed by restartable init containers",
                "[sig-network] Services should connect to the ports exposed by restartable init containers",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should fail health check node port if there are only terminating endpoints",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with externalTrafficPolicy=Local",
                "[sig-network] Services should fallback to local terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Local",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with externallTrafficPolicy=Cluster",
                "[sig-network] Services should fallback to terminating endpoints when there are no ready endpoints with internalTrafficPolicy=Cluster",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should not be able to connect to terminating and unready endpoints if PublishNotReadyAddresses is false",
                "[sig-network] Services should preserve source pod IP for traffic thru service cluster IP [LinuxOnly]",
                "[sig-network] Services should release NodePorts on delete",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod and Node, to Pod (hostNetwork: true)",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod (hostNetwork: true) to Pod",
                "[sig-network] Services should respect internalTrafficPolicy=Local Pod to Pod",
                "[sig-network] Services should serve a basic endpoint from pods [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocol for internal traffic on Type LoadBalancer",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should serve multiport endpoints from pods [Conformance]",
                "[sig-network] Services should support externalTrafficPolicy=Local for type=NodePort",
                "[sig-network] Services should support named targetPorts that resolve to different ports on different endpoints",
                "[sig-network] Services should work after the service has been recreated",
                "[sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified in annotations",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the container",
                "[sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile specified on the pod",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message as empty when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from file when pod succeeds and TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message from log output if TerminationMessagePolicy FallbackToLogsOnError is set [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set as non-root user and at a non-default path [NodeConformance] [Conformance]",
                "[sig-node] Container Runtime blackbox test on terminated container should report termination message if TerminationMessagePath is set [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should be able to pull image [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull from private registry without secret [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when running a container with a new image should not be able to pull image from invalid registry [NodeConformance]",
                "[sig-node] Container Runtime blackbox test when starting a container that exits should run with the expected status [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] crictl should be able to run crictl on the node",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Events should be sent by kubelets and the scheduler about pods scheduling and running",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/healthz RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is accessible via nodes/proxy RBAC",
                "[sig-node] [FeatureGate:KubeletFineGrainedAuthz] [Beta] when calling kubelet API check /healthz enpoint is not accessible via nodes/configz RBAC",
                "[sig-node] KubeletManagedEtcHosts should test kubelet managed /etc/hosts file [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command that always fails in a pod should have an terminated reason [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Lifecycle sleep action zero value when create a pod with lifecycle hook using sleep action with a duration of zero seconds prestop hook using sleep action with zero duration",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action ignore terminated container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Mount propagation should propagate mounts within defined scopes",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests BestEffort pod - request memory",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - nonrestartable initContainer",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu & memory limits + increase requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - remove memory requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - reorder containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - resize ephemeral storage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Burstable pod - set requests == limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - remove cpu & memory limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] apply invalid resize patch requests Guaranteed pod - rename containers",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy no restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended 6 containers - various operations performed (including adding limits and requests)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - extended resize with equivalents",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] decrease memory limit below usage",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase: CPU (c1,c3), memory (c2, c3) ; decrease: CPU (c2)",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, c2, decrease cpu & mem on c3 - net increase",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed pods with multiple containers 3 containers - increase cpu & mem on c1, decrease cpu & mem on c2, c3 - net decrease",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test exceed maximum Memory and CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min CPU and min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test request below min Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid decrease of Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (limit-ranger) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-limit-ranger-test valid increase of Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-node] PodOSRejection [NodeConformance] Kubelet [LinuxOnly] should reject pod when the node OS doesn't match pod's OS",
                "[sig-node] PodRejectionStatus Kubelet should reject pod when the node didn't have enough resource",
                "[sig-node] Pods Extended Delete Grace Period should be submitted and removed",
                "[sig-node] Pods Extended Pod Container lifecycle evicted pods should be terminal",
                "[sig-node] Pods Extended Pod Container lifecycle should not create extra sandbox if all containers are done",
                "[sig-node] Pods Extended Pods Set QOS Class should be set on Pods with matching resource requests and limits for memory and cpu [Conformance]",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be submitted and removed [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should get a host IP [NodeConformance] [Conformance]",
                "[sig-node] Pods should patch a pod status [Conformance]",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]",
                "[sig-node] Pods should support pod readiness gates [NodeConformance]",
                "[sig-node] Pods should support remote command execution over websockets [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] PreStop graceful pod terminated should wait until preStop hook completes the process",
                "[sig-node] PreStop should call prestop when killing a pod [Conformance]",
                "[sig-node] PrivilegedPod [NodeConformance] should enable privileged commands [LinuxOnly]",
                "[sig-node] Probing container should be ready immediately after startupProbe succeeds",
                "[sig-node] Probing container should be restarted by liveness probe after startup probe enables it",
                "[sig-node] Probing container should be restarted startup probe fails",
                "[sig-node] Probing container should be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a failing exec liveness probe that took longer than the timeout",
                "[sig-node] Probing container should be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should be restarted with a local redirect http liveness probe",
                "[sig-node] Probing container should be restarted with an exec liveness probe with timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should have monotonically increasing restart count [NodeConformance] [Conformance]",
                "[sig-node] Probing container should not be ready with an exec readiness probe timeout [MinimumKubeletVersion:1.20] [NodeConformance]",
                "[sig-node] Probing container should *not* be restarted by liveness probe because startup probe delays it",
                "[sig-node] Probing container should *not* be restarted with a exec \"cat /tmp/health\" liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a GRPC liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a /healthz http liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should *not* be restarted with a non-local redirect http liveness probe",
                "[sig-node] Probing container should *not* be restarted with a tcp:8080 liveness probe [NodeConformance] [Conformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when LivenessProbe field is set [NodeConformance]",
                "[sig-node] Probing container should override timeoutGracePeriodSeconds when StartupProbe field is set [NodeConformance]",
                "[sig-node] Probing container with readiness probe should not be ready before initial delay and never restart [NodeConformance] [Conformance]",
                "[sig-node] Probing container with readiness probe that fails should never be ready and never restart [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a container with runAsUser should run the container with uid 65534 [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with readonly rootfs when readOnlyRootFilesystem=true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context When creating a pod with readOnlyRootFilesystem should run the container with writable rootfs when readOnlyRootFilesystem=false [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should not launch unsafe, but not explicitly enabled sysctls on the node [MinimumKubeletVersion:1.21]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with absolute path [Conformance]",
                "[sig-node] Variable Expansion should fail substituting values in a volume subpath with backticks [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSIInlineVolumes should support CSIVolumeSource in Pod API [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes pod should support memory backed volumes of specified size",
                "[sig-storage] EmptyDir volumes pod should support shared volumes between containers [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                "[sig-storage] EmptyDir wrapper volumes should not conflict [Conformance]",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : configmap",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : projected",
                "[sig-storage] Ephemeralstorage When pod refers to non-existent ephemeral storage should allow deletion of pod with invalid volume : secret",
                "[sig-storage] Flexvolumes should be mountable when non-attachable",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPod",
            "conf_tested": true,
            "description": "read the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/ephemeralcontainers",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPodEphemeralcontainers",
            "conf_tested": true,
            "description": "read ephemeralcontainers of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/log",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should delete jobs and pods created by cronjob",
                "[sig-api-machinery] Garbage collector should delete pods created by rc when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should delete RS created by deployment when not orphaning [Conformance]",
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan RS created by deployment when deleteOptions.PropagationPolicy is Orphan [Conformance]",
                "[sig-auth] ServiceAccounts ServiceAccountIssuerDiscovery should support OIDC discovery of service account issuer [Conformance]",
                "[sig-auth] ServiceAccounts should mount projected service account token [Conformance]",
                "[sig-auth] ServiceAccounts should set ownership and permission when RunAsUser or FsGroup is present [LinuxOnly]",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on 0.0.0.0 that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost should support forwarding over websockets",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects a client request should support a client that connects, sends NO DATA, and disconnects",
                "[sig-cli] Kubectl Port forwarding With a server listening on localhost that expects NO client request should support a client that connects, sends DATA, and disconnects",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a ControllerManager.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Kubelet.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from API server.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics from a Scheduler.",
                "[sig-instrumentation] MetricsGrabber should grab all metrics slis from API server.",
                "[sig-instrumentation] Metrics should grab all metrics from kubelet /metrics/resource endpoint",
                "[sig-network] Conntrack proxy implementation should not be vulnerable to the invalid conntrack state bug [Privileged]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when initial unready endpoints get ready",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service and client is hostNetwork",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a ClusterIP service with InternalTrafficPolicy set to Local",
                "[sig-network] Conntrack should be able to preserve UDP traffic when server pod cycles for a NodePort service",
                "[sig-network] DNS HostNetwork should resolve DNS of partial qualified names for services on hostNetwork pods with dnsPolicy: ClusterFirstWithHostNet [LinuxOnly]",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] DNS should provide DNS for pods for Subdomain [Conformance]",
                "[sig-network] DNS should provide DNS for services [Conformance]",
                "[sig-network] DNS should resolve DNS of partial qualified names for services [LinuxOnly] [Conformance]",
                "[sig-node] ConfigMap should be consumable as environment variable names with various prefixes [Conformance]",
                "[sig-node] ConfigMap should be consumable via environment variable [NodeConformance] [Conformance]",
                "[sig-node] ConfigMap should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute poststart https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop exec hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop http hook properly [NodeConformance] [Conformance]",
                "[sig-node] Container Lifecycle Hook when create a pod with lifecycle hook should execute prestop https hook properly [MinimumKubeletVersion:1.23] [NodeConformance]",
                "[sig-node] Containers should be able to override the image's default arguments (container cmd) [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command and arguments [NodeConformance] [Conformance]",
                "[sig-node] Containers should be able to override the image's default command (container entrypoint) [NodeConformance] [Conformance]",
                "[sig-node] Containers should use the image defaults if command and args are blank [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide container's limits.cpu/memory and requests.cpu/memory as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide default limits.cpu/memory from node allocatable [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide host IP and pod IP as an env var if pod uses host network [LinuxOnly]",
                "[sig-node] Downward API should provide host IP as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide hostIPs as an env var [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod name, namespace and IP address as env vars [NodeConformance] [Conformance]",
                "[sig-node] Downward API should provide pod UID as env vars [NodeConformance] [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]",
                "[sig-node] Ephemeral Containers [NodeConformance] will start an ephemeral container in an existing pod [Conformance]",
                "[sig-node] Kubelet when scheduling a busybox command in a pod should print the output to logs [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling an agnhost Pod with hostAliases should write entries to /etc/hosts [NodeConformance] [Conformance]",
                "[sig-node] Kubelet when scheduling a read only busybox container should not write to root filesystem [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Kubelet with pods in a privileged namespace when scheduling an agnhost Pod with hostAliases and hostNetwork should write entries to /etc/hosts when hostNetwork is enabled [NodeConformance]",
                "[sig-node] Pods should contain environment variables for services [NodeConformance] [Conformance]",
                "[sig-node] Pods should support retrieving logs from the container over websockets [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable as environment variable names variable names with various prefixes [Conformance]",
                "[sig-node] Secrets should be consumable from pods in env vars [NodeConformance] [Conformance]",
                "[sig-node] Secrets should be consumable via the environment [NodeConformance] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser And container.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support container.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser And pod.Spec.SecurityContext.RunAsGroup [LinuxOnly] [Conformance]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.RunAsUser [LinuxOnly]",
                "[sig-node] Security Context should support pod.Spec.SecurityContext.SupplementalGroups [LinuxOnly]",
                "[sig-node] Security Context should support seccomp default which is unconfined [LinuxOnly]",
                "[sig-node] Security Context should support seccomp runtime/default [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the container [LinuxOnly]",
                "[sig-node] Security Context should support seccomp unconfined on the pod [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an explicit non-root user ID [LinuxOnly]",
                "[sig-node] Security Context When creating a container with runAsNonRoot should run with an image specified user ID",
                "[sig-node] Security Context When creating a pod with privileged should run the container as unprivileged when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when not explicitly set and uid != 0 [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should allow privilege escalation when true [LinuxOnly] [NodeConformance]",
                "[sig-node] Security Context when creating containers with AllowPrivilegeEscalation should not allow privilege escalation when false [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-node] Security Context when if the container's primary UID belongs to some groups in the image [LinuxOnly] should add pod.Spec.SecurityContext.SupplementalGroups to them [LinuxOnly] in resultant supplementary groups for the container processes",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls [MinimumKubeletVersion:1.21] [Environment:NotInUserNS] [Conformance]",
                "[sig-node] Sysctls [LinuxOnly] [NodeConformance] should support sysctls with slashes as separator [MinimumKubeletVersion:1.23] [Environment:NotInUserNS]",
                "[sig-node] Variable Expansion allow almost all printable ASCII characters as environment variable names",
                "[sig-node] Variable Expansion should allow composing env vars into new env vars [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's args [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a container's command [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should allow substituting values in a volume subpath [Conformance]",
                "[sig-storage] ConfigMap binary data should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] ConfigMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: CSI Ephemeral-volume (default fs)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] Downward API volume should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Downward API volume should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (non-root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0644,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0666,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,default) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes should support (root,0777,tmpfs) [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on default medium should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes volume on tmpfs should have the correct mode [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] files with FSGroup ownership should support (root,0644,tmpfs)",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is non-root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] new files should be created with FSGroup ownership when container is root",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] nonexistent volume subPath should have the correct mode and owner using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on default medium should have the correct mode using FSGroup",
                "[sig-storage] EmptyDir volumes when FSGroup is specified [LinuxOnly] volume on tmpfs should have the correct mode using FSGroup",
                "[sig-storage] HostPath should give a volume the correct mode [LinuxOnly] [NodeConformance]",
                "[sig-storage] HostPath should support r/w [NodeConformance]",
                "[sig-storage] HostPath should support subPath [NodeConformance]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: emptydir] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPathSymlink] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: hostPath] [Testpattern: Inline-volume (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Inline-volume (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and use it multiple times in a single pod",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] Projected combined should project all components that make up the projection API [Projection] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings and Item mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings as non-root with FSGroup [LinuxOnly]",
                "[sig-storage] Projected configMap should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap should be consumable in multiple volumes in the same pod [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's cpu request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory limit [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide container's memory request [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (cpu) as default cpu limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide node allocatable (memory) as default memory limit if the limit is not set [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup and defaultMode [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname as non-root with fsgroup [LinuxOnly]",
                "[sig-storage] Projected downwardAPI should provide podname only [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set DefaultMode on files [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should set mode on item file [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Projected secret should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be able to mount in a volume regardless of a different secret existing with same name in different namespace [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume as non-root with defaultMode and fsGroup set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with defaultMode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings and Item Mode set [LinuxOnly] [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable from pods in volume with mappings [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be consumable in multiple volumes in a pod [NodeConformance] [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with configmap pod with mountPath of existing file [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with downward pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with projected pod [Conformance]",
                "[sig-storage] Subpath Atomic writer volumes should support subpaths with secret pod [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPodLog",
            "conf_tested": true,
            "description": "read log of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/resize",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPodResize",
            "conf_tested": false,
            "description": "read resize of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPodStatus",
            "conf_tested": true,
            "description": "read status of the specified Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodTemplates should replace a pod template [Conformance]",
                "[sig-node] PodTemplates should run the lifecycle of PodTemplates [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedPodTemplate",
            "conf_tested": true,
            "description": "read the specified PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Garbage collector should keep the rc around until all its pods are deleted if the deleteOptions says so [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should not delete dependents that have both valid owner and owner that's waiting for dependents to be deleted [Serial] [Conformance]",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if deleteOptions.OrphanDependents is nil",
                "[sig-api-machinery] Garbage collector should orphan pods created by rc if delete options say so [Serial] [Conformance]",
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-storage] EmptyDir wrapper volumes should not cause race condition when used for configmaps [Serial] [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedReplicationController",
            "conf_tested": true,
            "description": "read the specified ReplicationController"
        },
        {
            "kind": "Scale",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedReplicationControllerScale",
            "conf_tested": true,
            "description": "read scale of the specified ReplicationController"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedReplicationControllerStatus",
            "conf_tested": true,
            "description": "read status of the specified ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against 2 pvcs with same volume attributes class.",
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a configMap. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource.",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a persistent volume claim with a storage class",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replica set. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a replication controller. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a ResourceClaim [FeatureGate:DynamicResourceAllocation] [DRA]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a secret. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a service. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and ensure its status is promptly calculated. [Conformance]",
                "[sig-api-machinery] ResourceQuota should manage the lifecycle of a ResourceQuota [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with best effort scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with cross namespace pod affinity scope using scope-selectors.",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota without scopes",
                "[sig-cli] Kubectl client Kubectl create quota should create a quota with scopes",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test exceed maximum Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase for both CPU and Memory",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of CPU",
                "[sig-node] Pod InPlace Resize Container (resource-quota) [FeatureGate:InPlacePodVerticalScaling] [Beta] pod-resize-resource-quota-test valid increase of Memory",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedResourceQuota",
            "conf_tested": true,
            "description": "read the specified ResourceQuota"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedResourceQuotaStatus",
            "conf_tested": true,
            "description": "read status of the specified ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Secrets should patch a secret [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedSecret",
            "conf_tested": true,
            "description": "read the specified Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "",
                "[sig-api-machinery] Namespaces [Serial] should ensure that all services are removed when a namespace is deleted [Conformance]",
                "[sig-api-machinery] ServerSideApply should create an applied object if it does not already exist",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-cli] Kubectl client Kubectl expose should create services for rc [Conformance]",
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] EndpointSlice should have Endpoints and EndpointSlices pointing to API Server [Conformance]",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: http",
                "[sig-network] Networking Granular Checks: Services should be able to handle large requests: udp",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: http [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for client IP based session affinity: udp [LinuxOnly]",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for endpoint-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for multiple endpoint-Services with same selector",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for node-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: http",
                "[sig-network] Networking Granular Checks: Services should function for pod-Service: udp",
                "[sig-network] Networking Granular Checks: Services should function for service endpoints using hostNetwork",
                "[sig-network] Networking Granular Checks: Services should support basic nodePort: udp functionality",
                "[sig-network] Networking Granular Checks: Services should update endpoints: http",
                "[sig-network] Networking Granular Checks: Services should update endpoints: udp",
                "[sig-network] Networking should check kube-proxy urls",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to up and down services",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should complete a service status lifecycle [Conformance]",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should have session affinity timeout work for NodePort service [LinuxOnly]",
                "[sig-network] Services should have session affinity timeout work for service with type clusterIP [LinuxOnly]",
                "[sig-network] Services should have session affinity work for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should have session affinity work for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should provide secure master service [Conformance]",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]",
                "[sig-network] Services should work after the service has been recreated",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedService",
            "conf_tested": true,
            "description": "read the specified Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts no secret-based service account token should be auto-generated",
                "[sig-auth] ServiceAccounts should run through the lifecycle of a ServiceAccount [Conformance]",
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedServiceAccount",
            "conf_tested": true,
            "description": "read the specified ServiceAccount"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should complete a service status lifecycle [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespacedServiceStatus",
            "conf_tested": true,
            "description": "read status of the specified Service"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NamespaceStatus",
            "conf_tested": true,
            "description": "read status of the specified Namespace"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                "[sig-apps] Daemon set [Serial] should list and delete a collection of DaemonSets [Conformance]",
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should run and stop simple daemon [Conformance]",
                "[sig-apps] Daemon set [Serial] should update pod when spec was updated and update strategy is RollingUpdate [Conformance]",
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                "[sig-auth] ServiceAccounts should mount an API token into pods [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] NodeLease NodeLease the kubelet should report node status infrequently",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] NoExecuteTaintManager Multiple Pods [Serial] evicts pods with minTolerationSeconds [Disruptive] [Conformance]",
                "[sig-node] NoExecuteTaintManager Single Pod [Serial] removing taint cancels eviction [Disruptive] [Conformance]",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu & mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing cpu requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy cpu restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing all resources in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem limits",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing mem requests",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] burstable pods - 1 container with all requests & limits set and resize policy mem restart resizing requests & limits in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1Node",
            "conf_tested": true,
            "description": "read the specified Node"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1NodeStatus",
            "conf_tested": false,
            "description": "read status of the specified Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should block a second pod from using an in-use ReadWriteOncePod volume on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] read-write-once-pod [MinimumKubeletVersion:1.27] should preempt lower priority pods using ReadWriteOncePod volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: blockfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (block volmode)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (ext4)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: block] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link-bindmounted] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir-link] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: dir] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: local] [LocalVolumeType: tmpfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should be able to unmount after the subpath directory is deleted [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directories when readOnly specified in the volumeSource",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing directory",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support existing single file [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support file as subpath [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support non-existent path",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly directory specified in the volumeMount",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] subPath should support readOnly file specified in the volumeMount [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read-only inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should create read/write inline ephemeral volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support multiple inline ephemeral volumes",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support two pods which have the same volume definition",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should allow exec of files on the volume",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (default fs)] volumes should store data",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Pre-provisioned PV (filesystem volmode)] volumeMode should not mount / map unused volumes in a pod [LinuxOnly]",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity",
                "[sig-storage] PersistentVolumes-local Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeSelector",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: blockfswithoutformat] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: block] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link-bindmounted] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir-link] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: dir] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and read from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] One pod requesting one prebound PVC should be able to mount volume and write from pod1",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume at the same time should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes-local [Volume type: tmpfs] Two pods mounting a local volume one after the other should be able to write from pod1 and read from pod2",
                "[sig-storage] PersistentVolumes NFS when invoking the Recycle reclaim policy should test that a PV becomes Available and is clean after the PVC is deleted.",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 2 PVs and 4 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with multiple PVs and PVCs all in same ns should create 3 PVs and 3 PVCs: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp is set",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test phase transition timestamp multiple updates",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV and a pre-bound PVC: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and a pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PVC and non-pre-bound PV: test write access",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs create a PV: test phase transition timestamp is set and phase is Available",
                "[sig-storage] PersistentVolumes NFS with Single PV - PVC pairs should create a non-pre-bound PV and PVC: test write access",
                "[sig-storage] PV Protection Verify \"immediate\" deletion of a PV that is not bound to a PVC",
                "[sig-storage] PV Protection Verify that PV bound to a PVC is not removed immediately",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1PersistentVolume",
            "conf_tested": true,
            "description": "read the specified PersistentVolume"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "readCoreV1PersistentVolumeStatus",
            "conf_tested": true,
            "description": "read status of the specified PersistentVolume"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices/{name}",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "readDiscoveryV1NamespacedEndpointSlice",
            "conf_tested": true,
            "description": "read the specified EndpointSlice"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events/{name}",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "readEventsV1NamespacedEvent",
            "conf_tested": true,
            "description": "read the specified Event"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should ensure that requests can be classified by adding FlowSchema and PriorityLevelConfiguration",
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "readFlowcontrolApiserverV1FlowSchema",
            "conf_tested": true,
            "description": "read the specified FlowSchema"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}/status",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "readFlowcontrolApiserverV1FlowSchemaStatus",
            "conf_tested": true,
            "description": "read status of the specified FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "readFlowcontrolApiserverV1PriorityLevelConfiguration",
            "conf_tested": true,
            "description": "read the specified PriorityLevelConfiguration"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}/status",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "readFlowcontrolApiserverV1PriorityLevelConfigurationStatus",
            "conf_tested": true,
            "description": "read status of the specified PriorityLevelConfiguration"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1IngressClass",
            "conf_tested": true,
            "description": "read the specified IngressClass"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1IPAddress",
            "conf_tested": true,
            "description": "read the specified IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1NamespacedIngress",
            "conf_tested": true,
            "description": "read the specified Ingress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}/status",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1NamespacedIngressStatus",
            "conf_tested": true,
            "description": "read status of the specified Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1NamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "read the specified NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]",
                "[sig-network] Service CIDRs should create Services and serve on different Service CIDRs"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1ServiceCIDR",
            "conf_tested": true,
            "description": "read the specified ServiceCIDR"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}/status",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support ServiceCIDR API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "readNetworkingV1ServiceCIDRStatus",
            "conf_tested": true,
            "description": "read status of the specified ServiceCIDR"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses/{name}",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass [NodeConformance] [Conformance]",
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "readNodeV1RuntimeClass",
            "conf_tested": true,
            "description": "read the specified RuntimeClass"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController evictions: enough pods, absolute => should allow an eviction",
                "[sig-apps] DisruptionController evictions: enough pods, replicaSet, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: maxUnavailable allow single eviction, percentage => should allow an eviction",
                "[sig-apps] DisruptionController evictions: too few pods, absolute => should not allow an eviction",
                "[sig-apps] DisruptionController Listing PodDisruptionBudgets for all namespaces should list and delete a collection of PodDisruptionBudgets [Conformance]",
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should evict ready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict ready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should evict unready pods with AlwaysAllow UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with Default UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should not evict unready pods with IfHealthyBudget UnhealthyPodEvictionPolicy",
                "[sig-apps] DisruptionController should observe PodDisruptionBudget status updated [Conformance]",
                "[sig-apps] DisruptionController should observe that the PodDisruptionBudget status is not updated for unmanaged pods",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "readPolicyV1NamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "read the specified PodDisruptionBudget"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}/status",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]",
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "readPolicyV1NamespacedPodDisruptionBudgetStatus",
            "conf_tested": true,
            "description": "read status of the specified PodDisruptionBudget"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "readRbacAuthorizationV1ClusterRole",
            "conf_tested": false,
            "description": "read the specified ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "readRbacAuthorizationV1ClusterRoleBinding",
            "conf_tested": false,
            "description": "read the specified ClusterRoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "readRbacAuthorizationV1NamespacedRole",
            "conf_tested": false,
            "description": "read the specified Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "readRbacAuthorizationV1NamespacedRoleBinding",
            "conf_tested": false,
            "description": "read the specified RoleBinding"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "readResourceV1DeviceClass",
            "conf_tested": false,
            "description": "read the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "readResourceV1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "read the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "readResourceV1NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "read status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "readResourceV1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "read the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "readResourceV1ResourceSlice",
            "conf_tested": false,
            "description": "read the specified ResourceSlice"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses/{name}",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "readSchedulingV1PriorityClass",
            "conf_tested": true,
            "description": "read the specified PriorityClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1CSIDriver",
            "conf_tested": true,
            "description": "read the specified CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should not pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock fsgroup as mount option Delegate FSGroup to CSI driver [LinuxOnly] should pass FSGroup to CSI driver if it is set in pod and driver supports VOLUME_MOUNT_GROUP",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Dynamic provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv delete reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pvc then pv",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy using mock driver Static provisioning should honor pv retain reclaim policy when deleting pv then pvc",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should modify fsGroup if fsGroupPolicy=File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy [LinuxOnly] should not modify fsGroup if fsGroupPolicy=None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should be plumbed down when csiServiceAccountTokenEnabled=true",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when CSIDriver is not deployed",
                "[sig-storage] CSI Mock volume service account token CSIServiceAccountToken token should not be plumbed down when csiServiceAccountTokenEnabled=false",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, immediate binding",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, no topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity exhausted, late binding, with topology",
                "[sig-storage] CSI Mock volume storage capacity storage capacity unlimited",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver contain ephemeral=true when using inline volume",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should be passed when podInfoOnMount=true",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when CSIDriver does not exist",
                "[sig-storage] CSI Mock workload info CSI workload information using mock driver should not be passed when podInfoOnMount=false",
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (filesystem volmode)] volumeLimits should verify that all csinodes have volume limits",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1CSINode",
            "conf_tested": true,
            "description": "read the specified CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1NamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "read the specified CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity disabled",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity unused",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, have capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, insufficient capacity",
                "[sig-storage] CSI Mock volume storage capacity CSIStorageCapacity CSIStorageCapacity used, no capacity",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs3] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should mount multiple PV pointing to the same storage on the same node",
                "[sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with mount options",
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1StorageClass",
            "conf_tested": true,
            "description": "read the specified StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should not require VolumeAttach for drivers without attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should preserve attachment policy when no CSIDriver present",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for drivers with attachment",
                "[sig-storage] CSI Mock volume attach CSI attach test using mock driver should require VolumeAttach for ephemermal volume and drivers with attachment",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] provisioning should provision storage with pvc data source",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] provisioning should provision storage with pvc data source",
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]",
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]",
                null
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1VolumeAttachment",
            "conf_tested": true,
            "description": "read the specified VolumeAttachment"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}/status",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1VolumeAttachmentStatus",
            "conf_tested": true,
            "description": "read status of the specified VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]"
            ],
            "action": "get",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "readStorageV1VolumeAttributesClass",
            "conf_tested": true,
            "description": "read the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/mutatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a mutating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update mutating webhook configurations with match conditions [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1MutatingWebhookConfiguration",
            "conf_tested": true,
            "description": "replace the specified MutatingWebhookConfiguration"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1ValidatingAdmissionPolicy",
            "conf_tested": true,
            "description": "replace the specified ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicyBinding API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1ValidatingAdmissionPolicyBinding",
            "conf_tested": true,
            "description": "replace the specified ValidatingAdmissionPolicyBinding"
        },
        {
            "kind": "ValidatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingadmissionpolicies/{name}/status",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ValidatingAdmissionPolicy [Privileged:ClusterAdmin] should support ValidatingAdmissionPolicy API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1ValidatingAdmissionPolicyStatus",
            "conf_tested": true,
            "description": "replace status of the specified ValidatingAdmissionPolicy"
        },
        {
            "kind": "ValidatingWebhookConfiguration",
            "path": "/apis/admissionregistration.k8s.io/v1/validatingwebhookconfigurations/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] patching/updating a validating webhook should work [Conformance]",
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to create and update validating webhook configurations with match conditions [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1ValidatingWebhookConfiguration",
            "conf_tested": true,
            "description": "replace the specified ValidatingWebhookConfiguration"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST evaluate a CRD Validation Rule with oldSelf = nil for new values when optionalOldSelf is true",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to CRD Validation Rule errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on changed fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST fail to update a resource due to JSONSchema errors on unchanged uncorrelatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to CRD Validation Rule errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT fail to update a resource due to JSONSchema errors on unchanged correlatable fields",
                "[sig-api-machinery] CRDValidationRatcheting [Privileged:ClusterAdmin] [FeatureGate:CRDValidationRatcheting] MUST NOT ratchet errors raised by transition rules",
                "[sig-api-machinery] CustomResourceConversionWebhook [Privileged:ClusterAdmin] should be able to convert a non homogeneous list of CRs [Conformance]",
                "[sig-api-machinery] CustomResourcePublishOpenAPI [Privileged:ClusterAdmin] removes definition from spec when one version gets changed to not be served [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "replaceApiextensionsV1CustomResourceDefinition",
            "conf_tested": true,
            "description": "replace the specified CustomResourceDefinition"
        },
        {
            "kind": "CustomResourceDefinition",
            "path": "/apis/apiextensions.k8s.io/v1/customresourcedefinitions/{name}/status",
            "group": "apiextensions.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] CustomResourceDefinition resources [Privileged:ClusterAdmin] Simple CustomResourceDefinition getting/updating/patching custom resource definition status sub-resource works [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiextensions",
            "endpoint": "replaceApiextensionsV1CustomResourceDefinitionStatus",
            "conf_tested": true,
            "description": "replace status of the specified CustomResourceDefinition"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "replaceApiregistrationV1APIService",
            "conf_tested": true,
            "description": "replace the specified APIService"
        },
        {
            "kind": "APIService",
            "path": "/apis/apiregistration.k8s.io/v1/apiservices/{name}/status",
            "group": "apiregistration.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Aggregator Should be able to support the 1.17 Sample API Server using the current Aggregator [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apiregistration",
            "endpoint": "replaceApiregistrationV1APIServiceStatus",
            "conf_tested": true,
            "description": "replace status of the specified APIService"
        },
        {
            "kind": "ControllerRevision",
            "path": "/apis/apps/v1/namespaces/{namespace}/controllerrevisions/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ControllerRevision [Serial] should manage the lifecycle of a ControllerRevision [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedControllerRevision",
            "conf_tested": true,
            "description": "replace the specified ControllerRevision"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should rollback without unnecessary restarts [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedDaemonSet",
            "conf_tested": true,
            "description": "replace the specified DaemonSet"
        },
        {
            "kind": "DaemonSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/daemonsets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should verify changes to a daemon set status [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedDaemonSetStatus",
            "conf_tested": true,
            "description": "replace status of the specified DaemonSet"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ServerSideApply should give up ownership of a field if forced applied by a controller",
                "[sig-apps] Deployment deployment should support proportional scaling [Conformance]",
                "[sig-apps] Deployment deployment should support rollover [Conformance]",
                "[sig-apps] Deployment iterative rollouts should eventually progress",
                "[sig-apps] Deployment RecreateDeployment should delete old pods and create new ones [Conformance]",
                "[sig-apps] Deployment should not disrupt a cloud load-balancer's connectivity during rollout",
                "[sig-apps] Deployment should run the lifecycle of a Deployment [Conformance]",
                "[sig-network] Services should create endpoints for unready pods",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedDeployment",
            "conf_tested": true,
            "description": "replace the specified Deployment"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment Deployment should have a working scale subresource [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedDeploymentScale",
            "conf_tested": true,
            "description": "replace scale of the specified Deployment"
        },
        {
            "kind": "Deployment",
            "path": "/apis/apps/v1/namespaces/{namespace}/deployments/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] Deployment should validate Deployment Status endpoints [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedDeploymentStatus",
            "conf_tested": true,
            "description": "replace status of the specified Deployment"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet Replace and Patch tests [Conformance]",
                "[sig-apps] ReplicaSet should surface a failure condition on a common issue like exceeded quota",
                "[sig-node] [DRA] control plane [ConformanceCandidate] must deallocate after use",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after creating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports claim and class parameters",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple containers of multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports external claim referenced by multiple pods",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports init containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports inline claim referenced by multiple containers",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports reusing resources",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports sharing a claim concurrently",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing external resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] supports simple pod referencing inline resource claim",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with different ResourceSlices keeps pod pending because of CEL runtime errors",
                "[sig-node] [DRA] control plane [ConformanceCandidate] with node-local resources uses all resources",
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] control plane supports count/resourceclaims.resource.k8s.io ResourceQuota [ConformanceCandidate]",
                "[sig-node] [DRA] control plane truncates the name of a generated resource claim [ConformanceCandidate]",
                "[sig-node] [DRA] control plane validate ResourceClaimTemplate and ResourceClaim for admin access [FeatureGate:DRAAdminAccess] [Beta]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedReplicaSet",
            "conf_tested": true,
            "description": "replace the specified ReplicaSet"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet Replicaset should have a working scale subresource [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedReplicaSetScale",
            "conf_tested": true,
            "description": "replace scale of the specified ReplicaSet"
        },
        {
            "kind": "ReplicaSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/replicasets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicaSet should validate Replicaset Status endpoints [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedReplicaSetStatus",
            "conf_tested": true,
            "description": "replace status of the specified ReplicaSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet AvailableReplicas should get updated accordingly when MinReadySeconds is enabled",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Burst scaling should run to completion even with unhealthy pods [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Scaling should happen in predictable order and halt if any stateful pod is unhealthy [Slow] [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should implement legacy replacement when the update strategy is OnDelete",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform rolling updates and roll backs of template modifications [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] Should recreate evicted statefulset [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Decreasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Increasing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Removing .start.ordinal",
                "[sig-apps] StatefulSet Scaling StatefulSetStartOrdinal Setting .start.ordinal"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedStatefulSet",
            "conf_tested": true,
            "description": "replace the specified StatefulSet"
        },
        {
            "kind": "Scale",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should have a working scale subresource [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedStatefulSetScale",
            "conf_tested": true,
            "description": "replace scale of the specified StatefulSet"
        },
        {
            "kind": "StatefulSet",
            "path": "/apis/apps/v1/namespaces/{namespace}/statefulsets/{name}/status",
            "group": "apps",
            "level": "stable",
            "tests": [
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should validate Statefulset Status endpoints [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "apps",
            "endpoint": "replaceAppsV1NamespacedStatefulSetStatus",
            "conf_tested": true,
            "description": "replace status of the specified StatefulSet"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "replaceAutoscalingV1NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "replace the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v1/namespaces/{namespace}/horizontalpodautoscalers/{name}/status",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "autoscaling",
            "endpoint": "replaceAutoscalingV1NamespacedHorizontalPodAutoscalerStatus",
            "conf_tested": false,
            "description": "replace status of the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "replaceAutoscalingV2NamespacedHorizontalPodAutoscaler",
            "conf_tested": false,
            "description": "replace the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "HorizontalPodAutoscaler",
            "path": "/apis/autoscaling/v2/namespaces/{namespace}/horizontalpodautoscalers/{name}/status",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v2",
            "category": "autoscaling",
            "endpoint": "replaceAutoscalingV2NamespacedHorizontalPodAutoscalerStatus",
            "conf_tested": false,
            "description": "replace status of the specified HorizontalPodAutoscaler"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "replaceBatchV1NamespacedCronJob",
            "conf_tested": true,
            "description": "replace the specified CronJob"
        },
        {
            "kind": "CronJob",
            "path": "/apis/batch/v1/namespaces/{namespace}/cronjobs/{name}/status",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] CronJob should support CronJob API operations [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "replaceBatchV1NamespacedCronJobStatus",
            "conf_tested": true,
            "description": "replace status of the specified CronJob"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should delete pods when suspended",
                "[sig-apps] Job should manage the lifecycle of a job [Conformance]",
                "[sig-apps] Job should not create pods when created in suspend state",
                "[sig-apps] Job should update the status ready field",
                "[sig-apps] TTLAfterFinished job should be deleted once it finishes after TTL seconds"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "replaceBatchV1NamespacedJob",
            "conf_tested": true,
            "description": "replace the specified Job"
        },
        {
            "kind": "Job",
            "path": "/apis/batch/v1/namespaces/{namespace}/jobs/{name}/status",
            "group": "batch",
            "level": "stable",
            "tests": [
                "[sig-apps] Job should apply changes to a job status [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "batch",
            "endpoint": "replaceBatchV1NamespacedJobStatus",
            "conf_tested": true,
            "description": "replace status of the specified Job"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1CertificateSigningRequest",
            "conf_tested": true,
            "description": "replace the specified CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}/approval",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support building a client with a CSR",
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1CertificateSigningRequestApproval",
            "conf_tested": true,
            "description": "replace approval of the specified CertificateSigningRequest"
        },
        {
            "kind": "CertificateSigningRequest",
            "path": "/apis/certificates.k8s.io/v1/certificatesigningrequests/{name}/status",
            "group": "certificates.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-auth] Certificates API [Privileged:ClusterAdmin] should support CSR API operations [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1CertificateSigningRequestStatus",
            "conf_tested": true,
            "description": "replace status of the specified CertificateSigningRequest"
        },
        {
            "kind": "Lease",
            "path": "/apis/coordination.k8s.io/v1/namespaces/{namespace}/leases/{name}",
            "group": "coordination.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] Lease lease API should be available [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "coordination",
            "endpoint": "replaceCoordinationV1NamespacedLease",
            "conf_tested": true,
            "description": "replace the specified Lease"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Namespaces [Serial] should apply an update to a Namespace [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1Namespace",
            "conf_tested": true,
            "description": "replace the specified Namespace"
        },
        {
            "kind": "ConfigMap",
            "path": "/api/v1/namespaces/{namespace}/configmaps/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] AdmissionWebhook [Privileged:ClusterAdmin] should be able to deny pod and configmap creation [Conformance]",
                "[sig-api-machinery] Watchers should be able to restart watching from the last resource version observed by the previous watch [Conformance]",
                "[sig-api-machinery] Watchers should be able to start watching from a specific resource version [Conformance]",
                "[sig-api-machinery] Watchers should observe add, update, and delete watch notifications on configmaps [Conformance]",
                "[sig-api-machinery] Watchers should observe an object deletion if it stops meeting the requirements of the selector [Conformance]",
                "[sig-api-machinery] Watchers should receive events on concurrent watches in same order [Conformance]",
                "[sig-auth] ServiceAccounts should guarantee kube-root-ca.crt exist in any namespace [Conformance]",
                "[sig-auth] ValidatingAdmissionPolicy can restrict access by-node",
                "[sig-node] ConfigMap should update ConfigMap successfully [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] ConfigMap should be immutable if `immutable` field is set [Conformance]",
                "[sig-storage] ConfigMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Projected configMap updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Subpath Container restart should verify that container can restart successfully after configmaps modified",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedConfigMap",
            "conf_tested": true,
            "description": "replace the specified ConfigMap"
        },
        {
            "kind": "Endpoints",
            "path": "/api/v1/namespaces/{namespace}/endpoints/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSliceMirroring should mirror a custom Endpoints resource through create update and delete [Conformance]",
                "[sig-network] Services should test the lifecycle of an Endpoint [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedEndpoints",
            "conf_tested": true,
            "description": "replace the specified Endpoints"
        },
        {
            "kind": "Event",
            "path": "/api/v1/namespaces/{namespace}/events/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events should manage the lifecycle of an event [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedEvent",
            "conf_tested": true,
            "description": "replace the specified Event"
        },
        {
            "kind": "LimitRange",
            "path": "/api/v1/namespaces/{namespace}/limitranges/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-scheduling] LimitRange should create a LimitRange with defaults and ensure pod has those defaults applied. [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedLimitRange",
            "conf_tested": true,
            "description": "replace the specified LimitRange"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion should expand volume without restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI online volume expansion with secret should expand volume without restarting pod if attach=on, nodeExpansion=on, csiNodeExpandSecret=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=off, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume by restarting pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should expand volume without restarting pod if nodeExpansion=off",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not expand volume if resizingOnDriver=off, resizingOnSC=on",
                "[sig-storage] CSI Mock volume expansion CSI Volume expansion should not have staging_path missing in node expand volume pod if attach=on, nodeExpansion=on",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should be possible for node-only expanded volumes with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery recovery should not be possible in partially expanded volumes",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with final error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should allow recovery if controller expansion fails with infeasible error",
                "[sig-storage] CSI Mock volume expansion Expansion with recovery should record target size in allocated resources",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (block volmode)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited and the pod is re-created on the same node after controller resize is finished",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand should resize volume when PVC is edited while pod is using it",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)(allowExpansion)] volume-expand Verify if offline PVC expansion works",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Dynamic PV (default fs)] volume-expand should not allow expansion of pvcs without AllowVolumeExpansion property",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (block volmode) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (immediate-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] CSI Volumes [Driver: csi-hostpath] [Testpattern: Generic Ephemeral-volume (default fs) (late-binding)] ephemeral should support expansion of pvcs created for ephemeral pvcs",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPersistentVolumeClaim",
            "conf_tested": true,
            "description": "replace the specified PersistentVolumeClaim"
        },
        {
            "kind": "PersistentVolumeClaim",
            "path": "/api/v1/namespaces/{namespace}/persistentvolumeclaims/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPersistentVolumeClaimStatus",
            "conf_tested": true,
            "description": "replace status of the specified PersistentVolumeClaim"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] OrderedNamespaceDeletion namespace deletion should delete pod first [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a pod. [Conformance]",
                "[sig-api-machinery] ResourceQuota should verify ResourceQuota with terminating scopes through scope selectors.",
                "[sig-apps] Job should adopt matching orphans and release non-matching pods [Conformance]",
                "[sig-apps] ReplicaSet should adopt matching pods on creation and release no longer matching pods [Conformance]",
                "[sig-apps] ReplicationController should release no longer matching pods [Conformance]",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 with failing container",
                "[sig-apps] StatefulSet Basic StatefulSet functionality [StatefulSetBasic] should perform canary updates and phased rolling updates of template modifications for partiton1 and delete pod-0 without failing container",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action reduce GracePeriodSeconds during runtime",
                "[sig-node] Lifecycle Sleep Hook when create a pod with lifecycle hook using sleep action valid prestop hook using sleep action",
                "[sig-node] Pods Extended Pod TerminationGracePeriodSeconds is negative pod with negative grace period",
                "[sig-node] Pods should allow activeDeadlineSeconds to be updated [NodeConformance] [Conformance]",
                "[sig-node] Pods should be updated [NodeConformance] [Conformance]",
                "[sig-node] Variable Expansion should succeed in writing subpaths in container [Conformance]",
                "[sig-node] Variable Expansion should verify that a failing subpath expansion can be modified during the lifecycle of a container [Slow] [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]",
                "[sig-storage] Downward API volume should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Downward API volume should update labels on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update annotations on modification [NodeConformance] [Conformance]",
                "[sig-storage] Projected downwardAPI should update labels on modification [NodeConformance] [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPod",
            "conf_tested": true,
            "description": "replace the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/ephemeralcontainers",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Ephemeral Containers [NodeConformance] should update the ephemeral containers in an existing pod [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPodEphemeralcontainers",
            "conf_tested": true,
            "description": "replace ephemeralcontainers of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/resize",
            "group": "",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPodResize",
            "conf_tested": false,
            "description": "replace resize of the specified Pod"
        },
        {
            "kind": "Pod",
            "path": "/api/v1/namespaces/{namespace}/pods/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should retry creating failed daemon pods [Conformance]",
                "[sig-node] [DRA] control plane [ConformanceCandidate] runs a pod without a generated resource claim",
                "[sig-node] Pods should run through the lifecycle of Pods and PodStatus [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPodStatus",
            "conf_tested": true,
            "description": "replace status of the specified Pod"
        },
        {
            "kind": "PodTemplate",
            "path": "/api/v1/namespaces/{namespace}/podtemplates/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] PodTemplates should replace a pod template [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedPodTemplate",
            "conf_tested": true,
            "description": "replace the specified PodTemplate"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should surface a failure condition on a common issue like exceeded quota [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedReplicationController",
            "conf_tested": true,
            "description": "replace the specified ReplicationController"
        },
        {
            "kind": "Scale",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}/scale",
            "group": "autoscaling",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should get and update a ReplicationController scale [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedReplicationControllerScale",
            "conf_tested": true,
            "description": "replace scale of the specified ReplicationController"
        },
        {
            "kind": "ReplicationController",
            "path": "/api/v1/namespaces/{namespace}/replicationcontrollers/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] ReplicationController should test the lifecycle of a ReplicationController [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedReplicationControllerStatus",
            "conf_tested": true,
            "description": "replace status of the specified ReplicationController"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should be able to update and delete ResourceQuota. [Conformance]",
                "[sig-api-machinery] ResourceQuota should create a ResourceQuota and capture the life of a custom resource."
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedResourceQuota",
            "conf_tested": true,
            "description": "replace the specified ResourceQuota"
        },
        {
            "kind": "ResourceQuota",
            "path": "/api/v1/namespaces/{namespace}/resourcequotas/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota should apply changes to a resourcequota status [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedResourceQuotaStatus",
            "conf_tested": true,
            "description": "replace status of the specified ResourceQuota"
        },
        {
            "kind": "Secret",
            "path": "/api/v1/namespaces/{namespace}/secrets/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] Projected secret optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets optional updates should be reflected in volume [NodeConformance] [Conformance]",
                "[sig-storage] Secrets should be immutable if `immutable` field is set [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedSecret",
            "conf_tested": true,
            "description": "replace the specified Secret"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Conntrack should be able to cleanup conntrack entries when UDP service target port changes for a NodePort service",
                "[sig-network] DNS should provide DNS for ExternalName services [Conformance]",
                "[sig-network] Services should be able to change the type from ClusterIP to ExternalName [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to ClusterIP [Conformance]",
                "[sig-network] Services should be able to change the type from ExternalName to NodePort [Conformance]",
                "[sig-network] Services should be able to change the type from NodePort to ExternalName [Conformance]",
                "[sig-network] Services should be able to switch session affinity for NodePort service [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to switch session affinity for service with type clusterIP [LinuxOnly] [Conformance]",
                "[sig-network] Services should be able to update service type to NodePort listening on same port number but different protocols",
                "[sig-network] Services should be updated after adding or deleting ports",
                "[sig-network] Services should check NodePort out-of-range",
                "[sig-network] Services should create endpoints for unready pods",
                "[sig-network] Services should implement NodePort and HealthCheckNodePort correctly when ExternalTrafficPolicy changes",
                "[sig-network] Services should implement service.kubernetes.io/headless",
                "[sig-network] Services should implement service.kubernetes.io/service-proxy-name",
                "[sig-network] Services should serve endpoints on same port and different protocols [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedService",
            "conf_tested": true,
            "description": "replace the specified Service"
        },
        {
            "kind": "ServiceAccount",
            "path": "/api/v1/namespaces/{namespace}/serviceaccounts/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-auth] ServiceAccounts should update a ServiceAccount [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedServiceAccount",
            "conf_tested": true,
            "description": "replace the specified ServiceAccount"
        },
        {
            "kind": "Service",
            "path": "/api/v1/namespaces/{namespace}/services/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-network] Services should complete a service status lifecycle [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespacedServiceStatus",
            "conf_tested": true,
            "description": "replace status of the specified Service"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}/finalize",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Namespaces [Serial] should apply a finalizer to a Namespace [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespaceFinalize",
            "conf_tested": true,
            "description": "replace finalize of the specified Namespace"
        },
        {
            "kind": "Namespace",
            "path": "/api/v1/namespaces/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] Namespaces [Serial] should apply changes to a namespace status [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NamespaceStatus",
            "conf_tested": true,
            "description": "replace status of the specified Namespace"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-apps] Daemon set [Serial] should run and stop complex daemon [Conformance]",
                "[sig-node] kubelet Clean up pods on node kubelet should be able to delete 10 pods per node in 1m0s.",
                "[sig-node] Node Lifecycle should run through the lifecycle of a node [Conformance]",
                "[sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with scheduling without taints",
                "[sig-scheduling] SchedulerPredicates [Serial] validates resource limits of pods that are allowed to run [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that NodeSelector is respected if matching [Conformance]",
                "[sig-scheduling] SchedulerPredicates [Serial] validates that there exists conflict between pods with same hostPort and protocol but one using 0.0.0.0 hostIP [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1Node",
            "conf_tested": true,
            "description": "replace the specified Node"
        },
        {
            "kind": "Node",
            "path": "/api/v1/nodes/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu & mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy cpu restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy mem restart resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart + resize initContainers resizing mem",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in opposite directions",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing cpu & mem in the same direction",
                "[sig-node] Pod InPlace Resize Container [FeatureGate:InPlacePodVerticalScaling] [Beta] guaranteed qos - 1 container with resize policy no restart resizing mem",
                "[sig-scheduling] SchedulerPreemption [Serial] PreemptionExecutionPath runs ReplicaSets to verify preemption running path [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates basic preemption works [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates lower priority pod preemption by critical pod [Conformance]",
                "[sig-scheduling] SchedulerPreemption [Serial] validates pod disruption condition is added to the preempted pod [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1NodeStatus",
            "conf_tested": true,
            "description": "replace status of the specified Node"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] ResourceQuota [FeatureGate:VolumeAttributesClass] should verify ResourceQuota's volume attributes class scope (quota set to pvc count: 1) against a pvc with different volume attributes class.",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from deleted to retain",
                "[sig-storage] CSI Mock honor pv reclaim policy CSI honor pv reclaim policy changes using mock driver should honor pv reclaim policy after it is changed from retain to deleted",
                "[sig-storage] PersistentVolumes CSI Conformance should run through the lifecycle of a PV and a PVC [Conformance]",
                "[sig-storage] PersistentVolumes-expansion loopback local block volume should support online expansion on node",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1PersistentVolume",
            "conf_tested": true,
            "description": "replace the specified PersistentVolume"
        },
        {
            "kind": "PersistentVolume",
            "path": "/api/v1/persistentvolumes/{name}/status",
            "group": "",
            "level": "stable",
            "tests": [
                "[sig-storage] PersistentVolumes CSI Conformance should apply changes to a pv/pvc status [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "core",
            "endpoint": "replaceCoreV1PersistentVolumeStatus",
            "conf_tested": true,
            "description": "replace status of the specified PersistentVolume"
        },
        {
            "kind": "EndpointSlice",
            "path": "/apis/discovery.k8s.io/v1/namespaces/{namespace}/endpointslices/{name}",
            "group": "discovery.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] EndpointSlice should support creating EndpointSlice API operations [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "discovery",
            "endpoint": "replaceDiscoveryV1NamespacedEndpointSlice",
            "conf_tested": true,
            "description": "replace the specified EndpointSlice"
        },
        {
            "kind": "Event",
            "path": "/apis/events.k8s.io/v1/namespaces/{namespace}/events/{name}",
            "group": "events.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-instrumentation] Events API should ensure that an event can be fetched, patched, deleted, and listed [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "events",
            "endpoint": "replaceEventsV1NamespacedEvent",
            "conf_tested": true,
            "description": "replace the specified Event"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "replaceFlowcontrolApiserverV1FlowSchema",
            "conf_tested": true,
            "description": "replace the specified FlowSchema"
        },
        {
            "kind": "FlowSchema",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/flowschemas/{name}/status",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support FlowSchema API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "replaceFlowcontrolApiserverV1FlowSchemaStatus",
            "conf_tested": true,
            "description": "replace status of the specified FlowSchema"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "replaceFlowcontrolApiserverV1PriorityLevelConfiguration",
            "conf_tested": true,
            "description": "replace the specified PriorityLevelConfiguration"
        },
        {
            "kind": "PriorityLevelConfiguration",
            "path": "/apis/flowcontrol.apiserver.k8s.io/v1/prioritylevelconfigurations/{name}/status",
            "group": "flowcontrol.apiserver.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-api-machinery] API priority and fairness should support PriorityLevelConfiguration API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "flowcontrolApiserver",
            "endpoint": "replaceFlowcontrolApiserverV1PriorityLevelConfigurationStatus",
            "conf_tested": true,
            "description": "replace status of the specified PriorityLevelConfiguration"
        },
        {
            "kind": "IngressClass",
            "path": "/apis/networking.k8s.io/v1/ingressclasses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] IngressClass API should support creating IngressClass API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1IngressClass",
            "conf_tested": true,
            "description": "replace the specified IngressClass"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] ServiceCIDR and IPAddress API should support IPAddress API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1IPAddress",
            "conf_tested": true,
            "description": "replace the specified IPAddress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1NamespacedIngress",
            "conf_tested": true,
            "description": "replace the specified Ingress"
        },
        {
            "kind": "Ingress",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/ingresses/{name}/status",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Ingress API should support creating Ingress API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1NamespacedIngressStatus",
            "conf_tested": true,
            "description": "replace status of the specified Ingress"
        },
        {
            "kind": "NetworkPolicy",
            "path": "/apis/networking.k8s.io/v1/namespaces/{namespace}/networkpolicies/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-network] Netpol API should support creating NetworkPolicy API operations"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1NamespacedNetworkPolicy",
            "conf_tested": false,
            "description": "replace the specified NetworkPolicy"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1ServiceCIDR",
            "conf_tested": false,
            "description": "replace the specified ServiceCIDR"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1/servicecidrs/{name}/status",
            "group": "networking.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1ServiceCIDRStatus",
            "conf_tested": false,
            "description": "replace status of the specified ServiceCIDR"
        },
        {
            "kind": "RuntimeClass",
            "path": "/apis/node.k8s.io/v1/runtimeclasses/{name}",
            "group": "node.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] RuntimeClass should support RuntimeClasses API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "node",
            "endpoint": "replaceNodeV1RuntimeClass",
            "conf_tested": true,
            "description": "replace the specified RuntimeClass"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController should block an eviction until the PDB is updated to allow it [Conformance]",
                "[sig-apps] DisruptionController should create a PodDisruptionBudget [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "replacePolicyV1NamespacedPodDisruptionBudget",
            "conf_tested": true,
            "description": "replace the specified PodDisruptionBudget"
        },
        {
            "kind": "PodDisruptionBudget",
            "path": "/apis/policy/v1/namespaces/{namespace}/poddisruptionbudgets/{name}/status",
            "group": "policy",
            "level": "stable",
            "tests": [
                "[sig-apps] DisruptionController should update/patch PodDisruptionBudget status [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "policy",
            "endpoint": "replacePolicyV1NamespacedPodDisruptionBudgetStatus",
            "conf_tested": true,
            "description": "replace status of the specified PodDisruptionBudget"
        },
        {
            "kind": "ClusterRole",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterroles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "replaceRbacAuthorizationV1ClusterRole",
            "conf_tested": false,
            "description": "replace the specified ClusterRole"
        },
        {
            "kind": "ClusterRoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/clusterrolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "replaceRbacAuthorizationV1ClusterRoleBinding",
            "conf_tested": false,
            "description": "replace the specified ClusterRoleBinding"
        },
        {
            "kind": "Role",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/roles/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "replaceRbacAuthorizationV1NamespacedRole",
            "conf_tested": false,
            "description": "replace the specified Role"
        },
        {
            "kind": "RoleBinding",
            "path": "/apis/rbac.authorization.k8s.io/v1/namespaces/{namespace}/rolebindings/{name}",
            "group": "rbac.authorization.k8s.io",
            "level": "stable",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1",
            "category": "rbacAuthorization",
            "endpoint": "replaceRbacAuthorizationV1NamespacedRoleBinding",
            "conf_tested": false,
            "description": "replace the specified RoleBinding"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane [ConformanceCandidate] retries pod scheduling after updating device class",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 DeviceClass"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "replaceResourceV1DeviceClass",
            "conf_tested": false,
            "description": "replace the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "replaceResourceV1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "replace the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane must be possible for the driver to update the ResourceClaim.Status.Devices once allocated [FeatureGate:DRAResourceClaimDeviceStatus] [Beta]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaim",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "replaceResourceV1NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "replace status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceClaimTemplate"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "replaceResourceV1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "replace the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-node] [DRA] control plane must apply per-node permission checks [ConformanceCandidate]",
                "[sig-node] [DRA] CRUD Tests resource.k8s.io/v1 ResourceSlice"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "resource",
            "endpoint": "replaceResourceV1ResourceSlice",
            "conf_tested": false,
            "description": "replace the specified ResourceSlice"
        },
        {
            "kind": "PriorityClass",
            "path": "/apis/scheduling.k8s.io/v1/priorityclasses/{name}",
            "group": "scheduling.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-scheduling] SchedulerPreemption [Serial] PriorityClass endpoints verify PriorityClass endpoints can be operated with different HTTP methods [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "scheduling",
            "endpoint": "replaceSchedulingV1PriorityClass",
            "conf_tested": true,
            "description": "replace the specified PriorityClass"
        },
        {
            "kind": "CSIDriver",
            "path": "/apis/storage.k8s.io/v1/csidrivers/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIInlineVolumes should run through the lifecycle of a CSIDriver [Conformance]",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from detault to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should not update fsGroup if update from File to None",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from detault to File",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from File to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to default",
                "[sig-storage] CSI Mock volume fsgroup policies CSI FSGroupPolicy Update [LinuxOnly] should update fsGroup if update from None to File",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should be passed when update from false to true",
                "[sig-storage] CSI Mock workload info CSI PodInfoOnMount Update should not be passed when update from true to false"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1CSIDriver",
            "conf_tested": true,
            "description": "replace the specified CSIDriver"
        },
        {
            "kind": "CSINode",
            "path": "/apis/storage.k8s.io/v1/csinodes/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSINodes CSI Conformance should run through the lifecycle of a csinode [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1CSINode",
            "conf_tested": true,
            "description": "replace the specified CSINode"
        },
        {
            "kind": "CSIStorageCapacity",
            "path": "/apis/storage.k8s.io/v1/namespaces/{namespace}/csistoragecapacities/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] CSIStorageCapacity should support CSIStorageCapacities API operations [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1NamespacedCSIStorageCapacity",
            "conf_tested": true,
            "description": "replace the specified CSIStorageCapacity"
        },
        {
            "kind": "StorageClass",
            "path": "/apis/storage.k8s.io/v1/storageclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] StorageClasses CSI Conformance should run through the lifecycle of a StorageClass [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1StorageClass",
            "conf_tested": true,
            "description": "replace the specified StorageClass"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should run through the lifecycle of a VolumeAttachment [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1VolumeAttachment",
            "conf_tested": true,
            "description": "replace the specified VolumeAttachment"
        },
        {
            "kind": "VolumeAttachment",
            "path": "/apis/storage.k8s.io/v1/volumeattachments/{name}/status",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttachment Conformance should apply changes to a volumeattachment status [Conformance]"
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1VolumeAttachmentStatus",
            "conf_tested": true,
            "description": "replace status of the specified VolumeAttachment"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "stable",
            "tests": [
                "[sig-storage] VolumeAttributesClass [FeatureGate:VolumeAttributesClass] should run through the lifecycle of a VolumeAttributesClass [Conformance]",
                null
            ],
            "action": "put",
            "tested": true,
            "release": "1.35.0",
            "version": "v1",
            "category": "storage",
            "endpoint": "replaceStorageV1VolumeAttributesClass",
            "conf_tested": true,
            "description": "replace the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1beta1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "create a MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1beta1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "create a MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "createCertificatesV1beta1ClusterTrustBundle",
            "conf_tested": false,
            "description": "create a ClusterTrustBundle"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "createCoordinationV1beta1NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "create a LeaseCandidate"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "createNetworkingV1beta1IPAddress",
            "conf_tested": false,
            "description": "create an IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "createNetworkingV1beta1ServiceCIDR",
            "conf_tested": false,
            "description": "create a ServiceCIDR"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "createResourceV1beta1DeviceClass",
            "conf_tested": false,
            "description": "create a DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "createResourceV1beta1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "create a ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "createResourceV1beta1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "create a ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "createResourceV1beta1ResourceSlice",
            "conf_tested": false,
            "description": "create a ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "createResourceV1beta2DeviceClass",
            "conf_tested": false,
            "description": "create a DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "createResourceV1beta2NamespacedResourceClaim",
            "conf_tested": false,
            "description": "create a ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "createResourceV1beta2NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "create a ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "createResourceV1beta2ResourceSlice",
            "conf_tested": false,
            "description": "create a ResourceSlice"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "createStorageV1beta1VolumeAttributesClass",
            "conf_tested": false,
            "description": "create a VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1beta1CollectionMutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "delete collection of MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1beta1CollectionMutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "delete collection of MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1beta1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "delete a MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1beta1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "delete a MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1beta1ClusterTrustBundle",
            "conf_tested": false,
            "description": "delete a ClusterTrustBundle"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1beta1CollectionClusterTrustBundle",
            "conf_tested": false,
            "description": "delete collection of ClusterTrustBundle"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "deleteCoordinationV1beta1CollectionNamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "delete collection of LeaseCandidate"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "deleteCoordinationV1beta1NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "delete a LeaseCandidate"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1beta1CollectionIPAddress",
            "conf_tested": false,
            "description": "delete collection of IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1beta1CollectionServiceCIDR",
            "conf_tested": false,
            "description": "delete collection of ServiceCIDR"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1beta1IPAddress",
            "conf_tested": false,
            "description": "delete an IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "deleteNetworkingV1beta1ServiceCIDR",
            "conf_tested": false,
            "description": "delete a ServiceCIDR"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1CollectionDeviceClass",
            "conf_tested": false,
            "description": "delete collection of DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1CollectionNamespacedResourceClaim",
            "conf_tested": false,
            "description": "delete collection of ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1CollectionNamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "delete collection of ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1CollectionResourceSlice",
            "conf_tested": false,
            "description": "delete collection of ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1DeviceClass",
            "conf_tested": false,
            "description": "delete a DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "delete a ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "delete a ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "deleteResourceV1beta1ResourceSlice",
            "conf_tested": false,
            "description": "delete a ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2CollectionDeviceClass",
            "conf_tested": false,
            "description": "delete collection of DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2CollectionNamespacedResourceClaim",
            "conf_tested": false,
            "description": "delete collection of ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2CollectionNamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "delete collection of ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2CollectionResourceSlice",
            "conf_tested": false,
            "description": "delete collection of ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2DeviceClass",
            "conf_tested": false,
            "description": "delete a DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2NamespacedResourceClaim",
            "conf_tested": false,
            "description": "delete a ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "delete a ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "deleteResourceV1beta2ResourceSlice",
            "conf_tested": false,
            "description": "delete a ResourceSlice"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "deleteStorageV1beta1CollectionVolumeAttributesClass",
            "conf_tested": false,
            "description": "delete collection of VolumeAttributesClass"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "deleteStorageV1beta1VolumeAttributesClass",
            "conf_tested": false,
            "description": "delete a VolumeAttributesClass"
        },
        {
            "kind": null,
            "path": "/apis/admissionregistration.k8s.io/v1beta1/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "admissionregistration",
            "endpoint": "getAdmissionregistrationV1beta1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/certificates.k8s.io/v1beta1/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "certificates",
            "endpoint": "getCertificatesV1beta1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/coordination.k8s.io/v1beta1/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "coordination",
            "endpoint": "getCoordinationV1beta1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/networking.k8s.io/v1beta1/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "networking",
            "endpoint": "getNetworkingV1beta1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/resource.k8s.io/v1beta1/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "resource",
            "endpoint": "getResourceV1beta1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/resource.k8s.io/v1beta2/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "resource",
            "endpoint": "getResourceV1beta2APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/.well-known/openid-configuration/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "WellKnown",
            "endpoint": "getServiceAccountIssuerOpenIDConfiguration",
            "conf_tested": false,
            "description": "get service account issuer OpenID configuration, also known as the 'OIDC discovery doc'"
        },
        {
            "kind": null,
            "path": "/openid/v1/jwks/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "openid",
            "endpoint": "getServiceAccountIssuerOpenIDKeyset",
            "conf_tested": false,
            "description": "get service account issuer OpenID JSON Web Key Set (contains public token verification keys)"
        },
        {
            "kind": null,
            "path": "/apis/storage.k8s.io/v1beta1/",
            "group": null,
            "level": "beta",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "storage",
            "endpoint": "getStorageV1beta1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1beta1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "list or watch objects of kind MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1beta1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "list or watch objects of kind MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "listCertificatesV1beta1ClusterTrustBundle",
            "conf_tested": false,
            "description": "list or watch objects of kind ClusterTrustBundle"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "listCoordinationV1beta1LeaseCandidateForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind LeaseCandidate"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "listCoordinationV1beta1NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "list or watch objects of kind LeaseCandidate"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "listNetworkingV1beta1IPAddress",
            "conf_tested": false,
            "description": "list or watch objects of kind IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "listNetworkingV1beta1ServiceCIDR",
            "conf_tested": false,
            "description": "list or watch objects of kind ServiceCIDR"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "listResourceV1beta1DeviceClass",
            "conf_tested": false,
            "description": "list or watch objects of kind DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "listResourceV1beta1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "listResourceV1beta1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaimTemplate"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "listResourceV1beta1ResourceClaimForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "listResourceV1beta1ResourceClaimTemplateForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "listResourceV1beta1ResourceSlice",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "listResourceV1beta2DeviceClass",
            "conf_tested": false,
            "description": "list or watch objects of kind DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "listResourceV1beta2NamespacedResourceClaim",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "listResourceV1beta2NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaimTemplate"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/resourceclaims",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "listResourceV1beta2ResourceClaimForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/resourceclaimtemplates",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "listResourceV1beta2ResourceClaimTemplateForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "listResourceV1beta2ResourceSlice",
            "conf_tested": false,
            "description": "list or watch objects of kind ResourceSlice"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "listStorageV1beta1VolumeAttributesClass",
            "conf_tested": false,
            "description": "list or watch objects of kind VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1beta1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "partially update the specified MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1beta1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "partially update the specified MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1beta1ClusterTrustBundle",
            "conf_tested": false,
            "description": "partially update the specified ClusterTrustBundle"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "patchCoordinationV1beta1NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "partially update the specified LeaseCandidate"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "patchNetworkingV1beta1IPAddress",
            "conf_tested": false,
            "description": "partially update the specified IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "patchNetworkingV1beta1ServiceCIDR",
            "conf_tested": false,
            "description": "partially update the specified ServiceCIDR"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}/status",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "patchNetworkingV1beta1ServiceCIDRStatus",
            "conf_tested": false,
            "description": "partially update status of the specified ServiceCIDR"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "patchResourceV1beta1DeviceClass",
            "conf_tested": false,
            "description": "partially update the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "patchResourceV1beta1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "partially update the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "patchResourceV1beta1NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "partially update status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "patchResourceV1beta1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "partially update the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "patchResourceV1beta1ResourceSlice",
            "conf_tested": false,
            "description": "partially update the specified ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "patchResourceV1beta2DeviceClass",
            "conf_tested": false,
            "description": "partially update the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "patchResourceV1beta2NamespacedResourceClaim",
            "conf_tested": false,
            "description": "partially update the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "patchResourceV1beta2NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "partially update status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "patchResourceV1beta2NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "partially update the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "patchResourceV1beta2ResourceSlice",
            "conf_tested": false,
            "description": "partially update the specified ResourceSlice"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "patchStorageV1beta1VolumeAttributesClass",
            "conf_tested": false,
            "description": "partially update the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1beta1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "read the specified MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1beta1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "read the specified MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "readCertificatesV1beta1ClusterTrustBundle",
            "conf_tested": false,
            "description": "read the specified ClusterTrustBundle"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "readCoordinationV1beta1NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "read the specified LeaseCandidate"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "readNetworkingV1beta1IPAddress",
            "conf_tested": false,
            "description": "read the specified IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "readNetworkingV1beta1ServiceCIDR",
            "conf_tested": false,
            "description": "read the specified ServiceCIDR"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}/status",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "readNetworkingV1beta1ServiceCIDRStatus",
            "conf_tested": false,
            "description": "read status of the specified ServiceCIDR"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "readResourceV1beta1DeviceClass",
            "conf_tested": false,
            "description": "read the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "readResourceV1beta1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "read the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "readResourceV1beta1NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "read status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "readResourceV1beta1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "read the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "readResourceV1beta1ResourceSlice",
            "conf_tested": false,
            "description": "read the specified ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "readResourceV1beta2DeviceClass",
            "conf_tested": false,
            "description": "read the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "readResourceV1beta2NamespacedResourceClaim",
            "conf_tested": false,
            "description": "read the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "readResourceV1beta2NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "read status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "readResourceV1beta2NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "read the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "readResourceV1beta2ResourceSlice",
            "conf_tested": false,
            "description": "read the specified ResourceSlice"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "readStorageV1beta1VolumeAttributesClass",
            "conf_tested": false,
            "description": "read the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1beta1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "replace the specified MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1beta1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1beta1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "replace the specified MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1beta1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1beta1ClusterTrustBundle",
            "conf_tested": false,
            "description": "replace the specified ClusterTrustBundle"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1beta1/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "coordination",
            "endpoint": "replaceCoordinationV1beta1NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "replace the specified LeaseCandidate"
        },
        {
            "kind": "IPAddress",
            "path": "/apis/networking.k8s.io/v1beta1/ipaddresses/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1beta1IPAddress",
            "conf_tested": false,
            "description": "replace the specified IPAddress"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1beta1ServiceCIDR",
            "conf_tested": false,
            "description": "replace the specified ServiceCIDR"
        },
        {
            "kind": "ServiceCIDR",
            "path": "/apis/networking.k8s.io/v1beta1/servicecidrs/{name}/status",
            "group": "networking.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "networking",
            "endpoint": "replaceNetworkingV1beta1ServiceCIDRStatus",
            "conf_tested": false,
            "description": "replace status of the specified ServiceCIDR"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta1/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "replaceResourceV1beta1DeviceClass",
            "conf_tested": false,
            "description": "replace the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "replaceResourceV1beta1NamespacedResourceClaim",
            "conf_tested": false,
            "description": "replace the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "replaceResourceV1beta1NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "replace status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta1/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "replaceResourceV1beta1NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "replace the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta1/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "resource",
            "endpoint": "replaceResourceV1beta1ResourceSlice",
            "conf_tested": false,
            "description": "replace the specified ResourceSlice"
        },
        {
            "kind": "DeviceClass",
            "path": "/apis/resource.k8s.io/v1beta2/deviceclasses/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "replaceResourceV1beta2DeviceClass",
            "conf_tested": false,
            "description": "replace the specified DeviceClass"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "replaceResourceV1beta2NamespacedResourceClaim",
            "conf_tested": false,
            "description": "replace the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaim",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaims/{name}/status",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "replaceResourceV1beta2NamespacedResourceClaimStatus",
            "conf_tested": false,
            "description": "replace status of the specified ResourceClaim"
        },
        {
            "kind": "ResourceClaimTemplate",
            "path": "/apis/resource.k8s.io/v1beta2/namespaces/{namespace}/resourceclaimtemplates/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "replaceResourceV1beta2NamespacedResourceClaimTemplate",
            "conf_tested": false,
            "description": "replace the specified ResourceClaimTemplate"
        },
        {
            "kind": "ResourceSlice",
            "path": "/apis/resource.k8s.io/v1beta2/resourceslices/{name}",
            "group": "resource.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta2",
            "category": "resource",
            "endpoint": "replaceResourceV1beta2ResourceSlice",
            "conf_tested": false,
            "description": "replace the specified ResourceSlice"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1beta1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "beta",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1beta1",
            "category": "storage",
            "endpoint": "replaceStorageV1beta1VolumeAttributesClass",
            "conf_tested": false,
            "description": "replace the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1alpha1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "create a MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "createAdmissionregistrationV1alpha1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "create a MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "createCertificatesV1alpha1ClusterTrustBundle",
            "conf_tested": false,
            "description": "create a ClusterTrustBundle"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "createCertificatesV1alpha1NamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "create a PodCertificateRequest"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "createCoordinationV1alpha2NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "create a LeaseCandidate"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "createInternalApiserverV1alpha1StorageVersion",
            "conf_tested": false,
            "description": "create a StorageVersion"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "createResourceV1alpha3DeviceTaintRule",
            "conf_tested": false,
            "description": "create a DeviceTaintRule"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "createStoragemigrationV1alpha1StorageVersionMigration",
            "conf_tested": false,
            "description": "create a StorageVersionMigration"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "post",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "createStorageV1alpha1VolumeAttributesClass",
            "conf_tested": false,
            "description": "create a VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1alpha1CollectionMutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "delete collection of MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1alpha1CollectionMutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "delete collection of MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1alpha1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "delete a MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "deleteAdmissionregistrationV1alpha1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "delete a MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1alpha1ClusterTrustBundle",
            "conf_tested": false,
            "description": "delete a ClusterTrustBundle"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1alpha1CollectionClusterTrustBundle",
            "conf_tested": false,
            "description": "delete collection of ClusterTrustBundle"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1alpha1CollectionNamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "delete collection of PodCertificateRequest"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "deleteCertificatesV1alpha1NamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "delete a PodCertificateRequest"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "deleteCoordinationV1alpha2CollectionNamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "delete collection of LeaseCandidate"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "deleteCoordinationV1alpha2NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "delete a LeaseCandidate"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "deleteInternalApiserverV1alpha1CollectionStorageVersion",
            "conf_tested": false,
            "description": "delete collection of StorageVersion"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "deleteInternalApiserverV1alpha1StorageVersion",
            "conf_tested": false,
            "description": "delete a StorageVersion"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "deleteResourceV1alpha3CollectionDeviceTaintRule",
            "conf_tested": false,
            "description": "delete collection of DeviceTaintRule"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules/{name}",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "deleteResourceV1alpha3DeviceTaintRule",
            "conf_tested": false,
            "description": "delete a DeviceTaintRule"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "deleteStoragemigrationV1alpha1CollectionStorageVersionMigration",
            "conf_tested": false,
            "description": "delete collection of StorageVersionMigration"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "deleteStoragemigrationV1alpha1StorageVersionMigration",
            "conf_tested": false,
            "description": "delete a StorageVersionMigration"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "deletecollection",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "deleteStorageV1alpha1CollectionVolumeAttributesClass",
            "conf_tested": false,
            "description": "delete collection of VolumeAttributesClass"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "delete",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "deleteStorageV1alpha1VolumeAttributesClass",
            "conf_tested": false,
            "description": "delete a VolumeAttributesClass"
        },
        {
            "kind": null,
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "admissionregistration",
            "endpoint": "getAdmissionregistrationV1alpha1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/certificates.k8s.io/v1alpha1/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "certificates",
            "endpoint": "getCertificatesV1alpha1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/coordination.k8s.io/v1alpha2/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "coordination",
            "endpoint": "getCoordinationV1alpha2APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "internalApiserver",
            "endpoint": "getInternalApiserverV1alpha1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/resource.k8s.io/v1alpha3/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "resource",
            "endpoint": "getResourceV1alpha3APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/storagemigration.k8s.io/v1alpha1/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "storagemigration",
            "endpoint": "getStoragemigrationV1alpha1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": null,
            "path": "/apis/storage.k8s.io/v1alpha1/",
            "group": null,
            "level": "alpha",
            "tests": [
                null
            ],
            "action": null,
            "tested": false,
            "release": "1.35.0",
            "version": null,
            "category": "storage",
            "endpoint": "getStorageV1alpha1APIResources",
            "conf_tested": false,
            "description": "get available resources"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1alpha1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "list or watch objects of kind MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "listAdmissionregistrationV1alpha1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "list or watch objects of kind MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "listCertificatesV1alpha1ClusterTrustBundle",
            "conf_tested": false,
            "description": "list or watch objects of kind ClusterTrustBundle"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "listCertificatesV1alpha1NamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "list or watch objects of kind PodCertificateRequest"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/podcertificaterequests",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "listCertificatesV1alpha1PodCertificateRequestForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind PodCertificateRequest"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "listCoordinationV1alpha2LeaseCandidateForAllNamespaces",
            "conf_tested": false,
            "description": "list or watch objects of kind LeaseCandidate"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "listCoordinationV1alpha2NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "list or watch objects of kind LeaseCandidate"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "listInternalApiserverV1alpha1StorageVersion",
            "conf_tested": false,
            "description": "list or watch objects of kind StorageVersion"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "listResourceV1alpha3DeviceTaintRule",
            "conf_tested": false,
            "description": "list or watch objects of kind DeviceTaintRule"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "listStoragemigrationV1alpha1StorageVersionMigration",
            "conf_tested": false,
            "description": "list or watch objects of kind StorageVersionMigration"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "list",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "listStorageV1alpha1VolumeAttributesClass",
            "conf_tested": false,
            "description": "list or watch objects of kind VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1alpha1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "partially update the specified MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "patchAdmissionregistrationV1alpha1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "partially update the specified MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1alpha1ClusterTrustBundle",
            "conf_tested": false,
            "description": "partially update the specified ClusterTrustBundle"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1alpha1NamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "partially update the specified PodCertificateRequest"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}/status",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "patchCertificatesV1alpha1NamespacedPodCertificateRequestStatus",
            "conf_tested": false,
            "description": "partially update status of the specified PodCertificateRequest"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "patchCoordinationV1alpha2NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "partially update the specified LeaseCandidate"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "patchInternalApiserverV1alpha1StorageVersion",
            "conf_tested": false,
            "description": "partially update the specified StorageVersion"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}/status",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "patchInternalApiserverV1alpha1StorageVersionStatus",
            "conf_tested": false,
            "description": "partially update status of the specified StorageVersion"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules/{name}",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "patchResourceV1alpha3DeviceTaintRule",
            "conf_tested": false,
            "description": "partially update the specified DeviceTaintRule"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "patchStoragemigrationV1alpha1StorageVersionMigration",
            "conf_tested": false,
            "description": "partially update the specified StorageVersionMigration"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}/status",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "patchStoragemigrationV1alpha1StorageVersionMigrationStatus",
            "conf_tested": false,
            "description": "partially update status of the specified StorageVersionMigration"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "patch",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "patchStorageV1alpha1VolumeAttributesClass",
            "conf_tested": false,
            "description": "partially update the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1alpha1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "read the specified MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "readAdmissionregistrationV1alpha1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "read the specified MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "readCertificatesV1alpha1ClusterTrustBundle",
            "conf_tested": false,
            "description": "read the specified ClusterTrustBundle"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "readCertificatesV1alpha1NamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "read the specified PodCertificateRequest"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}/status",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "readCertificatesV1alpha1NamespacedPodCertificateRequestStatus",
            "conf_tested": false,
            "description": "read status of the specified PodCertificateRequest"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "readCoordinationV1alpha2NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "read the specified LeaseCandidate"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "readInternalApiserverV1alpha1StorageVersion",
            "conf_tested": false,
            "description": "read the specified StorageVersion"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}/status",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "readInternalApiserverV1alpha1StorageVersionStatus",
            "conf_tested": false,
            "description": "read status of the specified StorageVersion"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules/{name}",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "readResourceV1alpha3DeviceTaintRule",
            "conf_tested": false,
            "description": "read the specified DeviceTaintRule"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "readStoragemigrationV1alpha1StorageVersionMigration",
            "conf_tested": false,
            "description": "read the specified StorageVersionMigration"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}/status",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "readStoragemigrationV1alpha1StorageVersionMigrationStatus",
            "conf_tested": false,
            "description": "read status of the specified StorageVersionMigration"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "get",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "readStorageV1alpha1VolumeAttributesClass",
            "conf_tested": false,
            "description": "read the specified VolumeAttributesClass"
        },
        {
            "kind": "MutatingAdmissionPolicy",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicies/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1alpha1MutatingAdmissionPolicy",
            "conf_tested": false,
            "description": "replace the specified MutatingAdmissionPolicy"
        },
        {
            "kind": "MutatingAdmissionPolicyBinding",
            "path": "/apis/admissionregistration.k8s.io/v1alpha1/mutatingadmissionpolicybindings/{name}",
            "group": "admissionregistration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "admissionregistration",
            "endpoint": "replaceAdmissionregistrationV1alpha1MutatingAdmissionPolicyBinding",
            "conf_tested": false,
            "description": "replace the specified MutatingAdmissionPolicyBinding"
        },
        {
            "kind": "ClusterTrustBundle",
            "path": "/apis/certificates.k8s.io/v1alpha1/clustertrustbundles/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1alpha1ClusterTrustBundle",
            "conf_tested": false,
            "description": "replace the specified ClusterTrustBundle"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1alpha1NamespacedPodCertificateRequest",
            "conf_tested": false,
            "description": "replace the specified PodCertificateRequest"
        },
        {
            "kind": "PodCertificateRequest",
            "path": "/apis/certificates.k8s.io/v1alpha1/namespaces/{namespace}/podcertificaterequests/{name}/status",
            "group": "certificates.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "certificates",
            "endpoint": "replaceCertificatesV1alpha1NamespacedPodCertificateRequestStatus",
            "conf_tested": false,
            "description": "replace status of the specified PodCertificateRequest"
        },
        {
            "kind": "LeaseCandidate",
            "path": "/apis/coordination.k8s.io/v1alpha2/namespaces/{namespace}/leasecandidates/{name}",
            "group": "coordination.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha2",
            "category": "coordination",
            "endpoint": "replaceCoordinationV1alpha2NamespacedLeaseCandidate",
            "conf_tested": false,
            "description": "replace the specified LeaseCandidate"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "replaceInternalApiserverV1alpha1StorageVersion",
            "conf_tested": false,
            "description": "replace the specified StorageVersion"
        },
        {
            "kind": "StorageVersion",
            "path": "/apis/internal.apiserver.k8s.io/v1alpha1/storageversions/{name}/status",
            "group": "internal.apiserver.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "internalApiserver",
            "endpoint": "replaceInternalApiserverV1alpha1StorageVersionStatus",
            "conf_tested": false,
            "description": "replace status of the specified StorageVersion"
        },
        {
            "kind": "DeviceTaintRule",
            "path": "/apis/resource.k8s.io/v1alpha3/devicetaintrules/{name}",
            "group": "resource.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha3",
            "category": "resource",
            "endpoint": "replaceResourceV1alpha3DeviceTaintRule",
            "conf_tested": false,
            "description": "replace the specified DeviceTaintRule"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "replaceStoragemigrationV1alpha1StorageVersionMigration",
            "conf_tested": false,
            "description": "replace the specified StorageVersionMigration"
        },
        {
            "kind": "StorageVersionMigration",
            "path": "/apis/storagemigration.k8s.io/v1alpha1/storageversionmigrations/{name}/status",
            "group": "storagemigration.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storagemigration",
            "endpoint": "replaceStoragemigrationV1alpha1StorageVersionMigrationStatus",
            "conf_tested": false,
            "description": "replace status of the specified StorageVersionMigration"
        },
        {
            "kind": "VolumeAttributesClass",
            "path": "/apis/storage.k8s.io/v1alpha1/volumeattributesclasses/{name}",
            "group": "storage.k8s.io",
            "level": "alpha",
            "tests": [
                null
            ],
            "action": "put",
            "tested": false,
            "release": "1.35.0",
            "version": "v1alpha1",
            "category": "storage",
            "endpoint": "replaceStorageV1alpha1VolumeAttributesClass",
            "conf_tested": false,
            "description": "replace the specified VolumeAttributesClass"
        }
    ],
    "release_date": "2025-10-04T12:03:08",
    "total endpoints": 859,
    "tested endpoints": 573,
    "new conformance eligible endpoints": 0,
    "total conformance eligible endpoints": 549,
    "tested conformance eligible endpoints": 512,
    "new tested conformance eligible endpoints": 0
}
