#+TITLE: APISnoop Update for 19 August 2019
#+NOSETUPFILE: ../org-templates/level-0.org
#+SETUPFILE_CALLS: .dir-locals.el twice for a single file
#+PROPERTY: header-args :eval never-export
#+PROPERTY: header-args:shell :eval never-export :results output verbatim replace drawer :exports both
#+OPTIONS: ':t *:t -:t ::t <:t H:3 \n:nil ^:nil arch:headline author:t c:nil
#+OPTIONS: creator:comment d:(not LOGBOOK) date:t e:t email:nil f:t inline:t
#+OPTIONS: num:nil p:nil pri:nil stat:t tags:t tasks:t tex:t timestamp:t toc:nil
#+OPTIONS: todo:t |:t
#+EXCLUDE_TAGS: noexport
#+KEYWORDS:
#+LANGUAGE: en
#+SELECT_TAGS: export
#+OPTIONS: html-postamble:nil html-preamble:t tex:t
#+CREATOR: <a href='https://ii.coop'>The ii team</a> 
#+HTML_CONTAINER: div
#+HTML_DOCTYPE: xhtml-strict
#+HTML_HEAD: <link rel="stylesheet" type="text/css" href="aesthetic/main.css" />
#+HTML_HEAD_EXTRA: <link href="https://fonts.googleapis.com/css?family=Fira+Sans:300,300i,400,400i,700" rel="stylesheet">
#+HTML_HTML5_FANCY:
#+HTML_LINK_HOME:
#+HTML_LINK_UP:
#+HTML_MATHJAX:
#+INFOJS_OPT:
#+AUTHOR: ii team
#+DATE: 2019-08-19
#+PROPERTY: header-args :exports both :eval never-export

* Summary  
The APISnoop team are working to expand how much one can know about field usage and coverage in Kubernetes.  Our initial question was “What is the state of testing coverage for every field related to PodSpec?” This question required us to first discover which fields actually relate to PodSpec and in what configuration, and how to correlate the data within Audit Log events to the corresponding fields and definitions within the swagger.json.

  Our work to answer this question is helping to answer the larger questions like, "what is the testing coverage for every field?   “Or for any arbitrary kind, what fields relate to it and what are their coverage?”
  
  The APISnoop team are working to expand how much we know, or can know, about field usage and coverage in Kubernetes.  Our initial question to answer was: “What is the state of testing coverage for every field related to PodSpec”. This question required us to first discover which fields actually relate to PodSpec and in what configuration, and how to correlate the data within Audit Log events to the corresponding fields and definitions within the swagger.json.
  
  We are working within a new infrastructure for APISnoop, where we load audit events and swaggers directly into a Postgres database, and then build out our queries from this raw data.  This allows us to query the data from multiple sources, including this report: all tables listed below are coming directly from our server, by running queries dynamically as we type this report.
* PodSpec Field Coverage
  
 Initially we explored podspec coverage by giving a report on each field related to podspec and its relative hits, test hits, and conformance test hits.  We did this by manually walking the podspec tree to get all relevant fields, then building out a custom view.
 
#+NAME: PodSpec Field Coverage
#+BEGIN_SRC sql-mode :exports both :eval never-export :results value raw drawer
select * from podspec_field_summary;
#+END_SRC

#+CAPTION: PodSpec Field Coverage
  |         podspec_field         | other_hits | e2e_hits | conf_hits|  
  |-------------------------------+------------+----------+----------|
  | ephemeralContainers           |          0 |        0 |         0|
  | overhead                      |          0 |        0 |         0|
  | preemptionPolicy              |          0 |        0 |         0|
  | shareProcessNamespace         |          0 |        0 |         0|
  | topologySpreadConstraints     |          0 |        0 |         0|
  | readinessGates                |          0 |        8 |         0|
  | dnsConfig                     |          0 |       16 |         0|
  | hostIPC                       |          0 |       16 |         0|
  | hostPID                       |          0 |       16 |         0|
  | priorityClassName             |       3731 |       32 |         0|
  | runtimeClassName              |          0 |       36 |         0|
  | affinity                      |       1213 |       43 |         0|
  | hostAliases                   |          0 |        0 |         8|
  | imagePullSecrets              |          0 |        0 |         8|
  | activeDeadlineSeconds         |         18 |        8 |        14|
  | initContainers                |          0 |     1315 |        32|
  | hostNetwork                   |       2687 |     1574 |        41|
  | automountServiceAccountToken  |          0 |       36 |        60|
  | subdomain                     |       5253 |       85 |        60|
  | hostname                      |       5469 |       85 |        60|
  | priority                      |        900 |       83 |       105|
  | tolerations                   |       4820 |       83 |       105|
  | nodeName                      |       8379 |     4170 |       127|
  | nodeSelector                  |       3260 |      257 |       128|
  | serviceAccount                |      12025 |     1199 |       201|
  | serviceAccountName            |      12025 |     1199 |       201|
  | volumes                       |      15598 |     6903 |       876|
  | enableServiceLinks            |      12097 |     6506 |      1741|
  | containers                    |      27717 |    13194 |      2063|
  | dnsPolicy                     |      27717 |    13194 |      2063|
  | restartPolicy                 |      27717 |    13194 |      2063|
  | schedulerName                 |      27717 |    13194 |      2063|
  | securityContext               |      27717 |    13194 |      2063|
  | terminationGracePeriodSeconds |      27717 |    13194 |      2063|

This was a useful summary, but immediately begged new questions: what's the coverage for all the fields within something like containers?  Can we see this not as a summary, but as a granular walk through each field and sub-field and see each of their coverage?

To answer these, we'd need to make a generalized query that walked the path of any kind, noting every field and sub-field and the path to each.
* Recursive Querying of Kubernetes Schemas
  We achieved this using a recursive view that starts from a swagger.json defition of a kind, then walks through each of its fields, finding any that reference their own schema and then branching out to walk down each of these paths.  
  
  This allows us to now see every field within the swagger.json, the kind it relates to, and any sub-kinds that come from it.  
  This clarity into kinds will help in multiple ways.  By connecting this work to our audit logs, we can start to see coverage field by field, based on any spec or kind we wished.  We can then see exactly which areas are untested, their importance as related to our kind definitions, and write out tests with better focus and priority.
  
  To better illustrate this, we can look at some sample queries.
* Sample Queries
** A listing of fields related to Podspec
    We can walk up or down a tree for any arbitrary kind, like podspec. 
    
    We can start at the PodSpec kind and see the fields within.
 #+NAME: Left PodSpec
  #+BEGIN_SRC sql-mode :exports both :eval never-export
   select * from kind_field_path
   where field_kind not like 'io%' -- only look at int and string
   and kind like '%PodSpec'
   and field_path like '%.%'
   limit 20;
 #+END_SRC

 #+CAPTION: Fields Within PodSpec
 | kind                       | field_path                            | field_kind | field_type | sub_kind                     |
 |----------------------------+---------------------------------------+------------+------------+------------------------------|
 | io.k8s.api.core.v1.PodSpec | containers.command                    | string     | array      | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.terminationMessagePath     | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.tty                        | integer    | boolean    | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.args                       | string     | array      | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.image                      | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.stdinOnce                  | integer    | boolean    | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.name                       | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.workingDir                 | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.imagePullPolicy            | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.terminationMessagePolicy   | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | containers.stdin                      | integer    | boolean    | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.command                | string     | array      | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.terminationMessagePath | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.tty                    | integer    | boolean    | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.args                   | string     | array      | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.image                  | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.stdinOnce              | integer    | boolean    | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.name                   | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.workingDir             | string     | string     | io.k8s.api.core.v1.Container |
 | io.k8s.api.core.v1.PodSpec | initContainers.imagePullPolicy        | string     | string     | io.k8s.api.core.v1.Container |
  
  Or we can go in the other direction, and see a sampling of fields that contain podspec.
  
 #+NAME: Right PodSpec
 #+BEGIN_SRC sql-mode :exports both :eval never-export
 select * from kind_field_path
 where field_kind not like 'io%' -- only look at int and string
 and sub_kind like '%PodSpec'
 and field_path like '%.%'
 limit 20;
 #+END_SRC

 #+CAPTION: Fields that Contain Podspec
 | kind                               | field_path                 | field_kind | field_type | sub_kind                   |
 |------------------------------------+----------------------------+------------+------------+----------------------------|
 | io.k8s.api.core.v1.PodTemplateSpec | spec.hostPID               | integer    | boolean    | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.hostIPC               | integer    | boolean    | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.hostname              | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.nodeName              | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.overhead              | integer    | object     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.priority              | integer    | integer    | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.dnsPolicy             | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.subdomain             | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.hostNetwork           | integer    | boolean    | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.nodeSelector          | integer    | object     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.restartPolicy         | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.schedulerName         | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.serviceAccount        | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.preemptionPolicy      | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.runtimeClassName      | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.priorityClassName     | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.enableServiceLinks    | integer    | boolean    | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.serviceAccountName    | string     | string     | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.activeDeadlineSeconds | integer    | integer    | io.k8s.api.core.v1.PodSpec |
 | io.k8s.api.core.v1.PodTemplateSpec | spec.shareProcessNamespace | integer    | boolean    | io.k8s.api.core.v1.PodSpec |

** A sampling of  subresources for Container
   
   Our initial summary made us curious to see all the sub-resources for any of the fields of podspec.  Here is a sampling for container.
   
  #+NAME: Sub-Resources for Container
 #+BEGIN_SRC sql-mode :exports both :eval never-export
  select * from kind_field_path
  where field_kind not like 'io%' -- only look at int and string
  and kind like '%v1.Container'
  and field_path like '%.%'
  limit 20;
  #+END_SRC

  #+Caption: Sub-resources for the kind Container
 | kind                         | field_path                          | field_kind   | field_type   | sub_kind                                  |
 |--------------------------- - + ----------------------------------- + ------------ + ------------ + ----------------------------------------- +
 | io.k8s.api.core.v1.Container | ports.name                          | string       | string       | io.k8s.api.core.v1.ContainerPort          |
 | io.k8s.api.core.v1.Container | ports.hostIP                        | string       | string       | io.k8s.api.core.v1.ContainerPort          |
 | io.k8s.api.core.v1.Container | ports.hostPort                      | integer      | integer      | io.k8s.api.core.v1.ContainerPort          |
 | io.k8s.api.core.v1.Container | ports.protocol                      | string       | string       | io.k8s.api.core.v1.ContainerPort          |
 | io.k8s.api.core.v1.Container | ports.containerPort                 | integer      | integer      | io.k8s.api.core.v1.ContainerPort          |
 | io.k8s.api.core.v1.Container | envFrom.prefix                      | string       | string       | io.k8s.api.core.v1.EnvFromSource          |
 | io.k8s.api.core.v1.Container | env.value                           | string       | string       | io.k8s.api.core.v1.EnvVar                 |
 | io.k8s.api.core.v1.Container | env.name                            | string       | string       | io.k8s.api.core.v1.EnvVar                 |
 | io.k8s.api.core.v1.Container | readinessProbe.successThreshold     | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | readinessProbe.periodSeconds        | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | readinessProbe.initialDelaySeconds  | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | readinessProbe.timeoutSeconds       | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | readinessProbe.failureThreshold     | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | livenessProbe.successThreshold      | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | livenessProbe.periodSeconds         | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | livenessProbe.initialDelaySeconds   | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | livenessProbe.timeoutSeconds        | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | livenessProbe.failureThreshold      | integer      | integer      | io.k8s.api.core.v1.Probe                  |
 | io.k8s.api.core.v1.Container | resources.limits                    | integer      | object       | io.k8s.api.core.v1.ResourceRequirements   |
 | io.k8s.api.core.v1.Container | resources.requests                  | integer      | object       | io.k8s.api.core.v1.ResourceRequirements   |

** PodSec - Completely Untested Fields 
This led us to identifying the following completely untested fields:

#+CAPTION: Completely Untested Fields in PodSpec
| podspec_field             | other | e2e_hit | conf_hit /  note |         |
|---------------------------+-------+---------+------------------+---------|
| ephemeralContainers       |     0 |       0 |                0 | include |
| topologySpreadConstraints |     0 |       0 |                0 | include |
| overhead                  |     0 |       0 |                0 | alpha   |
| preemptionPolicy          |     0 |       0 |                0 | alpha   |
| shareProcessNamespace     |     0 |       0 |                0 | beta    |


It was noted that some of these fields were alpha/beta, deprecated or hidden behind FeatureGates according to the description in the documentation, so we created new columns for easy of identification.


#+CAPTION: Field Path with Extended Columns
| field_path            | field_kind | release | deprecated | gated |
|-----------------------+------------+---------+------------+-------|
| overhead              | integer    | alpha   | f          | t     |
| preemptionPolicy      | string     | alpha   | f          | t     |
| shareProcessNamespace | integer    | beta    | f          | f     |
| runtimeClassName      | string     | beta    | f          | f     |
| serviceAccount        | string     | ga      | t          | f     |

* Recommended Actions and Next Steps
  As we built out these views, we were able to notice areas of improvement, which led us to make the following recommendations.
** Update Conformance Tests to use “serviceAccountName” instead of “serviceAccount”
   =serviceAccount= is deprecated, yet we hit it nearly 200 times during our conformance testing.

#+CAPTION: Number of Hits on deprecated serviceAccount
| podspec_field  | other_hits | e2e_hits | conf_hits |
|----------------+------------+----------+-----------|
| serviceAccount |      12025 |     1199 |       201 |

We should update these tests to use =serviceAccountName= instead.

** Prioritize writing test for ephemeralContainers and topologySpreadConstraints


=emphemeralContainers= and =topologySpreadConstraints= are the only GA, ungated PodSpec fields that are completely untested.

#+CAPTION: Number of Hits on GA, Ungated Podspec Fields
| podspec_field             | other_hits | e2e_hits | conf_hits |
|---------------------------+------------+----------+-----------|
| ephemeralContainers       |          0 |        0 |         0 |
| topologySpreadConstraints |          0 |        0 |         0 |
| readinessGates            |          0 |        8 |         0 |
| priorityClassName         |       3731 |       32 |         0 |
| hostIPC                   |          0 |       16 |         0 |
| hostPID                   |          0 |       16 |         0 |

We suggest we prioritize writing conformance tests for those two first, then the reamining four fields that don't have a recognizable test.

** Promote Tests

There are three podSpec fields not hit by any conformance tests.

#+CAPTION: Podspec Fields not hit by conformance tests
| podspec_field    | other_hits | e2e_hits | conf_hits |
|------------------+------------+----------+-----------|
| affinity         |       1213 |       43 |         0 |
| dnsConfig        |          0 |       16 |         0 |
| runtimeClassName |          0 |       36 |         0 |

However, these fields _are_ directly hit by other tests.

#+CAPTION: Tests that Hit non-conformance-tested Podspec Fields
| podspec_field    | test                                                                                                  |
|------------------+-------------------------------------------------------------------------------------------------------|
| affinity         | [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined |
| affinity         | [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile                |
| dnsConfig        | [sig-network] DNS should support configurable pod DNS nameservers                                     |
| dnsConfig        | [sig-network] DNS should support configurable pod resolv.conf                                         |
| runtimeClassName | [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass                         |
| runtimeClassName | [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass                    |
| runtimeClassName | [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler    |

We recommend looking into and preparing these tests for promotion. 

* PodSpec foo

** foo

#+NAME: createCoreV1NamespacedPod tests hitting otherwise unconformant endpoints
#+BEGIN_SRC sql-mode
select distinct podspec_field, test from podspec_field_coverage
where test != ''
and (podspec_field like 'readinessGates'
or podspec_field like 'dnsConfig'
or podspec_field like 'hostIPC'
or podspec_field like 'hostPID'
or podspec_field like 'affinity'
or podspec_field like 'runtimeClassName')
and operation_id = 'createCoreV1NamespacedPod'
and test not like '%NodeFeature:%' -- readinessGates / PodReadinessGate
and test not ilike '%storage%';
#+END_SRC

#+RESULTS: createCoreV1NamespacedPod tests hitting otherwise unconformant endpoints
#+begin_src sql-mode
  podspec_field   |                                                  test                                                  
------------------+--------------------------------------------------------------------------------------------------------
 affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined
 affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile
 dnsConfig        |  [sig-network] DNS should support configurable pod DNS nameservers
 dnsConfig        |  [sig-network] DNS should support configurable pod resolv.conf
 runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass
 runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass
 runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler
#+end_src

#+NAME: alpha/beta, deprecated and feature_gated PodSpec fields
#+BEGIN_SRC sql-mode
select field_name, release, deprecated, feature_gated
from api_schema_field
where field_schema like '%PodSpec'
and (release = 'alpha' or release = 'beta' or deprecated or feature_gated)
order by release, field_name;
#+END_SRC

#+RESULTS: alpha/beta, deprecated and feature_gated PodSpec fields
#+begin_src sql-mode
        field_name         | release | deprecated | feature_gated 
---------------------------+---------+------------+---------------
 ephemeralContainers       | alpha   | f          | t
 overhead                  | alpha   | f          | t
 preemptionPolicy          | alpha   | f          | t
 topologySpreadConstraints | alpha   | f          | t
 runtimeClassName          | beta    | f          | f
 shareProcessNamespace     | beta    | f          | f
 serviceAccount            | ga      | t          | f
(7 rows)

#+end_src

#+RESULTS:
#+begin_src sql-mode
       operation_id        |  podspec_field   |                                                                     test                                                                     
---------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------------------
 createCoreV1NamespacedPod | affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined
 createCoreV1NamespacedPod | affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile
 createCoreV1NamespacedPod | affinity         |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should access volume from different nodes
 createCoreV1NamespacedPod | affinity         |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should access volume from different nodes
 createCoreV1NamespacedPod | affinity         |  [sig-storage] PersistentVolumes-local  Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity
 createCoreV1NamespacedPod | dnsConfig        |  [sig-network] DNS should support configurable pod DNS nameservers
 createCoreV1NamespacedPod | dnsConfig        |  [sig-network] DNS should support configurable pod resolv.conf
 createCoreV1NamespacedPod | readinessGates   |  [k8s.io] Pods should support pod readiness gates [NodeFeature:PodReadinessGate]
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with a configured handler [NodeFeature:RuntimeHandler]
(12 rows)

#+end_src

** alpha/beta, deprecated, and gated fields

#+NAME: alpha/beta, deprecated, and gated PodSpec Fields
#+BEGIN_SRC sql-mode :exports both :eval never-export
select field_path, field_kind, release, deprecated, gated from kind_field_path
where field_type not like 'io%'
  and kind like '%PodSpec'
  and sub_kind like '%PodSpec'
  and (deprecated or gated or release != 'ga')
order by deprecated DESC, release DESC, gated;
#+END_SRC

#+RESULTS: alpha/beta, deprecated, and gated PodSpec Fields
#+begin_src sql-mode
      field_path       | field_kind | release | deprecated | gated 
-----------------------+------------+---------+------------+-------
 serviceAccount        | string     | ga      | t          | f
 runtimeClassName      | string     | beta    | f          | f
 shareProcessNamespace | integer    | beta    | f          | f
 preemptionPolicy      | string     | alpha   | f          | t
 overhead              | integer    | alpha   | f          | t
(5 rows)

#+end_src


** left
#+NAME: Left PodSpec
#+BEGIN_SRC sql-mode
select * from kind_field_path
where field_kind not like 'io%' -- only look at int and string
and kind like '%PodSpec'
and field_path like '%.%'
limit 120;
#+END_SRC


#+CAPTION: Completely Untested Fields in PodSpec
| podspec_field             | other | e2e_hit | conf_hit /  note |         |
|---------------------------+-------+---------+------------------+---------|
| ephemeralContainers       |     0 |       0 |                0 | include |
| topologySpreadConstraints |     0 |       0 |                0 | include |
| overhead                  |     0 |       0 |                0 | alpha   |
| preemptionPolicy          |     0 |       0 |                0 | alpha   |
| shareProcessNamespace     |     0 |       0 |                0 | beta    |


It was noted that some of these fields were alpha/beta, deprecated or hidden behind FeatureGates according to the description in the documentation, so we created new columns for easy of identification.


#+CAPTION: Field Path with Extended Columns
| field_path            | field_kind | release | deprecated | gated |
|-----------------------+------------+---------+------------+-------|
| overhead              | integer    | alpha   | f          | t     |
| preemptionPolicy      | string     | alpha   | f          | t     |
| shareProcessNamespace | integer    | beta    | f          | f     |
| runtimeClassName      | string     | beta    | f          | f     |
| serviceAccount        | string     | ga      | t          | f     |

* Recommended Actions and Next Steps
  As we built out these views, we were able to notice areas of improvement, which led us to make the following recommendations.
** Update Conformance Tests to use “serviceAccountName” instead of “serviceAccount”
   =serviceAccount= is deprecated, yet we hit it nearly 200 times during our conformance testing.

#+CAPTION: Number of Hits on deprecated serviceAccount
| podspec_field  | other_hits | e2e_hits | conf_hits |
|----------------+------------+----------+-----------|
| serviceAccount |      12025 |     1199 |       201 |

We should update these tests to use =serviceAccountName= instead.

** Prioritize writing test for ephemeralContainers and topologySpreadConstraints


=emphemeralContainers= and =topologySpreadConstraints= are the only GA, ungated PodSpec fields that are completely untested.

#+CAPTION: Number of Hits on GA, Ungated Podspec Fields
| podspec_field             | other_hits | e2e_hits | conf_hits |
|---------------------------+------------+----------+-----------|
| ephemeralContainers       |          0 |        0 |         0 |
| topologySpreadConstraints |          0 |        0 |         0 |
| readinessGates            |          0 |        8 |         0 |
| priorityClassName         |       3731 |       32 |         0 |
| hostIPC                   |          0 |       16 |         0 |
| hostPID                   |          0 |       16 |         0 |

We suggest we prioritize writing conformance tests for those two first, then the reamining four fields that don't have a recognizable test.

** Promote Tests

There are three podSpec fields not hit by any conformance tests.

#+CAPTION: Podspec Fields not hit by conformance tests
| podspec_field    | other_hits | e2e_hits | conf_hits |
|------------------+------------+----------+-----------|
| affinity         |       1213 |       43 |         0 |
| dnsConfig        |          0 |       16 |         0 |
| runtimeClassName |          0 |       36 |         0 |

However, these fields _are_ directly hit by other tests.

#+CAPTION: Tests that Hit non-conformance-tested Podspec Fields
| podspec_field    | test                                                                                                  |
|------------------+-------------------------------------------------------------------------------------------------------|
| affinity         | [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined |
| affinity         | [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile                |
| dnsConfig        | [sig-network] DNS should support configurable pod DNS nameservers                                     |
| dnsConfig        | [sig-network] DNS should support configurable pod resolv.conf                                         |
| runtimeClassName | [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass                         |
| runtimeClassName | [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass                    |
| runtimeClassName | [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler    |

We recommend looking into and preparing these tests for promotion. 

* PodSpec foo

** foo

#+NAME: createCoreV1NamespacedPod tests hitting otherwise unconformant endpoints
#+BEGIN_SRC sql-mode
select distinct podspec_field, test from podspec_field_coverage
where test != ''
and (podspec_field like 'readinessGates'
or podspec_field like 'dnsConfig'
or podspec_field like 'hostIPC'
or podspec_field like 'hostPID'
or podspec_field like 'affinity'
or podspec_field like 'runtimeClassName')
and operation_id = 'createCoreV1NamespacedPod'
and test not like '%NodeFeature:%' -- readinessGates / PodReadinessGate
and test not ilike '%storage%';
#+END_SRC

#+RESULTS: createCoreV1NamespacedPod tests hitting otherwise unconformant endpoints
#+begin_src sql-mode
  podspec_field   |                                                  test                                                  
------------------+--------------------------------------------------------------------------------------------------------
 affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined
 affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile
 dnsConfig        |  [sig-network] DNS should support configurable pod DNS nameservers
 dnsConfig        |  [sig-network] DNS should support configurable pod resolv.conf
 runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass
 runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass
 runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler
(7 rows)

#+end_src

#+RESULTS:
#+begin_src sql-mode
       operation_id        |  podspec_field   |                                                                     test                                                                     
---------------------------+------------------+----------------------------------------------------------------------------------------------------------------------------------------------
 createCoreV1NamespacedPod | affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles can disable an AppArmor profile, using unconfined
 createCoreV1NamespacedPod | affinity         |  [k8s.io] [sig-node] AppArmor load AppArmor profiles should enforce an AppArmor profile
 createCoreV1NamespacedPod | affinity         |  [sig-storage] In-tree Volumes [Driver: gcepd] [Testpattern: Dynamic PV (default fs)] provisioning should access volume from different nodes
 createCoreV1NamespacedPod | affinity         |  [sig-storage] In-tree Volumes [Driver: nfs] [Testpattern: Dynamic PV (default fs)] provisioning should access volume from different nodes
 createCoreV1NamespacedPod | affinity         |  [sig-storage] PersistentVolumes-local  Pod with node different from PV's NodeAffinity should fail scheduling due to different NodeAffinity
 createCoreV1NamespacedPod | dnsConfig        |  [sig-network] DNS should support configurable pod DNS nameservers
 createCoreV1NamespacedPod | dnsConfig        |  [sig-network] DNS should support configurable pod resolv.conf
 createCoreV1NamespacedPod | readinessGates   |  [k8s.io] Pods should support pod readiness gates [NodeFeature:PodReadinessGate]
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a deleted RuntimeClass
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a non-existent RuntimeClass
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should reject a Pod requesting a RuntimeClass with an unconfigured handler
 createCoreV1NamespacedPod | runtimeClassName |  [sig-node] RuntimeClass should run a Pod requesting a RuntimeClass with a configured handler [NodeFeature:RuntimeHandler]
(12 rows)

#+end_src

** alpha/beta, deprecated, and gated fields

#+NAME: alpha/beta, deprecated, and gated PodSpec Fields
#+BEGIN_SRC sql-mode :exports both :eval never-export
select field_path, field_kind, release, deprecated, gated from kind_field_path
where field_type not like 'io%'
  and kind like '%PodSpec'
  and sub_kind like '%PodSpec'
  and (deprecated or gated or release != 'ga')
order by deprecated DESC, release DESC, gated;
#+END_SRC

#+RESULTS: alpha/beta, deprecated, and gated PodSpec Fields
#+begin_src sql-mode
      field_path       | field_kind | release | deprecated | gated 
-----------------------+------------+---------+------------+-------
 serviceAccount        | string     | ga      | t          | f
 runtimeClassName      | string     | beta    | f          | f
 shareProcessNamespace | integer    | beta    | f          | f
 preemptionPolicy      | string     | alpha   | f          | t
 overhead              | integer    | alpha   | f          | t
(5 rows)

#+end_src


** left
#+NAME: Left PodSpec
#+BEGIN_SRC sql-mode
select * from kind_field_path
where field_kind not like 'io%' -- only look at int and string
and kind like '%PodSpec'
and field_path like '%.%'
limit 120;
#+END_SRC
