#+TITLE: Ticket 61 Exploration
#+AUTHOR: Zach Mandeville


* The Ticket
[[https://gitlab.ii.coop/apisnoop/apisnoop_v3/issues/61][Gitlab Link]]

#+BEGIN_QUOTE
operationID is not built into kubernetes, it is a generated string made for swagger.json.  It is not a part of our audit events, and so we have to do some heavy regex matching to match an event to its definition.  It's also not a part of the community, really, in that the majority of people we talk to are not looking at kubernetes from the perspective of opID.
You can match an event to a swagger definition using a combination of object_ref and request_object.  We will rebuild our podspec field coverage using these.
From this refactoring, a hope is that it offers another perspective into the array types, and why they are not counting as event hits.
#+END_QUOTE
* Process
  :PROPERTIES:
  :header-args: :results export
  :END:
** DONE Confirm mapping event to swagger def using object_ref and request_object
   Let's grab the data for a sample audit event that has a request object (make sure you have line navigation turned on =SPC tL=)
  #+NAME: data for event with request_object
  #+BEGIN_SRC sql-mode
    SELECT
      operation_id,
      jsonb_pretty(data -> 'objectRef') as object_ref,
      jsonb_pretty(data->'requestObject') as request_object
      FROM
          audit_event
     WHERE request_object IS NOT NULL
       AND useragent ilike 'e2e.test%'
       AND (data -> 'requestObject' ->> 'kind') = 'Pod'
     LIMIT 1;
  #+END_SRC

  #+RESULTS: data for event with request_object
  #+begin_src sql-mode
         operation_id        |                         object_ref                          |                                request_object                                 
  ---------------------------+-------------------------------------------------------------+-------------------------------------------------------------------------------
   createCoreV1NamespacedPod | {                                                          +| {                                                                            +
                             |     "name": "pod-subpath-test-local-preprovisionedpv-pr48",+|     "kind": "Pod",                                                           +
                             |     "resource": "pods",                                    +|     "spec": {                                                                +
                             |     "namespace": "provisioning-5874",                      +|         "volumes": [                                                         +
                             |     "apiVersion": "v1"                                     +|             {                                                                +
                             | }                                                           |                 "name": "test-volume",                                       +
                             |                                                             |                 "persistentVolumeClaim": {                                   +
                             |                                                             |                     "readOnly": true,                                        +
                             |                                                             |                     "claimName": "pvc-68xfp"                                 +
                             |                                                             |                 }                                                            +
                             |                                                             |             },                                                               +
                             |                                                             |             {                                                                +
                             |                                                             |                 "name": "liveness-probe-volume",                             +
                             |                                                             |                 "emptyDir": {                                                +
                             |                                                             |                 }                                                            +
                             |                                                             |             }                                                                +
                             |                                                             |         ],                                                                   +
                             |                                                             |         "nodeName": "bootstrap-e2e-minion-group-t7h8",                       +
                             |                                                             |         "dnsPolicy": "ClusterFirst",                                         +
                             |                                                             |         "containers": [                                                      +
                             |                                                             |             {                                                                +
                             |                                                             |                 "args": [                                                    +
                             |                                                             |                     "--file_content_in_loop=/test-volume/test-file",         +
                             |                                                             |                     "--retry_time=20"                                        +
                             |                                                             |                 ],                                                           +
                             |                                                             |                 "name": "test-container-subpath-local-preprovisionedpv-pr48",+
                             |                                                             |                 "image": "gcr.io/kubernetes-e2e-test-images/mounttest:1.0",  +
                             |                                                             |                 "resources": {                                               +
                             |                                                             |                 },                                                           +
                             |                                                             |                 "volumeMounts": [                                            +
                             |                                                             |                     {                                                        +
                             |                                                             |                         "name": "test-volume",                               +
                             |                                                             |                         "subPath": "provisioning-5874",                      +
                             |                                                             |                         "mountPath": "/test-volume"                          +
                             |                                                             |                     },                                                       +
                             |                                                             |                     {                                                        +
                             |                                                             |                         "name": "liveness-probe-volume",                     +
                             |                                                             |                         "mountPath": "/probe-volume"                         +
                             |                                                             |                     }                                                        +
                             |                                                             |                 ],                                                           +
                             |                                                             |                 "imagePullPolicy": "IfNotPresent",                           +
                             |                                                             |                 "securityContext": {                                         +
                             |                                                             |                     "procMount": "Default",                                  +
                             |                                                             |                     "privileged": true                                       +
                             |                                                             |                 },                                                           +
                             |                                                             |                 "terminationMessagePath": "/dev/termination-log",            +
                             |                                                             |                 "terminationMessagePolicy": "File"                           +
                             |                                                             |             }                                                                +
                             |                                                             |         ],                                                                   +
                             |                                                             |         "restartPolicy": "Never",                                            +
                             |                                                             |         "schedulerName": "default-scheduler",                                +
                             |                                                             |         "securityContext": {                                                 +
                             |                                                             |             "seLinuxOptions": {                                              +
                             |                                                             |                 "level": "s0:c0,c1"                                          +
                             |                                                             |             }                                                                +
                             |                                                             |         },                                                                   +
                             |                                                             |         "enableServiceLinks": true,                                          +
                             |                                                             |         "terminationGracePeriodSeconds": 1                                   +
                             |                                                             |     },                                                                       +
                             |                                                             |     "status": {                                                              +
                             |                                                             |     },                                                                       +
                             |                                                             |     "metadata": {                                                            +
                             |                                                             |         "name": "pod-subpath-test-local-preprovisionedpv-pr48",              +
                             |                                                             |         "namespace": "provisioning-5874",                                    +
                             |                                                             |         "creationTimestamp": null                                            +
                             |                                                             |     },                                                                       +
                             |                                                             |     "apiVersion": "v1"                                                       +
                             |                                                             | }
  (1 row)

  #+end_src
  
  Here we have a set operationID for this event, which we can use to find the entry in our swagger.json. To do so is complicated as we need to follow the path, then the verb, then find the right operation_id.   I did this by going onto the raw swagger and just ctrl+f for the operationID.  This showed that for =createCoreV1NamespacedPod= it's definition was at: =#/definitions/io.k8s.api.core.v1.Pod=

 What we want is to go straight to the definition.  And this structure of the def seems to be consistent with the version and kind, but not sure how core was applied. Let's stretch out to view object_refs for more events that aren't in pod.
 
 #+NAME: audit events beyond podSPec
  #+BEGIN_SRC sql-mode
   SELECT
     DISTINCT operation_id,
     jsonb_pretty(data -> 'objectRef') as object_ref
     FROM
         audit_event
    WHERE request_object IS NOT NULL
      AND useragent ilike 'e2e.test%'
      AND (data -> 'objectRef' ->> 'apiVersion') = 'v1'
    LIMIT 10;
  #+END_SRC

  #+RESULTS: audit event with filled in group
  #+begin_src sql-mode
            operation_id           |              object_ref               
  ---------------------------------+---------------------------------------
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-2251",+
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-3598",+
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-3867",+
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-4285",+
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-461", +
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-465", +
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-5821",+
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-611", +
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-62",  +
                                   |     "apiVersion": "v1"               +
                                   | }
   createAppsV1NamespacedDaemonSet | {                                    +
                                   |     "name": "csi-hostpathplugin",    +
                                   |     "apiGroup": "apps",              +
                                   |     "resource": "daemonsets",        +
                                   |     "namespace": "provisioning-6539",+
                                   |     "apiVersion": "v1"               +
                                   | }
  (10 rows)

  #+end_src

 You can see that some of these have an 'objectRef -> apiGroup' that wasn't in the first sample we did.  What are the distinct apiGroups?
 #+NAME: distinct apiGroup
  #+BEGIN_SRC sql-mode
   SELECT
     DISTINCT (data -> 'objectRef' ->> 'apiGroup') as api_group,
     (data -> 'objectRef' ->> 'apiVersion') as api_version
     FROM
         audit_event
    WHERE request_object IS NOT NULL
      AND useragent ilike 'e2e.test%';
  #+END_SRC

  #+RESULTS: distinct apiGroup
  #+begin_src sql-mode
            api_group           | api_version 
  ------------------------------+-------------
   admissionregistration.k8s.io | v1beta1
   apiextensions.k8s.io         | v1beta1
   apiregistration.k8s.io       | v1beta1
   apps                         | v1
   authorization.k8s.io         | v1beta1
   autoscaling                  | v1
   batch                        | v1
   batch                        | v1beta1
   certificates.k8s.io          | v1beta1
   extensions                   | v1beta1
   node.k8s.io                  | v1beta1
   policy                       | v1beta1
   rbac.authorization.k8s.io    | v1
   rbac.authorization.k8s.io    | v1beta1
   scheduling.k8s.io            | v1
   storage.k8s.io               | v1
                                | v1
  (17 rows)

  #+end_src
 
  I would bet core is when the apiGroup is null, which would make sense.  It's part of core kubernetes, not a specific group.  In the [[https://kubernetes.io/docs/reference/using-api/api-overview/#api-groups][k8s API Docs]], core is described separately from the 'named groups'.  So in other words, it is not a named group and so its api_group value has no name.
  
*** Exploring v1 Core events
    
    #+NAME: Core Events
    #+BEGIN_SRC sql-mode
      SELECT
        distinct operation_id
        FROM
            audit_event
       WHERE
         request_object IS NOT NULL
         AND useragent ilike 'e2e.test%'
         AND (data->'objectRef'->>'apiGroup') IS NULL
         AND (data -> 'objectRef' ->> 'apiVersion') = 'v1';
    #+END_SRC

    #+RESULTS: Core Events
    #+begin_src sql-mode
                     operation_id                 
    ----------------------------------------------
     createCoreV1Namespace
     createCoreV1NamespacedEndpoints
     createCoreV1NamespacedLimitRange
     createCoreV1NamespacedPersistentVolumeClaim
     createCoreV1NamespacedPod
     createCoreV1NamespacedPodTemplate
     createCoreV1NamespacedReplicationController
     createCoreV1NamespacedResourceQuota
     createCoreV1NamespacedService
     createCoreV1NamespacedServiceAccount
     createCoreV1PersistentVolume
     deleteCoreV1NamespacedLimitRange
     deleteCoreV1NamespacedPersistentVolumeClaim
     deleteCoreV1NamespacedPod
     deleteCoreV1NamespacedReplicationController
     deleteCoreV1NamespacedService
     deleteCoreV1NamespacedServiceAccount
     deleteCoreV1PersistentVolume
     patchCoreV1NamespacedPod
     patchCoreV1NamespacedPodStatus
     patchCoreV1Node
     replaceCoreV1Namespace
     replaceCoreV1NamespacedLimitRange
     replaceCoreV1NamespacedPersistentVolumeClaim
     replaceCoreV1NamespacedPod
     replaceCoreV1NamespacedReplicationController
     replaceCoreV1NamespacedResourceQuota
     replaceCoreV1NamespacedService
     replaceCoreV1NamespacedServiceAccount
     replaceCoreV1Node
     replaceCoreV1NodeStatus
    (31 rows)

    #+end_src

    We can check out a couple of these in the swagger and grab their referenced definition.
    
     - createCoreV1Namespace :: #/definitions/io.k8s.api.core.v1.Namespace 
     - createCoreV1NamespacedEndpoints :: #/definitions/io.k8s.api.core.v1.Endpoints
     - createCoreV1PersistentVolume :: #/definitions/io.k8s.api.core.v1.PersistentVolume
     - deleteCoreV1NamespacedReplicationController :: #/definitions/io.k8s.apimachinery.pkg.apis.meta.v1.DeleteOptions 
     - patchCoreV1Node :: #/definitions/io.k8s.apimachinery.pkg.apis.meta.v1.Patch
     - replaceCoreV1NamespacedResourceQuota ::  #/definitions/io.k8s.api.core.v1.ResourceQuota

   so io.k8s is consistent, and then there'v variation between k8s.api.core, k8s.apimachinery, and k8s.api.meta
   What does the objectRef look like?
   
   #+NAME: Object Ref for events with selected operation_id's
   #+BEGIN_SRC sql-mode
     SELECT DISTINCT ON(operation_id)
       jsonb_pretty(data -> 'objectRef') as object_ref,
       operation_id,
       data -> 'requestObject' ->> 'kind'
       FROM
           audit_event
      WHERE request_object IS NOT NULL
        AND useragent ilike 'e2e.test%'
        AND (data->'objectRef'->>'apiGroup') IS NULL
        AND (data -> 'objectRef' ->> 'apiVersion') = 'v1'
        AND operation_id = ANY('{
                               createCoreV1Namespace,
                               createCoreV1PersistentVolume,
                               deleteCoreV1NamespacedReplicationController,
                               patchCoreV1Node,
                               replaceCoreV1NamespacedResourceQuota}') ;
   #+END_SRC

   #+RESULTS: Object Ref for events with selected operation_id's
   #+begin_src sql-mode
   apisnoop'# apisnoop'# apisnoop'# apisnoop'# apisnoop'#                           object_ref                           |                operation_id                 |     ?column?     
   ---------------------------------------------------------------+---------------------------------------------+------------------
    {                                                            +| createCoreV1Namespace                       | Namespace
        "name": "pv-271",                                        +|                                             | 
        "resource": "namespaces",                                +|                                             | 
        "apiVersion": "v1"                                       +|                                             | 
    }                                                             |                                             | 
    {                                                            +| createCoreV1PersistentVolume                | PersistentVolume
        "resource": "persistentvolumes",                         +|                                             | 
        "apiVersion": "v1"                                       +|                                             | 
    }                                                             |                                             | 
    {                                                            +| deleteCoreV1NamespacedReplicationController | DeleteOptions
        "name": "cleanup40-0855a67a-cb10-4fdf-8695-e0195a983395",+|                                             | 
        "resource": "replicationcontrollers",                    +|                                             | 
        "namespace": "kubelet-8090",                             +|                                             | 
        "apiVersion": "v1"                                       +|                                             | 
    }                                                             |                                             | 
    {                                                            +| patchCoreV1Node                             | 
        "name": "bootstrap-e2e-minion-group-t7h8",               +|                                             | 
        "resource": "nodes",                                     +|                                             | 
        "apiVersion": "v1"                                       +|                                             | 
    }                                                             |                                             | 
    {                                                            +| replaceCoreV1NamespacedResourceQuota        | ResourceQuota
        "uid": "61032454-1269-4581-aeaf-05504781c86b",           +|                                             | 
        "name": "quota-for-e2e-test-resourcequota-6488-crds",    +|                                             | 
        "resource": "resourcequotas",                            +|                                             | 
        "namespace": "resourcequota-193",                        +|                                             | 
        "apiVersion": "v1",                                      +|                                             | 
        "resourceVersion": "7708"                                +|                                             | 
    }                                                             |                                             | 
   (5 rows)

   #+end_src

   So I do not think constructing the right definition from this is smart, as it's too finicky on how the exact def is structured, and we are back in the regex biz.
   I am remembering this now from conversation on Friday, that we can perhaps refererece the x-kubernetes sections in the definitions and match direct to that instead.

        
*** Thoghtful Pause
    It feels a rocky path to construct the definition, instead we can match to the definition using x-kubernetes-kind.  there isn't a super simple way to do it and check it, outside of constructing the definitions themselves and then comparing it to the schema ref's in the swagger.json
*** Construct View for Swagger Definitions
    We want to take our swagger row and parse out each definition, plus its x-kubernetes-action
    #+NAME: New View: Swagger Definitions
    #+BEGIN_SRC sql-mode
     CREATE OR REPLACE VIEW "public"."swagger_definition" AS
      SELECT
        def.key as definition,
          def.value as value,
        swagger.id as swagger_id
        FROM api_swagger as swagger,
             jsonb_each((swagger.data ->'definitions')) def(key, value);
    #+END_SRC

    #+RESULTS: New View: Swagger Definitions
    #+begin_src sql-mode
    CREATE VIEW
    #+end_src
    
    I want to confirm that these definitions map to a single x-kubernetes-action
    #+NAME: Distinct Definitions and Distinct x-kubernetes actions
    #+BEGIN_SRC sql-mode
      SELECT
        count(DISTINCT definition) as total_definitions,
        count(DISTINCT definition) FILTER(WHERE (value ->'x-kubernetes-group-version-kind') IS NULL) as unkinds,
        count(DISTINCT definition) FILTER(WHERE (value ->'x-kubernetes-group-version-kind') IS NOT NULL) as kinds,
        count(distinct (value->'x-kubernetes-group-version-kind')) as actions
          FROM swagger_definition;
    #+END_SRC

    #+RESULTS: Distinct Definitions and Distinct x-kubernetes actions
    #+begin_src sql-mode
     total_definitions | unkinds | kinds | actions 
    -------------------+---------+-------+---------
                   662 |     468 |   194 |     194
    (1 row)

    #+end_src
    
    When a definition has 'x-kubernetes-group-version-kind' it is unique.  What are the ones without?
    
   #+NAME: Sample of definitions without group-version-kind 
    #+BEGIN_SRC sql-mode
     SELECT
     definition
       FROM swagger_definition
      WHERE (value->'x-kubernetes-group-version-kind') IS NULL
      LIMIT 50;

    #+END_SRC

    #+RESULTS: Sample of definitions without group-version-kind
    #+begin_src sql-mode
                definition            
    ----------------------------------
     io.k8s.api.core.v1.PodIP
     io.k8s.api.core.v1.Probe
     io.k8s.api.core.v1.Taint
     io.k8s.api.core.v1.EnvVar
     io.k8s.api.core.v1.Sysctl
     io.k8s.api.core.v1.Volume
     io.k8s.api.core.v1.Handler
     io.k8s.api.core.v1.PodSpec
     io.k8s.api.rbac.v1.RoleRef
     io.k8s.api.rbac.v1.Subject
     io.k8s.api.batch.v1.JobSpec
     io.k8s.api.core.v1.Affinity
     io.k8s.api.core.v1.NodeSpec
     io.k8s.api.core.v1.Container
     io.k8s.api.core.v1.HostAlias
     io.k8s.api.core.v1.KeyToPath
     io.k8s.api.core.v1.Lifecycle
     io.k8s.api.core.v1.PodStatus
     io.k8s.api.batch.v1.JobStatus
     io.k8s.api.core.v1.ExecAction
     io.k8s.api.core.v1.HTTPHeader
     io.k8s.api.core.v1.NodeStatus
     io.k8s.api.core.v1.Toleration
     io.k8s.api.rbac.v1.PolicyRule
     io.k8s.api.core.v1.EventSeries
     io.k8s.api.core.v1.EventSource
     io.k8s.api.core.v1.NodeAddress
     io.k8s.api.core.v1.PodAffinity
     io.k8s.api.core.v1.ServicePort
     io.k8s.api.core.v1.ServiceSpec
     io.k8s.api.core.v1.VolumeMount
     io.k8s.api.core.v1.Capabilities
     io.k8s.api.core.v1.EndpointPort
     io.k8s.api.core.v1.EnvVarSource
     io.k8s.api.core.v1.NodeAffinity
     io.k8s.api.core.v1.NodeSelector
     io.k8s.api.core.v1.PodCondition
     io.k8s.api.core.v1.PodDNSConfig
     io.k8s.api.core.v1.VolumeDevice
     io.k8s.api.rbac.v1beta1.RoleRef
     io.k8s.api.rbac.v1beta1.Subject
     io.k8s.api.apps.v1.DaemonSetSpec
     io.k8s.api.batch.v1.JobCondition
     io.k8s.api.core.v1.ContainerPort
     io.k8s.api.core.v1.EnvFromSource
     io.k8s.api.core.v1.HTTPGetAction
     io.k8s.api.core.v1.NamespaceSpec
     io.k8s.api.core.v1.NodeCondition
     io.k8s.api.core.v1.ScopeSelector
     io.k8s.api.core.v1.ServiceStatus
    (50 rows)

    #+end_src
    
    From this sampling, and comparing it to the swagger, it looks like these don't directly connect to an opID, meaning the path's param->body-in->body->$ref won't point to these definitions.  they are used in reference to other definitions, but that's it. 

    We can do a semi-sanity check by counting the number of distinct param_schemas in our api_operation_param view, since this would hold the reference to an event's definition.  I would expect it to be at or below 194.  Higher than that means we have operations whose parameters point to a definition without a group-version-kind.
    #+NAME: distinct operation_params
    #+BEGIN_SRC sql-mode
      SELECT 
      count( distinct param_schema )
      FROM api_operation_parameter
      WHERE NOT (param_schema = ANY('{integer, string, boolean}'));
    #+END_SRC

    #+RESULTS: distinct operation_params
    #+begin_src sql-mode
     count 
    -------
       104
    (1 row)

    #+end_src
    
    That looks reasonable for now.  

*** Conclusion  
    I think we could reference the definition simply using the objectRef and requestObject in the audit_event, at least enough to explore our field coverage again.

** DONE Rebuild initial Podspec query to not use operation_id
   CLOSED: [2019-09-11 Wed 04:37]
*** Original PodSpec Materialized View
   Here we have our original to draw from.  It's a comple query, and before we refactor the parts, we should ensure a diff. method  on id would return same # of results on a simpler query.
 #+NAME: view podspec_field_coverage_material
 #+BEGIN_SRC sql-mode
   CREATE MATERIALIZED VIEW "public"."podspec_field_coverage_material" AS 
   SELECT DISTINCT
     audit_event.operation_id,
     jsonb_object_keys(audit_event.request_object -> 'spec'::text) AS podspec_field,
     count(event_field.event_field) AS hits,
     split_part(audit_event.useragent, '--', 2) as test,
     split_part(audit_event.useragent, '--', 1) as useragent
     FROM audit_event,
          LATERAL
            jsonb_object_keys(audit_event.request_object -> 'spec'::text)
            event_field(event_field)
    WHERE (audit_event.request_object ->> 'kind'::text) = 'Pod'::text
      AND audit_event.operation_id !~~ '%alpha%'::text
      AND audit_event.operation_id !~~ '%beta%'::text
    GROUP BY operation_id, podspec_field, useragent
   UNION
   SELECT DISTINCT
     audit_event.operation_id,
     jsonb_object_keys(audit_event.request_object -> 'template' -> 'spec'::text) AS podspec_field,
     count(event_field.event_field) AS hits,
     split_part(audit_event.useragent, '--', 2) as test,
     split_part(audit_event.useragent, '--', 1) as useragent
     FROM audit_event,
          LATERAL
            jsonb_object_keys(audit_event.request_object -> 'template' -> 'spec'::text)
            event_field(event_field)
    WHERE (audit_event.request_object ->> 'kind'::text) = 'PodTemplate'::text
      AND audit_event.operation_id !~~ '%alpha%'::text
      AND audit_event.operation_id !~~ '%beta%'::text
    GROUP BY operation_id, podspec_field, useragent
   UNION
   SELECT DISTINCT
     audit_event.operation_id,
     jsonb_object_keys(audit_event.request_object -> 'spec' -> 'template' -> 'spec'::text) AS podspec_field,
     count(event_field.event_field) AS hits,
     split_part(audit_event.useragent, '--', 2) as test,
     split_part(audit_event.useragent, '--', 1) as useragent
     FROM audit_event,
          LATERAL
            jsonb_object_keys(audit_event.request_object -> 'spec' -> 'template' -> 'spec'::text)
            event_field(event_field)
    WHERE (audit_event.request_object->>'kind' = 'DaemonSet'
      OR  audit_event.request_object->>'kind' = 'Deployment'
      OR  audit_event.request_object->>'kind' = 'ReplicationController'
      OR  audit_event.request_object->>'kind' = 'StatefulSet'
      OR  audit_event.request_object->>'kind' = 'Job'
      OR  audit_event.request_object->>'kind' = 'ReplicaSet')
      AND audit_event.operation_id !~~ '%alpha%'::text
      AND audit_event.operation_id !~~ '%beta%'::text
    GROUP BY operation_id, podspec_field, useragent;
 #+END_SRC
*** Ensure we can get same # of records  using alternate id
    
    What seems like a smart mapping for an audit_event woudl be verstion, group, kind, verb.  If we could use this as an identifier, instead of operationID, then we could build out distinct views without using any regex and the only medium between data and results is transparent sql queries. To be happy with this, though, we need to make sure that a view of distinct entries on this grouping matches a view with distinct groupings on operation_id. 

    One limit I'm going to put on these views is to only grab audit events with request_objects.  This sharply decreases the number of events we are looking at.  The reason for this is:
    - It's been stated that sig-arch only cares about the requests, and not the responses.  We want to see the events that hit--or make requests to-the api.
    - our grouping requires =kind= which is available in the request_object, so we want a consistent ability to grab this.
    
      So let's make a view that takes from our audit_event and pulls op_id plus the specific fields we want to id on.
      I've noticed that the objectRef can sometimes contain resource and subResources, which map to slightly altered operationId's, so I want to include these as well.
    #+NAME: events by gvkrv
    #+BEGIN_SRC sql-mode :results silent
      CREATE OR REPLACE VIEW "public"."events_by_gvkrv" AS
        SELECT
          CASE
          WHEN ((a.data -> 'objectRef' ->> 'apiGroup') IS NULL) THEN ''
          ELSE (a.data -> 'objectRef' ->> 'apiGroup')
                END as api_group,
          (a.data -> 'objectRef' ->>'apiVersion') as api_version,
          (a.data -> 'requestObject'->>'kind') as kind,
          (a.data -> 'objectRef'->>'resource') as resource,
            (a.data -> 'objectRef'->>'subresource') as sub_resource,
          (a.data->>'verb') as event_verb,
          operation_id,
          audit_id,
          split_part(a.useragent, '--', 2) as test,
          split_part(a.useragent, '--', 1) as useragent,
          (a.data -> 'requestObject') as request_object
          FROM audit_event as a
         where data->'requestObject' is not null;
    #+END_SRC

    
    As a sanity check, we can ensure the # of records for our new view matches the raw audit_events.
    #+NAME: Record Count
    #+BEGIN_SRC sql-mode
      SELECT
        (
          SELECT
            count(*)
            FROM audit_event
                   WHERE (data->'requestObject') IS NOT NULL

        ) as request_event_raw_count,
        (
          SELECT
            count(*)
            FROM
                events_by_gvkrv
        ) as gvkv_count;

    #+END_SRC

    #+RESULTS: Record Count
    #+begin_src sql-mode
     request_event_raw_count | gvkv_count 
    -------------------------+------------
                       62087 |      62087
    (1 row)

    #+end_src

    Sweet, so we are getting the exact same amount of records, of course.  There's no reason we wouldn't, but it's a nice sanity check.
    
    So now we want to compare distinct operation_ids to distinct group_version_kind.  We should get the same number for this too.
    
    #+NAME: Count Comparison: raw vs. gvkv
    #+BEGIN_SRC sql-mode
      SELECT (
        SELECT
          count(distinct operation_id)
          FROM audit_event
         WHERE
            (data->'requestObject') IS NOT NULL
      ) as raw_count,
        (
          SELECT
            count(*)
            FROM(
              SELECT distinct
                api_version,
                api_group,
                event_verb,
                kind
                FROM events_by_gvkrv
            ) as distinct_gvkrv
        ) as gvkrv_count;
    #+END_SRC

    #+RESULTS: Count Comparison: raw vs. gvkv
    #+begin_src sql-mode
     raw_count | gvkrv_count 
    -----------+-------------
           166 |         108
    (1 row)

    #+end_src

    Using just group, version, kind, verb we do not get the same number of distinct results.
    If we expand to resources, though...
    #+NAME: Count Comparison: raw vs. gvkrv
    #+BEGIN_SRC sql-mode
      SELECT (
        SELECT
          count(distinct operation_id)
          FROM audit_event
         WHERE
            (data->'requestObject') IS NOT NULL
      ) as raw_count,
        (
          SELECT
            count(*)
            FROM(
              SELECT distinct
                api_version,
                api_group,
                event_verb,
                kind,
                resource,
                sub_resource
                FROM events_by_gvkrv
            ) as distinct_gvkrv
        ) as gvkrv_count;
    #+END_SRC

    #+RESULTS: Count Comparison: raw vs. gvkrv
    #+begin_src sql-mode
     raw_count | gvkrv_count 
    -----------+-------------
           166 |         166
    (1 row)

    #+end_src

    Beauty!
    
    And just for completion, let's ensure that we are not getting the same number of distinct results, but _different_ distinct results.
    One way to do this is to compare operation id's for the two views.  Even if we are using a new id'ing, the old op_id method should still work and so there should be no difference in the distinct op_ids between the old and new view.
    
    To make the comparison query simpler, we'll make a view that is distinct on gvkrv, but also contains the op_id.
   #+NAME: distinct on gvkv + op_id 
   #+BEGIN_SRC sql-mode :results silent
     CREATE OR REPLACE VIEW "public"."distinct_gvkv" AS
       SELECT DISTINCT ON (
         api_version,
         api_group,
         event_verb,
         kind,
         resource,
         sub_resource
       ) api_version,
                       operation_id
         FROM
             events_by_gvkrv;
   #+END_SRC
   
   And compare the count of op_ids in our raw_count that don't exist in our gkrv count.  We are hoping for 0.
   #+RESULTS: distinct on gvkv + op_id
   #+begin_src sql-mode
   CREATE VIEW
   #+end_src
   #+BEGIN_SRC sql-mode 
     select count (*)
       FROM (
      SELECT
        distinct operation_id
        FROM audit_event
        WHERE (data->'requestObject') IS NOT NULL
      EXCEPT
      SELECT
        operation_id
        FROM
            distinct_gvkv
     ) as gkvrv_op_id;
   #+END_SRC
   
   #+RESULTS:
   #+begin_src sql-mode
    count 
   -------
        0
   (1 row)

   #+end_src
   
   Fantastic!  
**** Conclusion
     If we limit the events we look at in our audit logs to just request events (those with requestObject), then we can meaningfully group these events by group,version,kind,resource,subResource,verb.  Looking at the distinct results based around this grouping gives us identical #'s to our previous grouping of operationID.

     While this grouping is more verbose than op_id it has several advantages.  For one, it requires no expensive regex function to run on the data, decreasing the startup of our system by 30 minutes.  It also means we are not inserting anything additional into the audit events.  Our views are coming directly from the data given, using the same language as outlined in the k8s docs and the openAPI spec.

     There's also a nice path for our sunburst:  moving outward we can have version->group->kind->resource->subResource->verb.  It doubles the rings in the sunburst, but ensures that every node maps exactly to discrete endpoint and traversing the sunburst is more logical to the community we're serving.

*** Revised PodSpec Materialized View

    If we build off our events_by_gvkrv view, we can rebuild the table without operation_id and with a slightly cleaner format.  
    
  #+NAME: view podspec_field_coverage_material
  #+BEGIN_SRC sql-mode :results silent
    CREATE MATERIALIZED VIEW "public"."revised_podspec_field_coverage_material" AS 
    SELECT DISTINCT
      api_group,
      api_version,
      kind,
      event_verb,
      resource,
      sub_resource,
      test,
      useragent,
      jsonb_object_keys(request_object -> 'spec'::text) AS podspec_field,
      count(event_field.event_field) AS hits
      FROM events_by_gvkrv,
           LATERAL
             jsonb_object_keys(events_by_gvkrv.request_object -> 'spec'::text) event_field(event_field)
     WHERE kind = 'Pod'
       AND NOT (lower(api_version) ~~ ANY('{%alpha%, %beta%}')) -- api_version doesn't contain alpha or beta;
     GROUP BY api_group, api_version, kind, event_verb, resource, sub_resource, test, useragent, podspec_field
          UNION
    SELECT DISTINCT
      api_group,
      api_version,
      kind,
      event_verb,
      resource,
      sub_resource,
      test,
      useragent,
      jsonb_object_keys(request_object -> 'template' -> 'spec'::text) AS podspec_field,
      count(event_field.event_field) AS hits
      FROM events_by_gvkrv,
           LATERAL
             jsonb_object_keys(events_by_gvkrv.request_object -> 'template'-> 'spec'::text) event_field(event_field)
     WHERE kind = 'PodTemplate'
       AND NOT (lower(api_version) ~~ ANY('{%alpha%, %beta%}'))
     GROUP BY api_group, api_version, kind, event_verb, resource, sub_resource, test, useragent, podspec_field
          UNION
    SELECT DISTINCT
      api_group,
      api_version,
      kind,
      event_verb,
      resource,
      sub_resource,
      test,
      useragent,
      jsonb_object_keys(request_object -> 'spec' -> 'template' -> 'spec'::text) AS podspec_field,
      count(event_field.event_field) AS hits
      FROM events_by_gvkrv,
           LATERAL
             jsonb_object_keys(events_by_gvkrv.request_object -> 'spec' -> 'template'-> 'spec'::text) event_field(event_field)
     WHERE kind = ANY('{DaemonSet, Deployment, ReplicationController, StatefulSet, Job,ReplicaSet}')
       AND NOT (lower(api_version) ~~ ANY('{%alpha%, %beta%}'))
     GROUP BY api_group, api_version, kind, event_verb, resource, sub_resource, test, useragent, podspec_field; 
 #+END_SRC
 
 And comparing the two we get the same number of records.

  #+NAME: Comparison of orig and revised podspec
  #+BEGIN_SRC sql-mode
    SELECT
      (
        SELECT
          count(*)
          FROM
              podspec_field_coverage_material
      ) AS original_count,
      (
        SELECT
          count(*)
          FROM
              revised_podspec_field_coverage_material
        ) as revised_count;

  #+END_SRC

  #+RESULTS: Comparison of orig and revised podspec
  #+begin_src sql-mode
   original_count | revised_count 
  ----------------+---------------
             6572 |          6572
  (1 row)

  #+end_src
  
  Success!
** DONE Move down line of cascading views based on this change
   CLOSED: [2019-09-11 Wed 04:54]
*** Revised 601: PodSpec Field Coverage View
 #+NAME: view podspec_field_coverage
 #+BEGIN_SRC sql-mode
 create view revised_podspec_field_coverage as select * from revised_podspec_field_coverage_material;
 #+END_SRC
 
 #+NAME: podspec_field_coverage: Compare Counts to Original
  #+BEGIN_SRC sql-mode
    SELECT
      (
        SELECT
          count(*)
          FROM
              podspec_field_coverage
      ) AS original_count,
      (
        SELECT
          count(*)
          FROM
              revised_podspec_field_coverage
        ) as revised_count;

  #+END_SRC

  #+RESULTS: podspec_field_coverage: Compare Counts to Original
  #+begin_src sql-mode
   original_count | revised_count 
  ----------------+---------------
             6572 |          6572
  (1 row)

  #+end_src

*** Revised 602: PodSpec Field Summary View
 #+NAME: view podspec_field_summary
 #+BEGIN_SRC sql-mode
   create view revised_podspec_field_summary as
   select distinct field_name as podspec_field,
                   0 as other_hits,
                   0 as e2e_hits,
                   0 as conf_hits
     from api_schema_field
    where field_schema like '%PodSpec%'
    UNION
   select
     podspec_field,
     sum(hits) as other_hits,
     0 as e2e_hits,
     0 as conf_hits
     from revised_podspec_field_coverage
    where useragent not like 'e2e.test%'
    group by podspec_field
    UNION
   select
     podspec_field,
     0 as other_hits,
     sum(hits) as e2e_hits,
     0 as conf_hits
     from revised_podspec_field_coverage
    where useragent like 'e2e.test%'
      and test not like '%Conformance%'
    group by podspec_field
    UNION
   select
     podspec_field,
     0 as other_hits,
     0 as e2e_hits,
     sum(hits) as conf_hits
     from podspec_field_coverage
    where useragent like 'e2e.test%'
      and test like '%Conformance%'
    group by podspec_field;
 #+END_SRC

 #+NAME: podspec_field_summary: Compare Counts to Original
  #+BEGIN_SRC sql-mode
    SELECT
      (
        SELECT
          count(*)
          FROM
              podspec_field_summary
      ) AS original_count,
      (
        SELECT
          count(*)
          FROM
              revised_podspec_field_summary
        ) as revised_count;

  #+END_SRC

  #+RESULTS: podspec_field_summary: Compare Counts to Original
  #+begin_src sql-mode
   original_count | revised_count 
  ----------------+---------------
              103 |           103
  (1 row)

  #+end_src

*** Revised 604: PodSpec Field mid Report View
 #+NAME: podspec_field_mid
 #+BEGIN_SRC sql-mode
   create or replace view revised_podspec_field_mid_report as
   select distinct
     field_name as podspec_field,
     0 as other_hits,
     0 as e2e_hits,
     0 as conf_hits,
     release,
     deprecated,
     feature_gated as gated,
     required,
     field_kind,
     field_type
     from api_schema_field
    where field_schema like '%PodSpec%'
    UNION
   select distinct podspec_field,
         sum(other_hits) as other_hits,
         sum(e2e_hits) as e2e_hits,
         sum(conf_hits) as conf_hits,
         kfp.release,
         kfp.deprecated,
         kfp.gated,
         kfp.required,
         kfp.field_kind,
         kfp.field_type
   from revised_podspec_field_summary pfs, kind_field_path kfp
   where kfp.field_type not like 'io%'
     and (kfp.kind like '%PodSpec'
     or kfp.sub_kind like '%PodSpec')
     and pfs.podspec_field = regexp_replace(kfp.field_path, '.*\.','') 
   group by podspec_field, kfp.release, kfp.deprecated, kfp.gated, kfp.required, kfp.field_kind, kfp.field_type
   order by conf_hits, e2e_hits, other_hits;
 #+END_SRC

 #+NAME: podspec_field_mid_report: Compare Counts to Original
  #+BEGIN_SRC sql-mode
    SELECT
      (
        SELECT
          count(*)
          FROM
              podspec_field_mid_report
      ) AS original_count,
      (
        SELECT
          count(*)
          FROM
              revised_podspec_field_mid_report
        ) as revised_count;

  #+END_SRC

  #+RESULTS: podspec_field_mid_report: Compare Counts to Original
  #+begin_src sql-mode
   original_count | revised_count 
  ----------------+---------------
               53 |            53
  (1 row)

  #+end_src

*** Revised 604: PodSpec Field Report View
 #+NAME: revised podspec_field_hits
 #+BEGIN_SRC sql-mode
   create or replace view revised_podspec_field_report as
   select distinct podspec_field,
         sum(other_hits) as other_hits,
         sum(e2e_hits) as e2e_hits,
         sum(conf_hits) as conf_hits,
         release,
         deprecated,
         gated,
         required,
         field_kind,
         field_type
   from revised_podspec_field_mid_report
   group by podspec_field, release, deprecated, gated, required, field_kind, field_type
   order by conf_hits, e2e_hits, other_hits;
 #+END_SRC

 #+NAME: podspec_field_report: Compare Counts to Original
  #+BEGIN_SRC sql-mode
    SELECT
      (
        SELECT
          count(*)
          FROM
              podspec_field_report
      ) AS original_count,
      (
        SELECT
          count(*)
          FROM
              revised_podspec_field_report
        ) as revised_count;

  #+END_SRC

  #+RESULTS: podspec_field_report: Compare Counts to Original
  #+begin_src sql-mode
   original_count | revised_count 
  ----------------+---------------
               34 |            34
  (1 row)

  #+end_src

* Footnotes
** Connect to Database
    If you already have your db and hasura endpoint up and running:
 - [ ] Connect to your postgres db from within this file
   You'll want execute this code block by moving your cursor within and typing =,,=
  
   #+NAME: Connect org to postgres
   #+BEGIN_SRC emacs-lisp :results silent
     (sql-connect "apisnoop" (concat "*SQL: postgres:data*"))
   #+END_SRC

 - [ ] Test your connection works
   You can run this sql block, and it see a message in your minbuffer like:
   : You are connected to database "apisnoop" as user "apisnoop" on host "localhost" at port "10041".

   #+NAME: Test Connection
   #+BEGIN_SRC sql-mode :results silent
   \conninfo
   #+END_SRC

 If the db is not running, or hasn't been setup yet, follow the instructions in [[file:~/ii/apisnoop_v3/org/meta.org::*Welcome,%20ii%20dev!][meta.org]]  , then come back and do the steps above.
